{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import itertools\n",
    "from surgeon_recording.reader import Reader\n",
    "from scipy.io import savemat\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = join('..', 'data', 'cuts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_files = 20\n",
    "exp_folders = [join(datafolder, 'cut' + str(i)) for i in (np.arange(nb_files) + 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_row(data, row, labels=None):\n",
    "    return data.append(pd.Series(row, labels), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_motion(data, frames_list, scaler):\n",
    "    column_list = list(itertools.chain.from_iterable((f + '_x', f + '_y', f + '_z') for f in frames_list))\n",
    "    data[column_list] = 2 * scaler.fit_transform(data[column_list]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, time_vector):\n",
    "    current_time_index = 0\n",
    "    downsampled_data = pd.DataFrame(columns=data.columns)\n",
    "    \n",
    "    for i in range(len(time_vector)):\n",
    "        t = time_vector.iloc[i]\n",
    "        start_time = current_time_index\n",
    "        \n",
    "        while current_time_index < data.shape[0] and data['relative_time'].iloc[current_time_index] < t:\n",
    "            current_time_index = current_time_index + 1\n",
    "        stop_time = current_time_index\n",
    "\n",
    "        average_data = data.iloc[start_time:stop_time, :].mean()\n",
    "        downsampled_data = insert_row(downsampled_data, average_data)\n",
    "    return downsampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_emg(data, emg_list, scaler):\n",
    "    # first take the absolute value of the data\n",
    "    data[emg_list] = data[emg_list].abs()\n",
    "    # then apply a minmax scaler\n",
    "    data[emg_list] = 2 * scaler.fit_transform(data[emg_list]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_list = ['blade', 'wrist']\n",
    "optitrack_list = list(itertools.chain.from_iterable((f + '_x', f + '_y', f + '_z',\n",
    "                                                     f + '_qx', f + '_qy', f + '_qz', f + '_qw')\n",
    "                                                    for f in frames_list))\n",
    "emg_list = ['emg' + str(i) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = []\n",
    "\n",
    "scalers = {}\n",
    "scalers['optitrack'] = MinMaxScaler()\n",
    "scalers['emg'] = MinMaxScaler()\n",
    "\n",
    "for folder in exp_folders:\n",
    "    reader.play(folder)\n",
    "    # extract optitrack data and preprocess them\n",
    "    opt_data = reader.data['optitrack'].reset_index(drop=True)\n",
    "    preprocess_motion(opt_data, frames_list, scalers['optitrack'])\n",
    "    # downsample emg and preprocess it\n",
    "    emg_data = downsample(reader.data['emg'], opt_data['relative_time'])\n",
    "    preprocess_emg(emg_data, emg_list, scalers['emg'])\n",
    "    # merge the data\n",
    "    merge_data = pd.concat([opt_data, emg_data.iloc[:, 3:]], axis=1)\n",
    "    # store in the list\n",
    "    timeseries.append(merge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as mat file for Nadia's segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_column_list = optitrack_list\n",
    "\n",
    "# drop the data in matlab\n",
    "matdata = {}\n",
    "matdata['timeseries'] = []\n",
    "for t in timeseries:\n",
    "    # drop the index and times columns and convert to numpy array\n",
    "    matdata['timeseries'].append(t[merged_column_list].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat(\"segmentation_data.mat\", matdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply 0 velocity segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(timeseries):\n",
    "    frame_list = ['blade', 'wrist']\n",
    "\n",
    "    header = list(itertools.chain.from_iterable((f + '_dx', f + '_dy', f + '_dz', f + '_vel_mag',\n",
    "                                                 f + '_ddx', f + '_ddy', f + '_ddz', f + '_acc_mag')\n",
    "                                                for f in frame_list))\n",
    "\n",
    "    derived_data = pd.DataFrame(columns=header)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        row_data = []\n",
    "        for f in frame_list:\n",
    "            # compute velocity\n",
    "            if index == 0:\n",
    "                vel = np.zeros(3)\n",
    "            else:\n",
    "                x0 = data.loc[index - 1, [f + '_x', f + '_y', f + '_z']].to_numpy()\n",
    "                x1 = row.loc[[f + '_x', f + '_y', f + '_z']].to_numpy()\n",
    "                dt = row['relative_time'] - data.loc[index - 1, 'relative_time']\n",
    "                vel = (x1 - x0) / dt\n",
    "            vel_mag = np.linalg.norm(vel)\n",
    "            # compute accleration\n",
    "            if index < 2:\n",
    "                acc = np.zeros(3)\n",
    "            else:\n",
    "                x0 = data.loc[index - 2, [f + '_x', f + '_y', f + '_z']].to_numpy()\n",
    "                x1 = data.loc[index - 1, [f + '_x', f + '_y', f + '_z']].to_numpy()\n",
    "                x2 = row.loc[[f + '_x', f + '_y', f + '_z']].to_numpy()\n",
    "                dt = (row['relative_time'] - data.loc[index - 2, 'relative_time']) / 2.\n",
    "                acc = (x2 - 2*x1 + x0) / (dt *  dt)\n",
    "            acc_mag = np.linalg.norm(acc)\n",
    "            frame_vector = np.hstack((vel, vel_mag, acc, acc_mag))\n",
    "            row_data = np.hstack((row_data, frame_vector))\n",
    "        derived_data = insert_row(derived_data, row_data, header)\n",
    "        timeseries[i] = pd.concat([data, derived_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute normed and rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_frames = list(itertools.chain.from_iterable((f + '_vel_mag', f + '_acc_mag') for f in frame_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_velocities = []\n",
    "rolling_average_velocities = []\n",
    "\n",
    "for data in timeseries:\n",
    "    vel_acc_data = data.loc[:, vel_frames]\n",
    "    normed_velocities.append((vel_acc_data - vel_acc_data.min()) / (vel_acc_data.max() - vel_acc_data.min()))\n",
    "    rolling_average_velocities.append(normed_velocities[-1].rolling(window=window_size).mean().iloc[window_size-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "normed_velocities[idx].plot.line()\n",
    "rolling_average_velocities[idx].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
