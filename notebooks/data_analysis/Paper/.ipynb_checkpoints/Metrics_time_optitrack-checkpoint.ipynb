{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a3565bfb-825f-4818-a792-ccead1509051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surgeon_recording.reader import Reader\n",
    "from surgeon_recording.functions_metrics import F_metrics\n",
    "\n",
    "from os.path import join\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import scipy.interpolate as inter\n",
    "from pyquaternion import Quaternion\n",
    "from numpy import linalg as LA\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import subplots\n",
    "import matplotlib.lines\n",
    "from scipy import integrate\n",
    "import math \n",
    "\n",
    "reader = Reader()\n",
    "f_metrics = F_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9e7e8-66c1-4f89-b222-cee5e754bfd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "87300285-3cc1-47c6-ac0b-dd05f9761f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data_folder = '/home/anaelle/git/surgeon_recording/data_paper'                 \n",
    "#TO BE ADAPTED (go to the data folder)\n",
    "\n",
    "subject_list_tot = ['S1','S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12']\n",
    "subject_list = ['S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S12']           \n",
    "#Remove S1 for optitrack because bad tracking\n",
    "\n",
    "segment_list = ['500','510','530','540','541','560']\n",
    "# segments: \n",
    "#500 = 1st insertion (1 in paper)\n",
    "#510 = 2nd insertion (2 in paper)\n",
    "#530 = pulling on thread (3 in paper)\n",
    "#540 = 1st knot (4)\n",
    "#541 = 2nd knot (5)\n",
    "#560 = whole task (not in paper)\n",
    "\n",
    "sensors = ['optitrack'] #only use optitrack data here\n",
    "\n",
    "# names of the tools in the csv files\n",
    "tools_tweezer = ['tweezer_x', 'tweezer_y', 'tweezer_z']\n",
    "tools_scissors = ['scissors_x', 'scissors_y', 'scissors_z'] \n",
    "tools_verif_holder = ['needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z']\n",
    "\n",
    "\n",
    "data_segments = {}\n",
    "mean_segments = {}\n",
    "\n",
    "run_list = {}\n",
    "headers = {}\n",
    "file_list = {}\n",
    "\n",
    "\n",
    "# List of run we take for analysis, for each subject\n",
    "# take three runs for each subject = max nb of runs where we have complete data (all sensors) for all subjects (need same nb of runs for the paper)\n",
    "run_list = {}\n",
    "for subject in subject_list:\n",
    "    run_list[subject] = {}\n",
    "\n",
    "run_list['S1'] = ['R1','R2','R3'] \n",
    "run_list['S2'] = ['R1','R3','R4']\n",
    "run_list['S3'] = ['R2','R3','R4']\n",
    "run_list['S4'] = ['R1','R3','R4']\n",
    "run_list['S5'] = ['R3','R4','R5']\n",
    "run_list['S6'] = ['R1','R3','R5']\n",
    "run_list['S7'] = ['R1','R3','R4']\n",
    "run_list['S8'] = ['R1','R3','R4']\n",
    "run_list['S9'] = ['R2','R3','R5']\n",
    "run_list['S10'] = ['R1','R2','R4']\n",
    "run_list['S11'] = ['R1','R3','R4']\n",
    "run_list['S12'] = ['R1','R2','R3']\n",
    "\n",
    "\n",
    "# Create structures\n",
    "for subject in subject_list_tot:\n",
    "    data_segments[subject] = {}\n",
    "    mean_segments[subject]= {}\n",
    "    file_list[subject] = {}\n",
    "        \n",
    "    for segment in segment_list:\n",
    "        data_segments[subject][segment]= {}\n",
    "        file_list[subject][segment] = {}\n",
    "        mean_segments[subject][segment]= {}\n",
    "                    \n",
    "        for run in run_list[subject]:\n",
    "            data_segments[subject][segment][run] = {}\n",
    "            mean_segments[subject][segment][run]= {}\n",
    "            file_list[subject][segment][run] = {}\n",
    "\n",
    "            for sensor in sensors:\n",
    "                data_segments[subject][segment][run][sensor]= {}\n",
    "                mean_segments[subject][segment][run][sensor]= []\n",
    "                file_list[subject][segment][run][sensor] = []\n",
    "\n",
    "\n",
    "for sensor in sensors:\n",
    "    headers[sensor] = []\n",
    "    \n",
    "\n",
    "# put all the data in the data_segments variable, with subject, segment, run, sensor and tool or time as keys\n",
    "for subject in subject_list_tot:   \n",
    "        for sensor in sensors:\n",
    "            for segment in segment_list:\n",
    "                for run in run_list[subject]:\n",
    "                    data_folder = join('..', 'data_paper','OPTITRACK', subject, run )\n",
    "                    file_list[subject][segment][run][sensor] = join(data_folder, 'segment_nb_' + segment + '_' + sensor +'.csv')\n",
    "\n",
    "                    file = open(file_list[subject][segment][run][sensor])\n",
    "                    reader = csv.DictReader(file)\n",
    "                    headers[sensor] = reader.fieldnames\n",
    "\n",
    "                    tools = headers[sensor][3:-1]\n",
    "\n",
    "                    data = pd.read_csv(file_list[subject][segment][run][sensor])\n",
    "\n",
    "                    for tool in tools:\n",
    "                        data_segments[subject][segment][run][sensor][tool]= data[tool]\n",
    "                        data_segments[subject][segment][run][sensor]['rel_time'] = data['relative_time']              \n",
    "                    \n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad932e1b-24f4-4b28-83f1-a151c1efea17",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DATA OPTITRACK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a2c87-b4d2-4003-9bd1-29685ee6d881",
   "metadata": {
    "tags": []
   },
   "source": [
    "## REVIEW DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93501d60-9113-45f8-ab6b-0eb4ac5fccf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove 0 values (loss of tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "31901b63-9d55-4f2f-8665-72eea577e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segment_list_optitrack = ['500','510','530','540','541']\n",
    "segment_new_optitrack = ['2','3','4','5','6']               #reference of segments from PDM report, changed to (1,2,3,4,5) in the paper\n",
    "\n",
    "\n",
    "\n",
    "# with scissors\n",
    "#tools = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'scissors_x', 'scissors_y', 'scissors_z', 'scissors_qx', 'scissors_qy', 'scissors_qz', 'scissors_qw', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "#without the scissors (scissors not in the analysis here)\n",
    "tools = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "#separate position values and quaternions to make vectors\n",
    "tools_position = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z']\n",
    "tools_quaternions = ['tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "# data structure\n",
    "sensor = 'optitrack'\n",
    "optitrack_segment_subject = {}\n",
    "optitrack_non_zero= {}\n",
    "optitrack_non_zero_time = {}\n",
    "for subject in subject_list:   \n",
    "    optitrack_segment_subject[subject] = {}\n",
    "    optitrack_non_zero[subject]= {}\n",
    "    optitrack_non_zero_time[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        optitrack_segment_subject[subject][segment] = {}\n",
    "        optitrack_non_zero[subject][segment]= {}\n",
    "        optitrack_non_zero_time[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            optitrack_segment_subject[subject][segment][run] = {}\n",
    "            optitrack_non_zero[subject][segment][run]= {}\n",
    "            optitrack_non_zero_time[subject][segment][run] = {}\n",
    "            for tool in tools:  \n",
    "                optitrack_segment_subject[subject][segment][run][tool]=[]\n",
    "                optitrack_non_zero[subject][segment][run][tool] = []\n",
    "                optitrack_non_zero_time[subject][segment][run] [tool] = []\n",
    "\n",
    "\n",
    "#remove 0 values from loss of tracking and get corresponding time values to keep the time-data correspondance\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools:\n",
    "                time_current = data_segments[subject][segment][run][sensor]['rel_time']        \n",
    "                data_current = data_segments[subject][segment][run][sensor][tool]\n",
    "                \n",
    "                optitrack_segment_subject[subject][segment][run][tool] = data_current #data with the zeroes\n",
    "                optitrack_non_zero[subject][segment][run][tool] = data_current[data_current != 0] # data without zeroes\n",
    "                optitrack_non_zero_time[subject][segment][run][tool] = time_current[data_current != 0] #time without the zero data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff01696-09a0-4d56-be78-275aabc643ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpolation data top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "44c8a6fc-c840-4144-9f84-f753dbb23965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation of the data obtained from the tracking (top of the tool)\n",
    "# interpolation allows to fill the gaps made by removing the zero values \n",
    "# + allows to get a clean frequency of 120 Hz for derivation (fill the gaps of missing data points if existing)\n",
    "\n",
    "#data structure\n",
    "Interpole = {}\n",
    "time_vector_interp = {}\n",
    "interpolated_data = {}\n",
    "for subject in subject_list:   \n",
    "    Interpole[subject] = {}\n",
    "    time_vector_interp[subject]= {}\n",
    "    interpolated_data[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        Interpole[subject][segment] = {}\n",
    "        time_vector_interp[subject][segment]= {}\n",
    "        interpolated_data[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            Interpole[subject][segment][run] = {}\n",
    "            time_vector_interp[subject][segment][run]= {}\n",
    "            interpolated_data[subject][segment][run] = {}\n",
    "            for tool in tools:\n",
    "                Interpole[subject][segment][run][tool] = {}\n",
    "                time_vector_interp[subject][segment][run][tool]= {}\n",
    "                interpolated_data[subject][segment][run][tool] = {}\n",
    "\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools:\n",
    "                data = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                time = np.array(optitrack_non_zero_time[subject][segment][run][tool])\n",
    "                #create interpolation function y=f(x) based on the known points\n",
    "                Interpole[subject][segment][run][tool] = inter.interp1d(time, data ) \n",
    "                time_step = 1/120 #120Hz theoretical freqeuncy with optitrack \n",
    "                #time vector for interpolation\n",
    "                time_vector_interp[subject][segment][run][tool] = np.arange(time.min(),time.max()-time_step,time_step ) \n",
    "                # apply our inteprolation to the new time vector with the 120Hz frequency\n",
    "                interpolated_data[subject][segment][run][tool] = Interpole[subject][segment][run][tool](time_vector_interp[subject][segment][run][tool])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa82620d-b11e-4ec6-a272-9d38c78ca47b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformation to have tip position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e0127cb9-3355-460f-a327-1fd41d78a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded tool and tooltip rotation and position in form [qw,qx,qy,qz,tx,ty,tz,1] from the calibration recording\n",
    "# to get the geometric transformation from tool to tip\n",
    "# Quaternion((w, x, y, z)) function: Creates a unit quaternion 1 + 0i + 0j + 0k\n",
    "\n",
    "tools_name = [\"tweezer\", \"needle_holder2\"]\n",
    "tools_transf = {\n",
    "    \"tweezer\": {\n",
    "        # mean data from the fixed marker at the top during the calibration recording used for the tip measurement (tool stays fixed):\n",
    "        \"marker_tip\": [-0.14002110139417,0.011598759188847,0.914789185044361,-0.378701883396705,0.203922977186312,0.225921215462611,0.337081560202788,1], # TOP\n",
    "        # mean data from the fixed marker at the tip during the calibration recording used for the tip measurement (tool stays fixed):\n",
    "        \"tip\":  [-0.659606319391634,0.047673735107731,-0.082923699619772,-0.520023288973384,0.173957278833967,0.147784077313054,0.464396291508238,1]     # TIP\n",
    "        },\n",
    "\n",
    "    \"needle_holder2\":  {\n",
    "        \"marker_tip\": [-0.921827204331451,0.195545852165725,0.143764196798494,-0.302187299435028,0.181443717514124,0.300805392655367,0.335198482109228,1],\n",
    "        \"tip\":  [-0.864763969868174,-0.013123148775895,-0.07854127306968,-0.49579974858757,0.170293133709981,0.248165722222222,0.464240151600753,1]\n",
    "        }       \n",
    "}\n",
    "\n",
    "\n",
    "for tool in tools_name:    \n",
    "    marker_tip_quaternion = Quaternion(tools_transf[tool][\"marker_tip\"][:4])  #Return homogeneous rotation matrix from quaternion.\n",
    "    # = computes rotation matrix corresponding to the quaternions of the top\n",
    "    # ATTENTION: this function normalizes the quaternion to 1 \n",
    "    T_marker_tip_fixed = marker_tip_quaternion.transformation_matrix         # 4*4 matrix\n",
    "    \n",
    "    marker_tip_translation_vector = np.array((tools_transf[tool][\"marker_tip\"][-4:])) #Return matrix to translate by direction vector \n",
    "    # = compute the translation matrix corresponding to the position of the marker\n",
    "    T_marker_tip_fixed[:,-1] = marker_tip_translation_vector       # add translation part to the transformation matrix\n",
    "    #T_marker_tip_fixed = transformation matrix to go from the reference frame to the position of the top (o_T_top)\n",
    "        \n",
    "\n",
    "    tip_quaternion = Quaternion(tools_transf[tool][\"tip\"][:4]) #Rotation matrix of the tip, from the quaternions \n",
    "    #ATTENTION: normalise le quaternion a 1 donc pas exactemetn meme valeurs\n",
    "    T_tip = tip_quaternion.transformation_matrix\n",
    "  \n",
    "    tip_translation_vector = np.array((tools_transf[tool][\"tip\"][-4:])) #translation matrix for tip\n",
    "    T_tip[:,-1] = tip_translation_vector       \n",
    "    #T_tip = transformation matrix to go from the reference frame to the position of the tip (o_T_tip)\n",
    "    \n",
    "    T_marker_tip_fixed_inv = LA.inv(T_marker_tip_fixed)  #inverse of the transf. matrix: o_T_top^-1 = top_T_o\n",
    "    \n",
    "    ## ORIGIN TO TIP, BASED ON MARKER POSITION\n",
    "    # transformation matrix to obtain position of the tip based on the position of the top:\n",
    "    T_marker_tip = T_marker_tip_fixed_inv.dot(T_tip) #Matrice top_T_tip = top_T_o.o_T_tip\n",
    "    q_marker_tip = Quaternion(matrix = T_marker_tip) # quaternions of the matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "64635802-89db-490b-8b16-92efb0d7e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put them in the format to compute oTmarker\n",
    "\n",
    "# data structure\n",
    "translation_vector = {}\n",
    "quaternion_vector = {}\n",
    "position_vector_tip = {}\n",
    "position_vector_top = {}\n",
    "vector_top_to_tip = {}\n",
    "pos_x = {}\n",
    "pos_y = {}\n",
    "pos_z = {}\n",
    "pos_x_tip = {}\n",
    "pos_y_tip = {}\n",
    "pos_z_tip = {}\n",
    "pos_x_tip_outlier = {}\n",
    "pos_y_tip_outlier = {}\n",
    "pos_z_tip_outlier = {} \n",
    "for subject in subject_list:\n",
    "    translation_vector[subject] = {}\n",
    "    quaternion_vector[subject] = {}\n",
    "    position_vector_tip[subject] = {}\n",
    "    position_vector_top[subject] = {}\n",
    "    vector_top_to_tip[subject] = {}\n",
    "    pos_x[subject]= {}\n",
    "    pos_y[subject]= {}\n",
    "    pos_z[subject]= {}\n",
    "    pos_x_tip[subject]= {}\n",
    "    pos_y_tip[subject]= {}\n",
    "    pos_z_tip[subject]= {}\n",
    "    pos_x_tip_outlier[subject]= {}\n",
    "    pos_y_tip_outlier[subject]= {}\n",
    "    pos_z_tip_outlier[subject]= {}\n",
    "    for segment in segment_list:\n",
    "        translation_vector[subject][segment] = {}\n",
    "        quaternion_vector[subject][segment] = {}\n",
    "        position_vector_tip[subject][segment] = {}\n",
    "        position_vector_top[subject][segment] = {}\n",
    "        vector_top_to_tip[subject][segment] = {}\n",
    "        pos_x[subject][segment]= {}\n",
    "        pos_y[subject][segment]= {}\n",
    "        pos_z[subject][segment]= {}\n",
    "        pos_x_tip[subject][segment]= {}\n",
    "        pos_y_tip[subject][segment]= {}\n",
    "        pos_z_tip[subject][segment]= {}        \n",
    "        pos_x_tip_outlier[subject][segment]= {}\n",
    "        pos_y_tip_outlier[subject][segment]= {}\n",
    "        pos_z_tip_outlier[subject][segment]= {}         \n",
    "        for run in run_list[subject]:\n",
    "            translation_vector[subject][segment][run] = {}\n",
    "            quaternion_vector[subject][segment][run] = {}\n",
    "            position_vector_tip[subject][segment][run] = {}\n",
    "            position_vector_top[subject][segment][run] = {}\n",
    "            vector_top_to_tip[subject][segment][run] = {}\n",
    "            pos_x[subject][segment][run]= {}\n",
    "            pos_y[subject][segment][run]= {}\n",
    "            pos_z[subject][segment][run]= {}\n",
    "            pos_x_tip[subject][segment][run]= {}\n",
    "            pos_y_tip[subject][segment][run]= {}\n",
    "            pos_z_tip[subject][segment][run]= {}\n",
    "            pos_x_tip_outlier[subject][segment][run]= {}\n",
    "            pos_y_tip_outlier[subject][segment][run]= {}\n",
    "            pos_z_tip_outlier[subject][segment][run]= {}            \n",
    "            for tool in tools_name:\n",
    "                translation_vector[subject][segment][run][tool] = []\n",
    "                quaternion_vector[subject][segment][run][tool]  = []\n",
    "                position_vector_tip[subject][segment][run][tool]  = []\n",
    "                position_vector_top[subject][segment][run][tool]  = []\n",
    "                vector_top_to_tip[subject][segment][run][tool] = []\n",
    "                pos_x[subject][segment][run][tool] = []\n",
    "                pos_y[subject][segment][run][tool] = []\n",
    "                pos_z[subject][segment][run][tool] = []\n",
    "                pos_x_tip[subject][segment][run][tool] = []\n",
    "                pos_y_tip[subject][segment][run][tool] = []\n",
    "                pos_z_tip[subject][segment][run][tool] = []\n",
    "                pos_x_tip_outlier[subject][segment][run][tool] = []\n",
    "                pos_y_tip_outlier[subject][segment][run][tool] = []\n",
    "                pos_z_tip_outlier[subject][segment][run][tool] = []\n",
    "                \n",
    "# put the recorder position values and quaternions in vector representation [x,y,z],[qw,qx,qy,qz]:\n",
    "# can use the interpolated data if we are interested in the top values\n",
    "# here we use the raw data without the 0 values as we will make the transformation to get the tip values from raw values, and interpolate afterwards\n",
    "                #with interpolated data\n",
    "                #for i in range(len(interpolated_data[subject][segment][run][tool + '_' + 'x'])):\n",
    "                #with raw data (without 0 values)\n",
    "                for i in range(len(optitrack_non_zero[subject][segment][run][tool + '_' + 'x'])):\n",
    "                    \n",
    "                    # with interpolated data\n",
    "                    #current_trans_vect = np.array([np.array(interpolated_data[subject][segment][run][tool + '_' + 'x'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'y'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'z'])[i],1])\n",
    "                    \n",
    "                    #with raw data (without 0 values)\n",
    "                    current_trans_vect = np.array([np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'x'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'y'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'z'])[i],1])\n",
    "                                       \n",
    "                    #with interpolated data:\n",
    "                    #current_quaternion = np.array([np.array(interpolated_data[subject][segment][run][tool + '_' + 'qw'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qx'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qy'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qz'])[i]])\n",
    "                    \n",
    "                    #with raw data\n",
    "                    current_quaternion = np.array([np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qw'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qx'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qy'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qz'])[i]])\n",
    "                    \n",
    "                    #add at each iteration the position vectors and quaternions = get for each timestamp 1 position vector and 1 quaternion\n",
    "                    q = Quaternion(current_quaternion)\n",
    "                    quaternion_vector[subject][segment][run][tool].append(current_quaternion)\n",
    "                    translation_vector[subject][segment][run][tool].append(current_trans_vect)\n",
    "                   \n",
    "                    # get the transformation matrix o_T_top for each data points (from rotation and translation)\n",
    "                    T_marker = q.transformation_matrix        \n",
    "                    T_marker[:,-1] = current_trans_vect\n",
    "                    \n",
    "                    # get corresponding tip position using the geometrical transformation computed above\n",
    "                    tmp_pos_tip = T_marker.dot(T_marker_tip)[0:3,-1] \n",
    "                    tmp_pos_top = current_trans_vect[0:3]\n",
    "                    # store position vectors\n",
    "                    position_vector_tip[subject][segment][run][tool].append(tmp_pos_tip)\n",
    "                    position_vector_top[subject][segment][run][tool].append(tmp_pos_top)\n",
    "                    \n",
    "                    # vector corresponding to the translation from top to tip at frame of reference,  could be used for angles metrics\n",
    "                    tmp_top_to_tip = np.subtract(tmp_pos_tip, tmp_pos_top) \n",
    "                    vector_top_to_tip[subject][segment][run][tool].append(tmp_top_to_tip) #format x,y,z\n",
    "                \n",
    "                # separate values for x,y,z positions again\n",
    "                pos_x[subject][segment][run][tool] = [item[0] for item in position_vector_top[subject][segment][run][tool]]  # x top position\n",
    "                pos_y[subject][segment][run][tool] = [item[1] for item in position_vector_top[subject][segment][run][tool]]  # y top position\n",
    "                pos_z[subject][segment][run][tool] = [item[2] for item in position_vector_top[subject][segment][run][tool]]  # z top position\n",
    "                \n",
    "                pos_x_tip[subject][segment][run][tool] = [item[0] for item in position_vector_tip[subject][segment][run][tool]]  # tip x position\n",
    "                pos_y_tip[subject][segment][run][tool] = [item[1] for item in position_vector_tip[subject][segment][run][tool]]  # tip y position\n",
    "                pos_z_tip[subject][segment][run][tool] = [item[2] for item in position_vector_tip[subject][segment][run][tool]]  # tip z position\n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73a858e-2f12-457d-a87d-008af69153c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### REMOVE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d1ff1f0b-8bd4-421d-8442-acfa9fb84c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when plotting the data: found outliers = wrong data points (discontinuous position tracking)\n",
    "# --> remove manually the outliers from the data for the tip \n",
    "\n",
    "time_pos_x_tip_outlier={}\n",
    "time_pos_y_tip_outlier={}\n",
    "time_pos_z_tip_outlier={}\n",
    "for subject in subject_list:\n",
    "    time_pos_x_tip_outlier[subject]={}\n",
    "    time_pos_y_tip_outlier[subject]={}\n",
    "    time_pos_z_tip_outlier[subject]={}\n",
    "    for segment in segment_list:\n",
    "        time_pos_x_tip_outlier[subject][segment]={}\n",
    "        time_pos_y_tip_outlier[subject][segment]={}\n",
    "        time_pos_z_tip_outlier[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            time_pos_x_tip_outlier[subject][segment][run]={}\n",
    "            time_pos_y_tip_outlier[subject][segment][run]={}\n",
    "            time_pos_z_tip_outlier[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time_pos_x_tip_outlier[subject][segment][run][tool] = []\n",
    "                time_pos_y_tip_outlier[subject][segment][run][tool] = []\n",
    "                time_pos_z_tip_outlier[subject][segment][run][tool] = []\n",
    "\n",
    "\n",
    "#for y: a threshold can be used to remove all outliers\n",
    "for subject in subject_list:\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                pos_x_tip_outlier[subject][segment][run][tool] = pd.DataFrame(pos_x_tip[subject][segment][run][tool])\n",
    "                pos_z_tip_outlier[subject][segment][run][tool] = pd.DataFrame(pos_z_tip[subject][segment][run][tool])\n",
    "                time_pos_x_tip_outlier[subject][segment][run][tool] = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'x']))\n",
    "                time_pos_z_tip_outlier[subject][segment][run][tool] = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'z']))\n",
    "                \n",
    "                data_y = pd.DataFrame(pos_y_tip[subject][segment][run][tool])\n",
    "                pos_y_tip_outlier[subject][segment][run][tool] = data_y[data_y<0.15] #get data without outliers\n",
    "                time = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'y']))\n",
    "                time_pos_y_tip_outlier[subject][segment][run][tool] = time[data_y<0.2] # get corresponding timestamps (remove timestamps of outliers)\n",
    "\n",
    "\n",
    "#for x: specific values for the runs\n",
    "for segment in ['500', '560']:\n",
    "    data_x = pos_x_tip_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_pos_x_tip_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    pos_x_tip_outlier['S2'][segment]['R3']['needle_holder2'] = data_x[data_x<0.6]\n",
    "    time_pos_x_tip_outlier['S2'][segment]['R3'][tool] = time_x[data_x<0.6]\n",
    "\n",
    "for segment in ['510', '560']:\n",
    "    data_x = pos_x_tip_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_pos_x_tip_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    pos_x_tip_outlier['S9'][segment]['R3']['needle_holder2'] = data_x[data_x<0.4]\n",
    "    time_pos_x_tip_outlier['S9'][segment]['R3']['needle_holder2'] = time_x[data_x<0.4]\n",
    "    \n",
    "for segment in ['540', '560']:\n",
    "    data_x = pos_x_tip_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_pos_x_tip_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    pos_x_tip_outlier['S12'][segment]['R3']['needle_holder2'] = data_x[data_x<0.5]\n",
    "    time_pos_x_tip_outlier['S12'][segment]['R3']['needle_holder2'] = time_x[data_x<0.5]\n",
    "    \n",
    "for segment in ['510']:\n",
    "    data_x = pos_x_tip_outlier['S9'][segment]['R2']['tweezer']\n",
    "    time_x = time_pos_x_tip_outlier['S9'][segment]['R2']['tweezer']\n",
    "    pos_x_tip_outlier['S9'][segment]['R2']['tweezer'] = data_x[data_x>0.42]\n",
    "    time_pos_x_tip_outlier['S9'][segment]['R2']['tweezer'] = time_x[data_x>0.42]\n",
    "\n",
    "for segment in ['510', '560']:\n",
    "    data_x = pos_x_tip_outlier['S9'][segment]['R3']['tweezer']\n",
    "    time_x = time_pos_x_tip_outlier['S9'][segment]['R3']['tweezer']\n",
    "    pos_x_tip_outlier['S9'][segment]['R3']['tweezer'] = data_x[data_x>0.28]\n",
    "    time_pos_x_tip_outlier['S9'][segment]['R3']['tweezer'] = time_x[data_x>0.28] \n",
    "    \n",
    "for segment in ['560']:\n",
    "    data_x = pos_x_tip_outlier['S9'][segment]['R5']['tweezer']\n",
    "    time_x = time_pos_x_tip_outlier['S9'][segment]['R5']['tweezer']\n",
    "    pos_x_tip_outlier['S9'][segment]['R5']['tweezer'] = data_x[data_x>0.28]\n",
    "    time_pos_x_tip_outlier['S9'][segment]['R5']['tweezer'] = time_x[data_x>0.28] \n",
    "    \n",
    "# for z: specific values for the runs\n",
    "for segment in ['510', '560']:\n",
    "    data_z = pos_z_tip_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    time_z = time_pos_z_tip_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    pos_z_tip_outlier['S9'][segment]['R3']['needle_holder2'] = data_z[data_z>0.02]\n",
    "    time_pos_z_tip_outlier['S9'][segment]['R3'][tool] = time_z[data_z>0.02]\n",
    "\n",
    "for segment in ['540', '560']:\n",
    "    data_z = pos_z_tip_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    time_z = time_pos_z_tip_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    pos_z_tip_outlier['S12'][segment]['R3']['needle_holder2'] = data_z[data_z>0.05]\n",
    "    time_pos_z_tip_outlier['S12'][segment]['R3'][tool] = time_z[data_z>0.05]\n",
    "    \n",
    "for segment in ['540', '560']:\n",
    "    data_z = pos_z_tip_outlier['S2'][segment]['R1']['tweezer']\n",
    "    time_z = time_pos_z_tip_outlier['S2'][segment]['R1']['tweezer']\n",
    "    pos_z_tip_outlier['S2'][segment]['R1']['tweezer'] = data_z[data_z>0.18]\n",
    "    time_pos_z_tip_outlier['S2'][segment]['R1']['tweezer'] = time_z[data_z>0.18] \n",
    "    \n",
    "for segment in ['530', '560']:\n",
    "    data_z = pos_z_tip_outlier['S7'][segment]['R1']['tweezer']\n",
    "    time_z = time_pos_z_tip_outlier['S7'][segment]['R1']['tweezer']\n",
    "    pos_z_tip_outlier['S7'][segment]['R1']['tweezer'] = data_z[data_z>0.07]\n",
    "    time_pos_z_tip_outlier['S7'][segment]['R1']['tweezer'] = time_z[data_z>0.07] \n",
    "    \n",
    "for segment in ['500']:\n",
    "    data_z = pos_z_tip_outlier['S8'][segment]['R3']['tweezer']\n",
    "    time_z = time_pos_z_tip_outlier['S8'][segment]['R3']['tweezer']\n",
    "    pos_z_tip_outlier['S8'][segment]['R3']['tweezer'] = data_z[data_z>0.07]\n",
    "    time_pos_z_tip_outlier['S8'][segment]['R3']['tweezer'] = time_z[data_z>0.07] \n",
    "    \n",
    "for segment in ['510', '560']:\n",
    "    data_z = pos_z_tip_outlier['S9'][segment]['R3']['tweezer']\n",
    "    time_z = time_pos_z_tip_outlier['S9'][segment]['R3']['tweezer']\n",
    "    pos_z_tip_outlier['S9'][segment]['R3']['tweezer'] = data_z[data_z>0.18]\n",
    "    time_pos_z_tip_outlier['S9'][segment]['R3']['tweezer'] = time_z[data_z>0.18] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7da457-7325-4ca9-916d-3e4d0b2dce67",
   "metadata": {
    "tags": []
   },
   "source": [
    "### interpolation data tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7954dcec-fccc-4c00-962c-0e596a037217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation of the data obtained for the tip of the tool, to get a clean frequency of 120Hz and fill the gaps of the removed outliers\n",
    "\n",
    "# data structure\n",
    "interpolated_data_tip_y = {}\n",
    "interpolated_data_tip_x = {}\n",
    "interpolated_data_tip_z = {}\n",
    "time_vector_interp_new_x = {}\n",
    "time_vector_interp_new_y= {}\n",
    "time_vector_interp_new_z = {}\n",
    "for subject in subject_list:   \n",
    "    interpolated_data_tip_y[subject] = {}\n",
    "    interpolated_data_tip_x[subject] = {}\n",
    "    interpolated_data_tip_z[subject] = {}\n",
    "    time_vector_interp_new_x[subject] = {}\n",
    "    time_vector_interp_new_y[subject] ={}\n",
    "    time_vector_interp_new_z[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        interpolated_data_tip_y[subject][segment] = {}\n",
    "        interpolated_data_tip_x[subject][segment] = {}\n",
    "        interpolated_data_tip_z[subject][segment] = {}\n",
    "        time_vector_interp_new_x[subject][segment] = {}\n",
    "        time_vector_interp_new_y[subject][segment] ={}\n",
    "        time_vector_interp_new_z[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            interpolated_data_tip_y[subject][segment][run] = {}\n",
    "            interpolated_data_tip_x[subject][segment][run] = {}\n",
    "            interpolated_data_tip_z[subject][segment][run] = {}\n",
    "            time_vector_interp_new_x[subject][segment][run] = {}\n",
    "            time_vector_interp_new_y[subject][segment][run] ={}\n",
    "            time_vector_interp_new_z[subject][segment][run] = {}\n",
    "            for tool in tools_name:\n",
    "                interpolated_data_tip_x[subject][segment][run][tool] = {}\n",
    "                interpolated_data_tip_y[subject][segment][run][tool] = {}\n",
    "                interpolated_data_tip_z[subject][segment][run][tool] = {}\n",
    "                time_vector_interp_new_x[subject][segment][run][tool] = {}\n",
    "                time_vector_interp_new_y[subject][segment][run][tool] ={}\n",
    "                time_vector_interp_new_z[subject][segment][run][tool] = {}\n",
    "\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                data_y = list(pos_y_tip_outlier[subject][segment][run][tool][0])\n",
    "                data_x = list(pos_x_tip_outlier[subject][segment][run][tool][0])\n",
    "                data_z = list(pos_z_tip_outlier[subject][segment][run][tool][0])\n",
    "                \n",
    "                time = np.array(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'x'])\n",
    "                #interpolation functions\n",
    "                Interpole_y = inter.interp1d(list(time_pos_y_tip_outlier[subject][segment][run][tool][0]), list(data_y),bounds_error=False, fill_value='extrapolate') \n",
    "                Interpole_x = inter.interp1d(list(time_pos_x_tip_outlier[subject][segment][run][tool][0]), list(data_x),bounds_error=False,fill_value='extrapolate')\n",
    "                Interpole_z = inter.interp1d(list(time_pos_z_tip_outlier[subject][segment][run][tool][0]), list(data_z),bounds_error=False, fill_value='extrapolate')\n",
    "                \n",
    "                #new time vector\n",
    "                time_step = 1/120\n",
    "                time_vector = np.arange(time.min(),time.max()-time_step,time_step )\n",
    "                #interpolation using the functions and the new time vector\n",
    "                interpolated_data_tip_x[subject][segment][run][tool] = Interpole_x(time_vector)\n",
    "                interpolated_data_tip_y[subject][segment][run][tool] = Interpole_y(time_vector)\n",
    "                interpolated_data_tip_z[subject][segment][run][tool] = Interpole_z(time_vector)\n",
    "                \n",
    "                ##remove NAN values\n",
    "                ##not used here, the NAN values are removed later to keep same number of data in the 3 directions for now\n",
    "                #tmpx = Interpole_x(time_vector)\n",
    "                #tmpy = Interpole_y(time_vector)\n",
    "                #tmpz = Interpole_z(time_vector)\n",
    "                \n",
    "                #interpolated_data_tip_x[subject][segment][run][tool] = [o for o in tmpx if np.isnan(o) == False]\n",
    "                #interpolated_data_tip_y[subject][segment][run][tool] = [o for o in tmpy if np.isnan(o) == False]\n",
    "                #interpolated_data_tip_z[subject][segment][run][tool] = [o for o in tmpz if np.isnan(o) == False]\n",
    "                \n",
    "                ##remove corresponding time values\n",
    "                #bool_x = np.isnan(tmpx)\n",
    "                #bool_y = np.isnan(tmpy)\n",
    "                #bool_z = np.isnan(tmpz)\n",
    "                #inv_bool_x = [not elem for elem in bool_x]\n",
    "                #inv_bool_y = [not elem for elem in bool_y]\n",
    "                #inv_bool_z = [not elem for elem in bool_z]\n",
    "                #time_vector_interp_new_x[subject][segment][run][tool] = time_vector_interp[subject][segment][run][tool+'_x'][inv_bool_x] \n",
    "                #time_vector_interp_new_y[subject][segment][run][tool] = time_vector_interp[subject][segment][run][tool+'_x'][inv_bool_y]\n",
    "                #time_vector_interp_new_z[subject][segment][run][tool] = time_vector_interp[subject][segment][run][tool+'_x'][inv_bool_z]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7ab76-9e02-4417-86e2-1685feca1de2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b5bd28ae-0838-4143-b486-b21767344954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st filtering of the data to smooth the data\n",
    "pos_x_tip_filter = {}\n",
    "pos_y_tip_filter = {}\n",
    "pos_z_tip_filter = {} \n",
    "for subject in subject_list:\n",
    "    pos_x_tip_filter[subject]= {}\n",
    "    pos_y_tip_filter[subject]= {}\n",
    "    pos_z_tip_filter[subject]= {}\n",
    "    for segment in segment_list:     \n",
    "        pos_x_tip_filter[subject][segment]= {}\n",
    "        pos_y_tip_filter[subject][segment]= {}\n",
    "        pos_z_tip_filter[subject][segment]= {}         \n",
    "        for run in run_list[subject]:\n",
    "            pos_x_tip_filter[subject][segment][run]= {}\n",
    "            pos_y_tip_filter[subject][segment][run]= {}\n",
    "            pos_z_tip_filter[subject][segment][run]= {}            \n",
    "            for tool in tools_name:\n",
    "                pos_x_tip_filter[subject][segment][run][tool] = []\n",
    "                pos_y_tip_filter[subject][segment][run][tool] = []\n",
    "                pos_z_tip_filter[subject][segment][run][tool] = []              \n",
    "\n",
    "\n",
    "                pos_x_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_data_tip_x[subject][segment][run][tool] , size=14)\n",
    "                pos_y_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_data_tip_y[subject][segment][run][tool] , size=14, footprint=None, output=None, mode='reflect', cval=0.0, origin=0)\n",
    "                pos_z_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_data_tip_z[subject][segment][run][tool] , size=14, footprint=None, output=None, mode='reflect', cval=0.0, origin=0)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a3e66c-e4a7-4fea-a6d2-38bc00b5c202",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Derivative estimator (2nd filter and derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "59d43a57-6564-49fd-892d-6c1a261b8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the derivative using the Savitzky-Golay method (for filtering and deriving)\n",
    "\n",
    "#data structure\n",
    "speed_x_tip_estimator= {}\n",
    "speed_y_tip_estimator = {}\n",
    "speed_z_tip_estimator = {} \n",
    "acc_x_tip_estimator= {}\n",
    "acc_y_tip_estimator = {}\n",
    "acc_z_tip_estimator = {} \n",
    "jerk_x_tip_estimator= {}\n",
    "jerk_y_tip_estimator = {}\n",
    "jerk_z_tip_estimator = {} \n",
    "speed_x_tip = {} \n",
    "speed_y_tip = {} \n",
    "speed_z_tip = {} \n",
    "acc_x_tip= {}\n",
    "acc_y_tip = {}\n",
    "acc_z_tip = {} \n",
    "jerk_x_tip= {}\n",
    "jerk_y_tip = {}\n",
    "jerk_z_tip = {} \n",
    "for subject in subject_list:\n",
    "    speed_x_tip_estimator[subject]= {}\n",
    "    speed_y_tip_estimator[subject]= {}\n",
    "    speed_z_tip_estimator [subject]= {}\n",
    "    acc_x_tip_estimator[subject]= {}\n",
    "    acc_y_tip_estimator[subject]= {}\n",
    "    acc_z_tip_estimator [subject]= {}\n",
    "    jerk_x_tip_estimator[subject]= {}\n",
    "    jerk_y_tip_estimator[subject]= {}\n",
    "    jerk_z_tip_estimator [subject]= {}\n",
    "    speed_x_tip[subject]= {}\n",
    "    speed_y_tip[subject]= {}\n",
    "    speed_z_tip[subject]= {}\n",
    "    acc_x_tip[subject]= {}\n",
    "    acc_y_tip[subject]= {}\n",
    "    acc_z_tip[subject]= {}\n",
    "    jerk_x_tip[subject]= {}\n",
    "    jerk_y_tip[subject]= {}\n",
    "    jerk_z_tip[subject]= {}\n",
    "    for segment in segment_list:     \n",
    "        speed_x_tip_estimator[subject][segment]= {}\n",
    "        speed_y_tip_estimator[subject][segment]= {}\n",
    "        speed_z_tip_estimator [subject][segment]= {}      \n",
    "        acc_x_tip_estimator[subject][segment]= {}\n",
    "        acc_y_tip_estimator[subject][segment]= {}\n",
    "        acc_z_tip_estimator [subject][segment]= {}   \n",
    "        jerk_x_tip_estimator[subject][segment]= {}\n",
    "        jerk_y_tip_estimator[subject][segment]= {}\n",
    "        jerk_z_tip_estimator [subject][segment]= {}  \n",
    "        speed_x_tip[subject][segment]= {}  \n",
    "        speed_y_tip[subject][segment]= {} \n",
    "        speed_z_tip[subject][segment]= {} \n",
    "        acc_x_tip[subject][segment]= {}\n",
    "        acc_y_tip[subject][segment]= {}\n",
    "        acc_z_tip[subject][segment]= {}   \n",
    "        jerk_x_tip[subject][segment]= {}\n",
    "        jerk_y_tip[subject][segment]= {}\n",
    "        jerk_z_tip[subject][segment]= {}  \n",
    "        for run in run_list[subject]:\n",
    "            speed_x_tip_estimator[subject][segment][run]= {}\n",
    "            speed_y_tip_estimator[subject][segment][run]= {}\n",
    "            speed_z_tip_estimator [subject][segment][run]= {}\n",
    "            acc_x_tip_estimator[subject][segment][run]= {}\n",
    "            acc_y_tip_estimator[subject][segment][run]= {}\n",
    "            acc_z_tip_estimator [subject][segment][run]= {}  \n",
    "            jerk_x_tip_estimator[subject][segment][run]= {}\n",
    "            jerk_y_tip_estimator[subject][segment][run]= {}\n",
    "            jerk_z_tip_estimator [subject][segment][run]= {}  \n",
    "            speed_x_tip [subject][segment][run]= {}  \n",
    "            speed_y_tip [subject][segment][run]= {}\n",
    "            speed_z_tip [subject][segment][run]= {}\n",
    "            acc_x_tip[subject][segment][run]= {}\n",
    "            acc_y_tip[subject][segment][run]= {}\n",
    "            acc_z_tip[subject][segment][run]= {}  \n",
    "            jerk_x_tip[subject][segment][run]= {}\n",
    "            jerk_y_tip[subject][segment][run]= {}\n",
    "            jerk_z_tip[subject][segment][run]= {}  \n",
    "            for tool in tools_name:\n",
    "                speed_x_tip_estimator[subject][segment][run][tool] = []\n",
    "                speed_y_tip_estimator[subject][segment][run][tool] = []\n",
    "                speed_z_tip_estimator [subject][segment][run][tool] = []     \n",
    "                acc_x_tip_estimator[subject][segment][run][tool] = []\n",
    "                acc_y_tip_estimator[subject][segment][run][tool] = []\n",
    "                acc_z_tip_estimator [subject][segment][run][tool] = []\n",
    "                jerk_x_tip_estimator[subject][segment][run][tool] = []\n",
    "                jerk_y_tip_estimator[subject][segment][run][tool] = []\n",
    "                jerk_z_tip_estimator [subject][segment][run][tool] = []\n",
    "                speed_x_tip [subject][segment][run][tool] = []\n",
    "                speed_y_tip [subject][segment][run][tool] = []\n",
    "                speed_z_tip [subject][segment][run][tool] = []\n",
    "                acc_x_tip[subject][segment][run][tool] = []\n",
    "                acc_y_tip[subject][segment][run][tool] = []\n",
    "                acc_z_tip[subject][segment][run][tool] = []\n",
    "                jerk_x_tip[subject][segment][run][tool] = []\n",
    "                jerk_y_tip[subject][segment][run][tool] = []\n",
    "                jerk_z_tip[subject][segment][run][tool] = []\n",
    "                \n",
    "                # filter and derivative parameters \n",
    "                window_length = 5\n",
    "                polyorder = 3\n",
    "                dt = 1/120\n",
    "                \n",
    "                #1st derivative (speed)\n",
    "                speed_x_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_x_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                speed_y_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_y_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                speed_z_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_z_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                \n",
    "                #2nd derivative (acc)\n",
    "                acc_x_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_x_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=2, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                acc_y_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_y_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=2, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                acc_z_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_z_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=2, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                \n",
    "                #3rd derivative (jerk)\n",
    "                jerk_x_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_x_tip_filter[subject][segment][run][tool], window_length,polyorder, deriv=3, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                jerk_y_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_y_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=3, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                jerk_z_tip_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(pos_z_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=3, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                \n",
    "                data_current_x = pos_x_tip_filter[subject][segment][run][tool]\n",
    "                data_current_y = pos_y_tip_filter[subject][segment][run][tool]\n",
    "                data_current_z = pos_z_tip_filter[subject][segment][run][tool]\n",
    "                time_current = time_vector_interp[subject][segment][run][tool+'_x'] #same time for the 3 directions (time used for interpolation)\n",
    "                \n",
    "                ## If different time vectors because the NAN values were removed:\n",
    "                #time_current_x = time_vector_interp_new_x[subject][segment][run][tool] \n",
    "                #time_current_y = time_vector_interp_new_y[subject][segment][run][tool]\n",
    "                #time_current_z = time_vector_interp_new_z[subject][segment][run][tool]\n",
    "                \n",
    "                # basic way to compute the derivative to check the correctness of the previous method\n",
    "                speed_x_tip[subject][segment][run][tool] = (data_current_x[1:-1] - data_current_x[0:-2])/(time_current[1:-1] - time_current[0:-2])\n",
    "                speed_y_tip[subject][segment][run][tool] = (data_current_y[1:-1] - data_current_y[0:-2])/(time_current[1:-1] - time_current[0:-2])\n",
    "                speed_z_tip[subject][segment][run][tool] = (data_current_z[1:-1] - data_current_z[0:-2])/(time_current[1:-1] - time_current[0:-2])\n",
    "                \n",
    "                ## compute the time points corresponding to the derivative\n",
    "                #diff_optitrack_time_x[subject][segment][run][tool] = ((time_current_x[1:]) + (time_current_x[0:-1]))/2\n",
    "                #diff_optitrack_time_y[subject][segment][run][tool] = ((time_current_y[1:]) + (time_current_y[0:-1]))/2\n",
    "                #diff_optitrack_time_z[subject][segment][run][tool] = ((time_current_z[1:]) + (time_current_z[0:-1]))/2\n",
    "                \n",
    "                acc_x_tip[subject][segment][run][tool] = np.diff(speed_x_tip[subject][segment][run][tool])/(1/120)\n",
    "                acc_y_tip[subject][segment][run][tool] = np.diff(speed_y_tip[subject][segment][run][tool])/(1/120)\n",
    "                acc_z_tip[subject][segment][run][tool] = np.diff(speed_z_tip[subject][segment][run][tool])/(1/120)\n",
    "                \n",
    "                jerk_x_tip[subject][segment][run][tool] = (acc_x_tip[subject][segment][run][tool][1:-1] - acc_x_tip[subject][segment][run][tool][0:-2])/(1/120)\n",
    "                jerk_y_tip[subject][segment][run][tool] = (acc_y_tip[subject][segment][run][tool][1:-1] - acc_y_tip[subject][segment][run][tool][0:-2])/(1/120)\n",
    "                jerk_z_tip[subject][segment][run][tool] = (acc_z_tip[subject][segment][run][tool][1:-1] - acc_z_tip[subject][segment][run][tool][0:-2])/(1/120)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc593e-37b1-4e8b-b3d0-f407e036622d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quaternions to euler angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07b79c8-3889-459b-9764-2a1f2cca43d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "edb01457-2ea5-43e9-992b-5da425c9d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert quaternions to euler angles\n",
    "\n",
    "#data structure\n",
    "euler_angles = {}\n",
    "euler_angles_x = {}\n",
    "euler_angles_y = {}\n",
    "euler_angles_z = {}\n",
    "for subject in subject_list:\n",
    "    euler_angles[subject]={}\n",
    "    euler_angles_x[subject]={}\n",
    "    euler_angles_y[subject]={}\n",
    "    euler_angles_z[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        euler_angles[subject][segment]={}\n",
    "        euler_angles_x[subject][segment]={}\n",
    "        euler_angles_y[subject][segment]={}\n",
    "        euler_angles_z[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            euler_angles[subject][segment][run]={}\n",
    "            euler_angles_x[subject][segment][run]={}\n",
    "            euler_angles_y[subject][segment][run]={}\n",
    "            euler_angles_z[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                euler_angles[subject][segment][run][tool] = []\n",
    "                euler_angles_x[subject][segment][run][tool] = []\n",
    "                euler_angles_y[subject][segment][run][tool] = []\n",
    "                euler_angles_z[subject][segment][run][tool] = []\n",
    "                for i in range(len(optitrack_non_zero[subject][segment][run][tool + '_' + 'x'])):\n",
    "                    \n",
    "                    # get the quaternion in the right format\n",
    "                    current_quaternion = np.array([np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qx'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qy'])[i],\n",
    "                                                   np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qz'])[i], np.array(optitrack_non_zero[subject][segment][run][tool + '_' + 'qw'])[i]])\n",
    "                    # conversion to euler angles\n",
    "                    angles = f_metrics.euler_from_quaternion(current_quaternion)\n",
    "                    euler_angles[subject][segment][run][tool].append(angles)\n",
    "                    # separate the 3 angles\n",
    "                    euler_angles_x[subject][segment][run][tool].append(angles[0])\n",
    "                    euler_angles_y[subject][segment][run][tool].append(angles[1])\n",
    "                    euler_angles_z[subject][segment][run][tool].append(angles[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c6ed8-0054-4bf8-b944-e828456a5812",
   "metadata": {
    "tags": []
   },
   "source": [
    "### remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "dfccab9f-820d-440d-83be-990350454437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outliers from the angles (found by plotting the data, where we have discontinuity)\n",
    "\n",
    "euler_angles_x_top_outlier={}\n",
    "euler_angles_y_top_outlier={}\n",
    "euler_angles_z_top_outlier={}\n",
    "time_euler_angles_x_top_outlier={}\n",
    "time_euler_angles_y_top_outlier={}\n",
    "time_euler_angles_z_top_outlier={}\n",
    "for subject in subject_list:\n",
    "    euler_angles_x_top_outlier[subject]={}\n",
    "    euler_angles_y_top_outlier[subject]={}\n",
    "    euler_angles_z_top_outlier[subject]={}\n",
    "    time_euler_angles_x_top_outlier[subject]={}\n",
    "    time_euler_angles_y_top_outlier[subject]={}\n",
    "    time_euler_angles_z_top_outlier[subject]={}\n",
    "    for segment in segment_list:\n",
    "        euler_angles_x_top_outlier[subject][segment]={}\n",
    "        euler_angles_y_top_outlier[subject][segment]={}\n",
    "        euler_angles_z_top_outlier[subject][segment]={}\n",
    "        time_euler_angles_x_top_outlier[subject][segment]= {}\n",
    "        time_euler_angles_y_top_outlier[subject][segment]= {}\n",
    "        time_euler_angles_z_top_outlier[subject][segment]= {}\n",
    "        for run in run_list[subject]:\n",
    "            euler_angles_x_top_outlier[subject][segment][run]={}\n",
    "            euler_angles_y_top_outlier[subject][segment][run]={}\n",
    "            euler_angles_z_top_outlier[subject][segment][run]={}\n",
    "            time_euler_angles_x_top_outlier[subject][segment][run] = {}\n",
    "            time_euler_angles_y_top_outlier[subject][segment][run] = {}\n",
    "            time_euler_angles_z_top_outlier[subject][segment][run] = {}\n",
    "            for tool in tools_name:\n",
    "                euler_angles_x_top_outlier[subject][segment][run][tool] = []\n",
    "                euler_angles_y_top_outlier[subject][segment][run][tool] = []\n",
    "                euler_angles_z_top_outlier[subject][segment][run][tool] = []\n",
    "                time_euler_angles_x_top_outlier[subject][segment][run][tool] = []\n",
    "                time_euler_angles_y_top_outlier[subject][segment][run][tool] =[]\n",
    "                time_euler_angles_z_top_outlier[subject][segment][run][tool] =[]\n",
    "\n",
    "\n",
    "\n",
    "for subject in subject_list:\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                # convert data\n",
    "                euler_angles_x_top_outlier[subject][segment][run][tool] = pd.DataFrame(euler_angles_x[subject][segment][run][tool])\n",
    "                euler_angles_y_top_outlier[subject][segment][run][tool] = pd.DataFrame(euler_angles_y[subject][segment][run][tool])\n",
    "                euler_angles_z_top_outlier[subject][segment][run][tool] = pd.DataFrame(euler_angles_z[subject][segment][run][tool])\n",
    "                \n",
    "                time_euler_angles_x_top_outlier[subject][segment][run][tool] = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'x']))\n",
    "                time_euler_angles_y_top_outlier[subject][segment][run][tool] = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'y']))\n",
    "                time_euler_angles_z_top_outlier[subject][segment][run][tool] = pd.DataFrame(list(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'z']))\n",
    "            \n",
    "\n",
    "#remove specifically for the recordings\n",
    "            \n",
    "# S2 R1\n",
    "for segment in ['540', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S2'][segment]['R1']['tweezer']\n",
    "    data_y = euler_angles_y_top_outlier['S2'][segment]['R1']['tweezer']\n",
    "    \n",
    "    time_x = time_euler_angles_x_top_outlier['S2'][segment]['R1']['tweezer']\n",
    "    time_y = time_euler_angles_y_top_outlier['S2'][segment]['R1']['tweezer']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S2'][segment]['R1']['tweezer'] = data_x[data_x>-0.5]\n",
    "    time_euler_angles_x_top_outlier['S2'][segment]['R1']['tweezer'] = time_x[data_x>-0.5] \n",
    "    euler_angles_y_top_outlier['S2'][segment]['R1']['tweezer'] = data_y[data_y>0.6]\n",
    "    time_euler_angles_y_top_outlier['S2'][segment]['R1']['tweezer'] = time_y[data_y>0.6] \n",
    "    \n",
    "#S7R1\n",
    "for segment in ['530', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S7'][segment]['R1']['tweezer']\n",
    "    data_y = euler_angles_y_top_outlier['S7'][segment]['R1']['tweezer']\n",
    "    \n",
    "    time_x = time_euler_angles_x_top_outlier['S7'][segment]['R1']['tweezer']\n",
    "    time_y = time_euler_angles_y_top_outlier['S7'][segment]['R1']['tweezer']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S7'][segment]['R1']['tweezer'] = data_x[data_x<2.5]\n",
    "    time_euler_angles_x_top_outlier['S7'][segment]['R1']['tweezer'] = time_x[data_x<2.5] \n",
    "    euler_angles_y_top_outlier['S7'][segment]['R1']['tweezer'] = data_y[data_y>0.4]\n",
    "    time_euler_angles_y_top_outlier['S7'][segment]['R1']['tweezer'] = time_y[data_y>0.4] \n",
    "    \n",
    "#S8R3\n",
    "for segment in ['500']:\n",
    "    data_x = euler_angles_x_top_outlier['S8'][segment]['R3']['tweezer']\n",
    "    #data_y = euler_angles_y_top_outlier['S8'][segment]['R3']['tweezer']\n",
    "    time_x = time_euler_angles_x_top_outlier['S8'][segment]['R3']['tweezer']\n",
    "    #time_y = time_euler_angles_y_top_outlier['S8'][segment]['R3']['tweezer']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S8'][segment]['R3']['tweezer'] = data_x[data_x<2.5]\n",
    "    time_euler_angles_x_top_outlier['S8'][segment]['R3']['tweezer'] = time_x[data_x<2.5] \n",
    "    #euler_angles_y_top_outlier['S8'][segment]['R3']['tweezer'] = data_y[data_y>0.4]\n",
    "    #time_euler_angles_y_top_outlier['S8'][segment]['R3']['tweezer'] = time_y[data_y>0.4] \n",
    "    \n",
    "#S9 R3\n",
    "for segment in ['510', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S9'][segment]['R3']['tweezer']\n",
    "    time_x = time_euler_angles_x_top_outlier['S9'][segment]['R3']['tweezer']\n",
    "    data_y = euler_angles_y_top_outlier['S9'][segment]['R3']['tweezer']\n",
    "    time_y = time_euler_angles_y_top_outlier['S9'][segment]['R3']['tweezer']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S9'][segment]['R3']['tweezer'] = data_x[data_x<2.5]\n",
    "    euler_angles_y_top_outlier['S9'][segment]['R3']['tweezer'] = data_y[data_y>-0.5]\n",
    "    \n",
    "    time_euler_angles_x_top_outlier['S9'][segment]['R3']['tweezer'] = time_x[data_x<2.5] \n",
    "    time_euler_angles_y_top_outlier['S9'][segment]['R3']['tweezer'] = time_y[data_y>-0.5] \n",
    "    \n",
    "#S11 R3 R1 R4\n",
    "for segment in segment_list:\n",
    "     for run in run_list['S11']:\n",
    "            tool = 'tweezer'\n",
    "            for i in range(len( euler_angles_x_top_outlier['S11'][segment][run][tool])):\n",
    "                data = euler_angles_x_top_outlier['S11'][segment][run][tool][0][i]\n",
    "                if data < 0:\n",
    "                    euler_angles_x_top_outlier['S11'][segment][run][tool][0][i] = data + 2*math.pi  \n",
    "                    \n",
    "            for i in range(len( euler_angles_z_top_outlier['S11'][segment][run][tool])):\n",
    "                data = euler_angles_z_top_outlier['S11'][segment][run][tool][0][i]\n",
    "                if data < 0:\n",
    "                    euler_angles_z_top_outlier['S11'][segment][run][tool][0][i] = data + 2*math.pi  \n",
    "\n",
    "#S2 R3\n",
    "for segment in ['500', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_euler_angles_x_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    data_y = euler_angles_y_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    time_y = time_euler_angles_y_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    data_z = euler_angles_z_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    time_z = time_euler_angles_z_top_outlier['S2'][segment]['R3']['needle_holder2']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S2'][segment]['R3']['needle_holder2'] = data_x[data_x>-2]\n",
    "    euler_angles_y_top_outlier['S2'][segment]['R3']['needle_holder2'] = data_y[data_y<0.4]\n",
    "    euler_angles_z_top_outlier['S2'][segment]['R3']['needle_holder2'] = data_z[data_z>-0.6]\n",
    "    \n",
    "    time_euler_angles_x_top_outlier['S2'][segment]['R3']['needle_holder2'] = time_x[data_x>-2] \n",
    "    time_euler_angles_y_top_outlier['S2'][segment]['R3']['needle_holder2'] = time_y[data_y<0.4] \n",
    "    time_euler_angles_z_top_outlier['S2'][segment]['R3']['needle_holder2'] = time_z[data_z>-0.6] \n",
    "    \n",
    "#S12 R3\n",
    "for segment in ['540', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_euler_angles_x_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    data_y = euler_angles_y_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    time_y = time_euler_angles_y_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    data_z = euler_angles_z_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    time_z = time_euler_angles_z_top_outlier['S12'][segment]['R3']['needle_holder2']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S12'][segment]['R3']['needle_holder2'] = data_x[data_x<2.5]\n",
    "    euler_angles_y_top_outlier['S12'][segment]['R3']['needle_holder2'] = data_y[data_y>-1.25]\n",
    "    euler_angles_z_top_outlier['S12'][segment]['R3']['needle_holder2'] = data_z[data_z<-0.2]\n",
    "    \n",
    "    time_euler_angles_x_top_outlier['S12'][segment]['R3']['needle_holder2'] = time_x[data_x<2.5] \n",
    "    time_euler_angles_y_top_outlier['S12'][segment]['R3']['needle_holder2'] = time_y[data_y>-1.25] \n",
    "    time_euler_angles_z_top_outlier['S12'][segment]['R3']['needle_holder2'] = time_z[data_z<-0.2] \n",
    "    \n",
    "#S9 R3\n",
    "for segment in ['510', '560']:\n",
    "    data_x = euler_angles_x_top_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    time_x = time_euler_angles_x_top_outlier['S9'][segment]['R3']['needle_holder2']\n",
    "    \n",
    "    euler_angles_x_top_outlier['S9'][segment]['R3']['needle_holder2'] = data_x[data_x<1.5]\n",
    "    time_euler_angles_x_top_outlier['S9'][segment]['R3']['needle_holder2'] = time_x[data_x<1.5] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb208fa9-816e-4f5b-aa14-2f71ecbdb274",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpolation angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "40d61b06-623f-49d2-9932-a7dceba1ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation of the euler angles to get a clean frequencz and remove the gaps from removing the outliers\n",
    "\n",
    "#data structure\n",
    "interpolated_euler_angles_y = {}\n",
    "interpolated_euler_angles_x = {}\n",
    "interpolated_euler_angles_z = {}\n",
    "for subject in subject_list:   \n",
    "    interpolated_euler_angles_y[subject] = {}\n",
    "    interpolated_euler_angles_x[subject] = {}\n",
    "    interpolated_euler_angles_z[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        interpolated_euler_angles_y[subject][segment] = {}\n",
    "        interpolated_euler_angles_x[subject][segment] = {}\n",
    "        interpolated_euler_angles_z[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            interpolated_euler_angles_y[subject][segment][run] = {}\n",
    "            interpolated_euler_angles_x[subject][segment][run] = {}\n",
    "            interpolated_euler_angles_z[subject][segment][run] = {}\n",
    "            for tool in tools_name:\n",
    "                interpolated_euler_angles_x[subject][segment][run][tool] = {}\n",
    "                interpolated_euler_angles_y[subject][segment][run][tool] = {}\n",
    "                interpolated_euler_angles_z[subject][segment][run][tool] = {}\n",
    "\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                data_x = list(euler_angles_x_top_outlier[subject][segment][run][tool][0])\n",
    "                data_y = list(euler_angles_y_top_outlier[subject][segment][run][tool][0])\n",
    "                data_z = list(euler_angles_z_top_outlier[subject][segment][run][tool][0])\n",
    "                \n",
    "                # interpolation functions\n",
    "                time = np.array(optitrack_non_zero_time[subject][segment][run][tool+ '_' + 'x'])\n",
    "                Interpole_x = inter.interp1d(list(time_euler_angles_x_top_outlier[subject][segment][run][tool][0]), list(data_x),bounds_error=False, fill_value='extrapolate')\n",
    "                Interpole_y = inter.interp1d(list(time_euler_angles_y_top_outlier[subject][segment][run][tool][0]), list(data_y),bounds_error=False,fill_value='extrapolate')\n",
    "                Interpole_z = inter.interp1d(list(time_euler_angles_z_top_outlier[subject][segment][run][tool][0]), list(data_z),bounds_error=False, fill_value='extrapolate')\n",
    "                \n",
    "                # interpolation using the new time vector\n",
    "                time_step = 1/120\n",
    "                time_vector = np.arange(time.min(),time.max()-time_step,time_step )\n",
    "                interpolated_euler_angles_x[subject][segment][run][tool] = Interpole_x(time_vector)\n",
    "                interpolated_euler_angles_y[subject][segment][run][tool] = Interpole_y(time_vector)\n",
    "                interpolated_euler_angles_z[subject][segment][run][tool] = Interpole_z(time_vector)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eceb877-5fdc-4083-88c8-c809ce17ee71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### filter median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6c72acbe-425e-4547-8c86-b6b16a396425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st filter to smooth the angles data\n",
    "\n",
    "euler_angles_x_tip_filter = {}\n",
    "euler_angles_y_tip_filter = {}\n",
    "euler_angles_z_tip_filter = {} \n",
    "for subject in subject_list:\n",
    "    euler_angles_x_tip_filter[subject]= {}\n",
    "    euler_angles_y_tip_filter[subject]= {}\n",
    "    euler_angles_z_tip_filter[subject]= {}\n",
    "    for segment in segment_list:     \n",
    "        euler_angles_x_tip_filter[subject][segment]= {}\n",
    "        euler_angles_y_tip_filter[subject][segment]= {}\n",
    "        euler_angles_z_tip_filter[subject][segment]= {}         \n",
    "        for run in run_list[subject]:\n",
    "            euler_angles_x_tip_filter[subject][segment][run]= {}\n",
    "            euler_angles_y_tip_filter[subject][segment][run]= {}\n",
    "            euler_angles_z_tip_filter[subject][segment][run]= {}            \n",
    "            for tool in tools_name:\n",
    "                euler_angles_x_tip_filter[subject][segment][run][tool] = []\n",
    "                euler_angles_y_tip_filter[subject][segment][run][tool] = []\n",
    "                euler_angles_z_tip_filter[subject][segment][run][tool] = []              \n",
    "\n",
    "\n",
    "                euler_angles_x_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_euler_angles_x[subject][segment][run][tool] , size=14)\n",
    "                euler_angles_y_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_euler_angles_y[subject][segment][run][tool] , size=14, footprint=None, output=None, mode='reflect', cval=0.0, origin=0)\n",
    "                euler_angles_z_tip_filter[subject][segment][run][tool] = scipy.ndimage.median_filter(interpolated_euler_angles_z[subject][segment][run][tool] , size=14, footprint=None, output=None, mode='reflect', cval=0.0, origin=0)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10af65b-1648-4288-a4c3-aa50e3c8c038",
   "metadata": {
    "tags": []
   },
   "source": [
    "### angular velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1c919e69-3736-4274-bb84-cea65ca95596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structure\n",
    "angular_vel_x_top_estimator= {}\n",
    "angular_vel_y_top_estimator = {}\n",
    "angular_vel_z_top_estimator = {} \n",
    "angular_vel_x_top = {} \n",
    "angular_vel_y_top = {} \n",
    "angular_vel_z_top = {} \n",
    "for subject in subject_list:\n",
    "    angular_vel_x_top_estimator[subject]= {}\n",
    "    angular_vel_y_top_estimator[subject]= {}\n",
    "    angular_vel_z_top_estimator[subject]= {}\n",
    "    angular_vel_x_top[subject]= {}\n",
    "    angular_vel_y_top [subject]= {}\n",
    "    angular_vel_z_top [subject]= {}\n",
    "    for segment in segment_list:     \n",
    "        angular_vel_x_top_estimator[subject][segment]= {}\n",
    "        angular_vel_y_top_estimator[subject][segment]= {}\n",
    "        angular_vel_z_top_estimator[subject][segment]= {}      \n",
    "        angular_vel_x_top[subject][segment]= {}  \n",
    "        angular_vel_y_top [subject][segment]= {} \n",
    "        angular_vel_z_top[subject][segment]= {} \n",
    "        for run in run_list[subject]:\n",
    "            angular_vel_x_top_estimator[subject][segment][run]= {}\n",
    "            angular_vel_y_top_estimator[subject][segment][run]= {}\n",
    "            angular_vel_z_top_estimator[subject][segment][run]= {}\n",
    "            angular_vel_x_top[subject][segment][run]= {}  \n",
    "            angular_vel_y_top[subject][segment][run]= {}\n",
    "            angular_vel_z_top[subject][segment][run]= {}\n",
    "            for tool in tools_name:\n",
    "                angular_vel_x_top_estimator[subject][segment][run][tool] = []\n",
    "                angular_vel_y_top_estimator[subject][segment][run][tool] = []\n",
    "                angular_vel_z_top_estimator[subject][segment][run][tool] = []     \n",
    "                angular_vel_x_top[subject][segment][run][tool] = []\n",
    "                angular_vel_y_top [subject][segment][run][tool] = []\n",
    "                angular_vel_z_top[subject][segment][run][tool] = []\n",
    "\n",
    "                # derivation using the Savitzky-Golay method to get angular velocity\n",
    "                window_length = 5\n",
    "                polyorder = 3\n",
    "                dt = 1/120\n",
    "                angular_vel_x_top_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(euler_angles_x_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                angular_vel_y_top_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(euler_angles_y_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                angular_vel_z_top_estimator[subject][segment][run][tool] = scipy.signal.savgol_filter(euler_angles_z_tip_filter[subject][segment][run][tool], window_length, polyorder, deriv=1, delta=dt, axis=- 1, mode='interp', cval=0.0)\n",
    "                \n",
    "                # 2nd computation method of the derivative to check\n",
    "                angular_vel_x_top[subject][segment][run][tool] = np.diff(euler_angles_x_tip_filter[subject][segment][run][tool])/(1/120)\n",
    "                angular_vel_y_top[subject][segment][run][tool] = np.diff(euler_angles_y_tip_filter[subject][segment][run][tool])/(1/120)\n",
    "                angular_vel_z_top[subject][segment][run][tool] = np.diff(euler_angles_z_tip_filter[subject][segment][run][tool])/(1/120)\n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecad488-58d4-4801-af6e-8b5c21db2fbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PLOTS to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d98e4-dace-4e4a-8e26-9fd402200a79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### position and quaternions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144c195-9f11-492b-97e3-ffe33eb9f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interpolated data to check interpolation, for the position\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            fig = go.Figure()\n",
    "            for tool in ['tweezer_x', 'tweezer_y', 'tweezer_z','needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z']:  \n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool]\n",
    "\n",
    "                data_current1 = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                data_current2 = np.array(interpolated_data[subject][segment][run][tool])\n",
    "                               \n",
    "                fig.add_trace(go.Scatter(y=data_current2, x=np.array(time_vector_interp[subject][segment][run][tool] -data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool+ \"interp\"))\n",
    "                fig.add_trace(go.Scatter(y=data_current1, x=np.array((optitrack_non_zero_time[subject][segment][run][tool])-data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool ))\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Optitrack data [m]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', subject)):\n",
    "                os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', subject ))\n",
    "            fig.write_image(join('..', 'data_paper',  'PLOTS' , 'OPTITRACK', subject, 'optitrack_position_INTERP_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1cf3bf-c0f7-44da-8796-befc2078004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interpolated data to check interpolation, for the quaternions\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            fig = go.Figure()\n",
    "            for tool in ['tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw','needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']:  \n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool]\n",
    "\n",
    "                data_current1 = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                data_current2 = np.array(interpolated_data[subject][segment][run][tool])\n",
    "                               \n",
    "                fig.add_trace(go.Scatter(y=data_current2, x=np.array(time_vector_interp[subject][segment][run][tool] -data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool+ \"interp\"))\n",
    "                fig.add_trace(go.Scatter(y=data_current1, x=np.array((optitrack_non_zero_time[subject][segment][run][tool])-data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool ))\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Optitrack data [m]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', subject)):\n",
    "                os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', subject ))\n",
    "            fig.write_image(join('..', 'data_paper',  'PLOTS' , 'OPTITRACK', subject, 'optitrack_quaternion_INTERP_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3cfe18-2ca7-4a60-bc5c-3e5a1f26123b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### plots data with filter/  interpolation / outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69ccd5-f1ed-4aed-8211-d58e3cbb0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the y position signals: raw signal, w/o outliers, interpolated, anf filtered for the top and the tip\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool+'_y']\n",
    "                fig = go.Figure()\n",
    "                #for tool in tools_name:  \n",
    "\n",
    "                a = np.array(optitrack_non_zero[subject][segment][run][tool+'_y'])\n",
    "                b = np.array(interpolated_data[subject][segment][run][tool+'_y'])\n",
    "                c = pos_y[subject][segment][run][tool]\n",
    "                d = pos_y_tip[subject][segment][run][tool]\n",
    "                e = pos_y_tip_outlier[subject][segment][run][tool]\n",
    "                f = np.array(interpolated_data_tip_y[subject][segment][run][tool])\n",
    "                g = pos_y_tip_filter[subject][segment][run][tool] \n",
    "\n",
    "                fig.add_trace(go.Scatter(y=b, x=time_vector_interp[subject][segment][run][tool+'_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='interp_'+tool+'_y',marker=dict(color='LightSkyBlue',size=10)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=a, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool+'_y raw',marker=dict(size=5)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=c, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool+'_y',marker=dict(size=3) ))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=d, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip', marker=dict(color='yellow',  size=15)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=f, x=time_vector_interp[subject][segment][run][tool+'_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter outliers interp', marker=dict(color='LightSkyBlue',size=10)))  \n",
    "\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=list(e[0]), x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter outliers', marker=dict(color='violet', size=8)))\n",
    "\n",
    "    \n",
    "                fig.add_trace(go.Scatter(y=g, x=time_vector_interp[subject][segment][run][tool+'_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter median', marker=dict(color='red', size=3)))\n",
    "        \n",
    "\n",
    "                fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                    xaxis_title='Time',\n",
    "                    yaxis_title='Optitrack data [m]',\n",
    "                    width=1000,\n",
    "                    height=500)\n",
    "                #fig.show()\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'POSITION_y', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'POSITION_y', tool))\n",
    "                fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'POSITION_y', tool, 'optitrack_position_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b80707-b8ff-4805-a48d-9fdb5ad09df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the x position signals: raw signal, w/o outliers, interpolated, anf filtered for the top and the tip\n",
    "\n",
    "for subject in subject_list:   \n",
    "    print(subject)\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool+'_x']\n",
    "                fig = go.Figure()\n",
    "                #for tool in tools_name:  \n",
    "\n",
    "                c = np.array(optitrack_non_zero[subject][segment][run][tool+'_x'])\n",
    "                d = np.array(interpolated_data[subject][segment][run][tool+'_x'])\n",
    "                a = pos_x[subject][segment][run][tool]\n",
    "                b = pos_x_tip[subject][segment][run][tool]\n",
    "                e = pos_x_tip_outlier[subject][segment][run][tool]\n",
    "                f = np.array(interpolated_data_tip_x[subject][segment][run][tool])\n",
    "                g = pos_x_tip_filter[subject][segment][run][tool] \n",
    "\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=d, x=time_vector_interp[subject][segment][run][tool+'_x']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='interp' + tool + '_x',marker=dict(color='LightSkyBlue',size=10)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=c, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool +'_x raw',marker=dict(color = 'navy', size=5)))\n",
    "\n",
    "                #fig.add_trace(go.Scatter(y=a, x=time_vector_interp[subject][segment][run]['tweezer_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                #    mode='markers', name='tweezer_y',marker=dict(size=3) ))\n",
    "                fig.add_trace(go.Scatter(y=a, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool+'_x from transf',marker=dict(size=3) ))\n",
    "                #fig.add_trace(go.Scatter(y=b, x=time_vector_interp[subject][segment][run]['tweezer_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                #    mode='markers', name='position tip'))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=f, x=time_vector_interp[subject][segment][run][tool+'_x']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip interp', marker=dict(color='LightGreen',size=15)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=b, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip ', marker=dict(color='forestgreen', size=12)))\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=list(e[0]), x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter outliers', marker=dict(color='indigo', size=8)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=g, x=time_vector_interp[subject][segment][run][tool+'_x']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter median', marker=dict(color='red', size=3)))\n",
    "                \n",
    "\n",
    "\n",
    "                fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                    xaxis_title='Time',\n",
    "                    yaxis_title='Optitrack data [m]',\n",
    "                    width=1000,\n",
    "                    height=500)\n",
    "                #fig.show()\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'POSITION_x', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'POSITION_x', tool))\n",
    "                fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK', 'POSITION_x', tool, 'x_optitrack_position_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452d138-30ba-4c20-9c20-b885cea4f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the z position signals: raw signal, w/o outliers, interpolated, anf filtered for the top and the tip\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool +'_z']\n",
    "                fig = go.Figure()\n",
    "\n",
    "\n",
    "                c = np.array(optitrack_non_zero[subject][segment][run][tool +'_z'])\n",
    "                d = np.array(interpolated_data[subject][segment][run][tool +'_z'])\n",
    "                a = pos_z[subject][segment][run][tool]\n",
    "                b = pos_z_tip[subject][segment][run][tool]\n",
    "                e = pos_z_tip_outlier[subject][segment][run][tool]\n",
    "                f = np.array(interpolated_data_tip_z[subject][segment][run][tool])\n",
    "                g = pos_z_tip_filter[subject][segment][run][tool] \n",
    "\n",
    "                fig.add_trace(go.Scatter(y=d, x=time_vector_interp[subject][segment][run][tool +'_z']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='interp' + tool + '_z',marker=dict(color='LightSkyBlue',size=10)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=c, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool + '_z raw',marker=dict(size=5)))\n",
    "\n",
    "                #fig.add_trace(go.Scatter(y=a, x=time_vector_interp[subject][segment][run]['tweezer_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                #    mode='markers', name='tweezer_y',marker=dict(size=3) ))\n",
    "                fig.add_trace(go.Scatter(y=a, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool + '_z',marker=dict(size=3) ))\n",
    "                #fig.add_trace(go.Scatter(y=b, x=time_vector_interp[subject][segment][run]['tweezer_y']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                #    mode='markers', name='position tip'))\n",
    "                fig.add_trace(go.Scatter(y=f, x=time_vector_interp[subject][segment][run][tool +'_z']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip interp', marker=dict(color='LightGreen',size=12)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=b, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip', marker=dict(size=8)))\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=g, x=time_vector_interp[subject][segment][run][tool+'_z']-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                        mode='markers', name='position tip filter median', marker=dict(color='red', size=3)))\n",
    "                \n",
    "                 fig.add_trace(go.Scatter(y=list(e[0]), x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name='position tip filter outliers', marker=dict(color='violet', size=8)))\n",
    "\n",
    "                fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                    xaxis_title='Time',\n",
    "                    yaxis_title='Optitrack data [m]',\n",
    "                    width=1000,\n",
    "                    height=500)\n",
    "                #fig.show()\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'POSITION_z', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'POSITION_z', tool))\n",
    "                fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'POSITION_z', tool, 'z_optitrack_position_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb012be0-9d72-47ff-b4e5-0deeb715b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the x,y,z speed signals: 2 methods of computation to compare\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                \n",
    "                fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "                x = time_vector_interp[subject][segment][run][tool+ '_' + 'x']-data_segments[subject][segment][run][sensor]['rel_time'][0]\n",
    "\n",
    "                ax1 = axs[0]\n",
    "                ax2 = axs[1]\n",
    "                ax3 = axs[2]\n",
    "                \n",
    "                ax1.plot(x[1:-1], speed_x_tip[subject][segment][run][tool],color='lightgreen', label = 'Speed x base', linewidth =3 )\n",
    "                ax1.plot(x, speed_x_tip_estimator[subject][segment][run][tool],color='green', label = 'Speed x est', linewidth =1 )\n",
    "\n",
    "                ax2.plot(x[1:-1], speed_y_tip[subject][segment][run][tool],color='lightcoral', label = 'Speed y base', linewidth =3 )\n",
    "                ax2.plot(x, speed_y_tip_estimator[subject][segment][run][tool] ,color='red', label = 'Speed y est', linewidth =1 )\n",
    "                \n",
    "                ax3.plot(x[1:-1], speed_z_tip[subject][segment][run][tool],color='blue', label = 'Speed z base', linewidth =3 )\n",
    "                ax3.plot(x, speed_z_tip_estimator[subject][segment][run][tool],color='turquoise', label = 'Speed z est', linewidth =1)\n",
    "                \n",
    "                ax2.legend()\n",
    "                ax1.legend()\n",
    "                ax3.legend()\n",
    "\n",
    "                ax1.grid()\n",
    "                ax2.grid()\n",
    "                ax3.grid()\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.set(xlabel='time', ylabel='speed m/s')\n",
    "\n",
    "                ax1.set_title(\"Speed x\")\n",
    "                ax2.set_title(\"Speed y\") \n",
    "                ax3.set_title(\"Speed z\")\n",
    "\n",
    "                fig.suptitle(\"Subject_\"+ subject + \"Segment \" + segment + \" run: \" + run + \" tool: \" + tool, x = 0.5, fontsize=15)    \n",
    "                #fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'SPEED', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'SPEED', tool))\n",
    "                #fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'SPEED', tool, 'speed_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "                plt.savefig(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'SPEED', tool, 'speed_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b45cf-cabe-4719-85e3-c065b21a6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the x,y,z acceleration signals: 2 methods of computation to compare\n",
    "\n",
    "plt.ioff()\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                              \n",
    "                fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "                x = time_vector_interp[subject][segment][run][tool+ '_' + 'x']\n",
    "\n",
    "                ax1 = axs[0]\n",
    "                ax2 = axs[1]\n",
    "                ax3 = axs[2]\n",
    "                \n",
    "                ax1.plot(x[2:-2], acc_x_tip[subject][segment][run][tool],color='lightgreen', label = 'Acc x base', linewidth =3 )\n",
    "                ax1.plot(x, acc_x_tip_estimator[subject][segment][run][tool],color='green', label = 'Acc x est', linewidth =1)\n",
    "                ax2.plot(x[2:-2], acc_y_tip[subject][segment][run][tool],color='lightcoral', label = 'Acc y base', linewidth =3 )\n",
    "                ax2.plot(x, acc_y_tip_estimator[subject][segment][run][tool] ,color='red', label = 'Acc y est', linewidth =1)\n",
    "                ax3.plot(x[2:-2], acc_z_tip[subject][segment][run][tool],color='turquoise', label = 'Acc y base', linewidth =3 )\n",
    "                ax3.plot(x, acc_z_tip_estimator[subject][segment][run][tool],color='blue', label = 'Acc z est', linewidth =1)\n",
    "\n",
    "                ax2.legend()\n",
    "                ax1.legend()\n",
    "                ax3.legend()\n",
    "                ax1.grid()\n",
    "                ax2.grid()\n",
    "                ax3.grid()\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.set(xlabel='time', ylabel='acc m/s2')\n",
    "\n",
    "                ax1.set_title(\"Acc x\")\n",
    "                ax2.set_title(\"Acc y\") \n",
    "                ax3.set_title(\"Acc z\")\n",
    "\n",
    "                fig.suptitle(\"Subject: \"+ subject + \"; Segment \" + segment + \"; run: \" + run + \"; tool: \" + tool, x = 0.5, fontsize=15)    \n",
    "                #fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'ACC', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'ACC', tool))\n",
    "                #fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'SPEED', tool, 'speed_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "                plt.savefig(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'ACC', tool, 'acc_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8de0d-199c-4cc1-a6f0-804008c4a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the x,y,z jerk signals: 2 methods of computation to compare\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                \n",
    "                fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "                x = time_vector_interp[subject][segment][run][tool+ '_' + 'x']\n",
    "\n",
    "                ax1 = axs[0]\n",
    "                ax2 = axs[1]\n",
    "                ax3 = axs[2]\n",
    "                \n",
    "                ax1.plot(x[3:-3], jerk_x_tip[subject][segment][run][tool],color='lightgreen', label = 'jerk x base', linewidth =3 )\n",
    "                ax1.plot(x, jerk_x_tip_estimator[subject][segment][run][tool],color='green', label = 'jerk x est', linewidth =1)\n",
    "                ax2.plot(x[3:-3], jerk_x_tip[subject][segment][run][tool],color='lightcoral', label = 'jerk y base', linewidth =3 )\n",
    "                ax2.plot(x, jerk_y_tip_estimator[subject][segment][run][tool] ,color='red', label = 'jerk y est', linewidth =1)\n",
    "                ax3.plot(x[3:-3], jerk_z_tip[subject][segment][run][tool],color='turquoise', label = 'jerk z base', linewidth =3 )\n",
    "                ax3.plot(x, jerk_z_tip_estimator[subject][segment][run][tool],color='blue', label = 'jerk z est', linewidth =1)\n",
    "\n",
    "                ax1.grid()\n",
    "                ax2.grid()\n",
    "                ax3.grid()\n",
    "                ax2.legend()\n",
    "                ax1.legend()\n",
    "                ax3.legend()\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.set(xlabel='time', ylabel='jerk m/s3')\n",
    "\n",
    "                ax1.set_title(\"Jerk x\")\n",
    "                ax2.set_title(\"Jerk y\") \n",
    "                ax3.set_title(\"Jerk z\")\n",
    "\n",
    "                fig.suptitle(\"Subject_\"+ subject + \"Segment \" + segment + \" run: \" + run + \" tool: \" + tool, x = 0.15, fontsize=15)    \n",
    "                #fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'JERK', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'JERK', tool))\n",
    "                #fig.write_image(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'SPEED', tool, 'speed_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "                plt.savefig(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'JERK', tool, 'jerk_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6de49f-a0dc-4d56-9526-c533d51f61a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### angles and angular velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4706b8-8d25-4561-8cf2-ac59d498601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the angles: raw signals (w/o zeros), w/o outliers, interpolated signals, filtered signals\n",
    "\n",
    "plt.ioff()\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                \n",
    "                fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "                x = optitrack_non_zero_time[subject][segment][run][tool+'_x']-data_segments[subject][segment][run][sensor]['rel_time'][0]\n",
    "                t_interp = time_vector_interp[subject][segment][run][tool+'_x'] -data_segments[subject][segment][run][sensor]['rel_time'][0]\n",
    "\n",
    "                ax1 = axs[0]\n",
    "                ax2 = axs[1]\n",
    "                ax3 = axs[2]\n",
    "                \n",
    "                ax1.plot(t_interp , interpolated_euler_angles_x[subject][segment][run][tool] ,'o', color='orange', label = 'Roll x interp',markersize =10)\n",
    "                ax1.plot(x, euler_angles_x[subject][segment][run][tool],'o', color='lightgreen', label = 'Roll x base',markersize = 8)#, linewidth =3 )\n",
    "                ax1.plot(time_euler_angles_x_top_outlier[subject][segment][run][tool][0]-data_segments[subject][segment][run][sensor]['rel_time'][0], euler_angles_x_top_outlier[subject][segment][run][tool][0] ,'o', color='green', label = 'Roll x outlier',markersize = 5)\n",
    "                ax1.plot(t_interp , euler_angles_x_tip_filter[subject][segment][run][tool],'o', color='lime', label = 'Roll x filter',markersize = 2)\n",
    "                \n",
    "                ax2.plot(t_interp , interpolated_euler_angles_y[subject][segment][run][tool] ,'o', color='gold', label = 'pitch y interp',markersize =10)\n",
    "                ax2.plot(x, euler_angles_y[subject][segment][run][tool],'o', color='lightcoral', label = 'pitch y base', markersize =8 )\n",
    "                ax2.plot(time_euler_angles_y_top_outlier[subject][segment][run][tool][0]-data_segments[subject][segment][run][sensor]['rel_time'][0], euler_angles_y_top_outlier[subject][segment][run][tool][0] ,'o', color='red', label = 'Roll x outlier',markersize = 2)\n",
    "                ax2.plot(t_interp , euler_angles_y_tip_filter[subject][segment][run][tool],'o', color='lime', label = 'pitch y filter',markersize = 2)\n",
    "\n",
    "                ax3.plot(t_interp , interpolated_euler_angles_z[subject][segment][run][tool] ,'o', color='gold', label = 'yaw z interp',markersize =10)\n",
    "                ax3.plot(x ,euler_angles_z[subject][segment][run][tool],'o' ,color='turquoise', label = 'yaw z base', markersize =4 )\n",
    "                ax3.plot(time_euler_angles_z_top_outlier[subject][segment][run][tool][0]-data_segments[subject][segment][run][sensor]['rel_time'][0], euler_angles_z_top_outlier[subject][segment][run][tool][0] ,'o', color='blue', label = 'Roll x outlier',markersize = 2)\n",
    "                ax3.plot(t_interp , euler_angles_z_tip_filter[subject][segment][run][tool],'o', color='teal', label = 'yaw z filter',markersize = 2)\n",
    "\n",
    "                ax2.legend()\n",
    "                ax1.legend()\n",
    "                ax3.legend()\n",
    "                ax1.grid()\n",
    "                ax2.grid()\n",
    "                ax3.grid()\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.set(xlabel='time', ylabel='acc m/s2')\n",
    "\n",
    "                ax1.set_title(\"Roll x [rad]\")\n",
    "                ax2.set_title(\"Pitch y [rad]\") \n",
    "                ax3.set_title(\"Yaw z [rad]\")\n",
    "                fig.suptitle(\"Subject: \"+ subject + \"; Segment \" + segment + \"; run: \" + run + \"; tool: \" + tool, x = 0.5, fontsize=15)    \n",
    "                #fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'EULER', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'EULER', tool))\n",
    "                plt.savefig(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'EULER', tool, 'euler_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57586937-534e-46d0-a26a-30530ddc9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for the angular velocities: 2 methods to compare results\n",
    "\n",
    "plt.ioff()\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:  \n",
    "                                \n",
    "                fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "                x = optitrack_non_zero_time[subject][segment][run][tool+'_x']-data_segments[subject][segment][run][sensor]['rel_time'][0]\n",
    "                t_interp = time_vector_interp[subject][segment][run][tool+'_x'] -data_segments[subject][segment][run][sensor]['rel_time'][0]\n",
    "\n",
    "                ax1 = axs[0]\n",
    "                ax2 = axs[1]\n",
    "                ax3 = axs[2]\n",
    "                \n",
    "                ax1.plot(t_interp ,angular_vel_x_top_estimator[subject][segment][run][tool] , color='orange', label = 'Diff roll x base', linewidth =4)\n",
    "                ax1.plot(t_interp[0:-1], angular_vel_x_top[subject][segment][run][tool], color='lightgreen', label = 'Diff roll x estimator', linewidth =1)#, linewidth =3 )\n",
    "               \n",
    "                ax2.plot(t_interp ,angular_vel_y_top_estimator[subject][segment][run][tool] , color='gold', label = 'diff pitch y base', linewidth =4)\n",
    "                ax2.plot(t_interp[0:-1], angular_vel_y_top[subject][segment][run][tool], color='lightcoral', label = 'diff pitch y est',  linewidth =1)\n",
    "                \n",
    "                ax3.plot(t_interp ,angular_vel_z_top_estimator[subject][segment][run][tool]  , color='gold', label = 'diff yaw z base', linewidth =4)\n",
    "                ax3.plot(t_interp[0:-1], angular_vel_z_top[subject][segment][run][tool],color='turquoise', label = 'diff yaw z est',  linewidth =1 )\n",
    "                \n",
    "                ax2.legend()\n",
    "                ax1.legend()\n",
    "                ax3.legend()\n",
    "                ax1.grid()\n",
    "                ax2.grid()\n",
    "                ax3.grid()\n",
    "\n",
    "                for ax in axs.flat:\n",
    "                    ax.set(xlabel='time', ylabel='acc m/s2')\n",
    "\n",
    "                ax1.set_title(\"Roll x [rad]\")\n",
    "                ax2.set_title(\"Pitch y [rad]\") \n",
    "                ax3.set_title(\"Yaw z [rad]\")\n",
    "\n",
    "                fig.suptitle(\"Subject: \"+ subject + \"; Segment \" + segment + \"; run: \" + run + \"; tool: \" + tool, x = 0.5, fontsize=15)    \n",
    "                #fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK', 'EULER_vel', tool)):\n",
    "                    os.makedirs(join(path_to_data_folder, 'PLOTS' , 'OPTITRACK',  'EULER_vel', tool))\n",
    "\n",
    "                plt.savefig(join('..', 'data_paper', 'PLOTS' , 'OPTITRACK',  'EULER_vel', tool, 'ang_vel_optitrack_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "                plt.close(fig)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26f6a4-f57d-48f0-8b40-51f22c6bbf9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compute norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287b4ff-1097-418d-9687-4aeb597e3cfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Norm Velocity tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9b39b98d-0e6e-4b28-8558-6aeec03b7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tip_speed={}\n",
    "for subject in subject_list:\n",
    "    norm_tip_speed[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        norm_tip_speed[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            norm_tip_speed[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                norm_tip_speed[subject][segment][run][tool]=[]\n",
    "                for i in range(len(speed_x_tip_estimator[subject][segment][run][tool])):\n",
    "                    # put x,y,y values in a vector and compute vector norm [vx,vy,vz]\n",
    "                    v = [speed_x_tip_estimator[subject][segment][run][tool][i], speed_y_tip_estimator[subject][segment][run][tool][i],speed_z_tip_estimator[subject][segment][run][tool][i]]\n",
    "                    norm_tip_speed[subject][segment][run][tool].append(LA.norm(v,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44509225-3dd5-45f7-8cf9-e73596c7222c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### norm acc tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "81c2afe0-081e-4c3d-83dd-71187d7061ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tip_acc={}\n",
    "for subject in subject_list:\n",
    "    norm_tip_acc[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        norm_tip_acc[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            norm_tip_acc[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                norm_tip_acc[subject][segment][run][tool]=[]\n",
    "                for i in range(len(acc_x_tip_estimator[subject][segment][run][tool])):\n",
    "                    # put x,y,y values in a vector and compute vector norm [ax,ay,az]\n",
    "                    a = [acc_x_tip_estimator[subject][segment][run][tool][i], acc_y_tip_estimator[subject][segment][run][tool][i],acc_z_tip_estimator[subject][segment][run][tool][i]]\n",
    "                    norm_tip_acc[subject][segment][run][tool].append(LA.norm(a,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6a929-6831-4015-9fb9-d5b63570f9b1",
   "metadata": {},
   "source": [
    "### norm jerk tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ede12273-8f0e-4efe-bdf4-da44075e980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tip_jerk={}\n",
    "for subject in subject_list:\n",
    "    norm_tip_jerk[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        norm_tip_jerk[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            norm_tip_jerk[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                norm_tip_jerk[subject][segment][run][tool]=[]\n",
    "                for i in range(len(jerk_x_tip_estimator[subject][segment][run][tool])):\n",
    "                    # put x,y,y values in a vector and compute vector norm [jx,jy,jz]\n",
    "                    j = [jerk_x_tip_estimator[subject][segment][run][tool][i], jerk_y_tip_estimator[subject][segment][run][tool][i], jerk_z_tip_estimator[subject][segment][run][tool][i]]\n",
    "                    norm_tip_jerk[subject][segment][run][tool].append(LA.norm(j,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcef53f-b51a-4f89-9a06-fa266b4e83b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### angular velocity norm (top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c41c09d8-3ade-4940-8a94-e9cf8b6e9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_w={}\n",
    "for subject in subject_list:\n",
    "    norm_w[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        norm_w[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            norm_w[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                norm_w[subject][segment][run][tool]=[]\n",
    "                for i in range(len(angular_vel_x_top_estimator[subject][segment][run][tool])):\n",
    "                    # put x,y,y values in a vector and compute vector norm [wx,vwy,wz]\n",
    "                    w = [angular_vel_x_top_estimator[subject][segment][run][tool][i], angular_vel_y_top_estimator[subject][segment][run][tool][i],angular_vel_z_top_estimator[subject][segment][run][tool][i]]\n",
    "                    norm_w[subject][segment][run][tool].append(LA.norm(w,2)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cf4746-9228-4e4a-9867-bb52acdf9c61",
   "metadata": {
    "tags": []
   },
   "source": [
    "# METRICS kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e197b-c1c6-47cc-831e-16c9b98fa2df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK1 path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "088a9c1e-5ad6-401c-8256-fc67ffe855e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PL = {}\n",
    "for subject in subject_list:\n",
    "    PL[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        PL[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            PL[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time = time_vector_interp[subject][segment][run][tool + '_x'] - time_vector_interp[subject][segment][run][tool + '_x'][0]\n",
    "                data = norm_tip_speed[subject][segment][run][tool]\n",
    "                \n",
    "                # need to emove NAN before integrating (NaN values coming from the interpolation, but not a huge amount)\n",
    "                bool_tmp = np.isnan(data)\n",
    "                inv_bool_tmp = [not elem for elem in bool_tmp]\n",
    "                data_clean = [o for o in data if np.isnan(o) == False]\n",
    "                time_clean = time[inv_bool_tmp]\n",
    "                # integration of the tip speed\n",
    "                PL[subject][segment][run][tool] = (scipy.integrate.cumtrapz(data_clean, time_clean, initial=0))[-1]\n",
    "\n",
    "# put subjects into categories\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "PL_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    PL_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK1_PL','PL_data_SEGMENT' + segment +'.csv') #file names\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                       \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                pl_tweezer = PL[subject][segment][run]['tweezer']\n",
    "                pl_nh = PL[subject][segment][run]['needle_holder2']\n",
    "                # add row in the csv with the specialty, the path length for the tweezer and the needle holder for each recording (3 for each subjects)\n",
    "                row = [cat, pl_tweezer, pl_nh] \n",
    "                writer.writerow(row)\n",
    "                PL_segment_subject_expertise[segment].append(row) #save data on python if we want to perform the anova here\n",
    "    f.close() \n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60015a47-b381-47b0-bed9-602554bcc7c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK2 Average velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "00064b7b-e111-4a33-b972-f47aae379634",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_vel = {}\n",
    "duration_run={}\n",
    "for subject in subject_list:\n",
    "    av_vel[subject]={}\n",
    "    duration_run[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        av_vel[subject][segment]={}\n",
    "        duration_run[subject][segment]= {}\n",
    "        for run in run_list[subject]:\n",
    "            av_vel[subject][segment][run]={}\n",
    "            duration_run[subject][segment][run] = np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0] \n",
    "            for tool in tools_name:\n",
    "                time = duration_run[subject][segment][run]\n",
    "                data = PL[subject][segment][run][tool] \n",
    "                #nan values already removed in PL\n",
    "                av_vel[subject][segment][run][tool] = 1/time * data\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "av_vel_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    av_vel_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK2_AV_VEL','av_vel_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                val_tweezer = av_vel[subject][segment][run]['tweezer']\n",
    "                val_nh = av_vel[subject][segment][run]['needle_holder2']\n",
    "                row = [cat, val_tweezer, val_nh]\n",
    "                writer.writerow(row)\n",
    "                av_vel_segment_subject_expertise[segment].append(row)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271de29e-6bd1-483f-a062-86e0811f6a4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK3 depth percpetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0446e693-39f5-48a3-a0b6-103486b3dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_perception = {}\n",
    "for subject in subject_list:\n",
    "    depth_perception[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        depth_perception[subject][segment]= {}\n",
    "        for run in run_list[subject]:\n",
    "            depth_perception[subject][segment][run] = {}\n",
    "            for tool in tools_name:\n",
    "                time_int = time_vector_interp[subject][segment][run][tool + '_x'] - time_vector_interp[subject][segment][run][tool + '_x'][0]\n",
    "                data = abs(speed_y_tip_estimator[subject][segment][run][tool])\n",
    "                \n",
    "                # need to emove NAN before integrating\n",
    "                bool_tmp = np.isnan(data)\n",
    "                inv_bool_tmp = [not elem for elem in bool_tmp]\n",
    "                data_clean = [o for o in data if np.isnan(o) == False]\n",
    "                time_clean = time_int[inv_bool_tmp]\n",
    "                \n",
    "                depth_perception[subject][segment][run][tool] = (scipy.integrate.cumtrapz(data_clean, time_clean, initial=0))[-1]\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "depth_perception_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    depth_perception_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK3_DP','DP_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                val_tweezer = depth_perception[subject][segment][run]['tweezer']\n",
    "                val_nh = depth_perception[subject][segment][run]['needle_holder2']\n",
    "                row = [cat, val_tweezer, val_nh]\n",
    "                writer.writerow(row)\n",
    "                depth_perception_segment_subject_expertise[segment].append(row)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97adb3-cb89-4b31-a564-887ac58b9371",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK4 Average acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f168053-f149-4493-a955-f19c2914eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_acc = {}\n",
    "for subject in subject_list:\n",
    "    av_acc[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        av_acc[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            av_acc[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time_int = time_vector_interp[subject][segment][run][tool + '_x'] - time_vector_interp[subject][segment][run][tool + '_x'][0]\n",
    "                time = duration_run[subject][segment][run] \n",
    "                data = norm_tip_acc[subject][segment][run][tool]\n",
    "                \n",
    "                # need to emove NAN before integrating\n",
    "                bool_tmp = np.isnan(data)\n",
    "                inv_bool_tmp = [not elem for elem in bool_tmp]\n",
    "                data_clean = [o for o in data if np.isnan(o) == False]\n",
    "                time_clean = time_int[inv_bool_tmp]\n",
    "                \n",
    "                int_acc = (scipy.integrate.cumtrapz(data_clean, time_clean, initial=0))[-1]\n",
    "                av_acc[subject][segment][run][tool] = 1/time * int_acc\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "av_acc_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    av_acc_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK4_AV_ACC','av_acc_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                val_tweezer = av_acc[subject][segment][run]['tweezer']\n",
    "                val_nh = av_acc[subject][segment][run]['needle_holder2']\n",
    "                row = [cat, val_tweezer, val_nh]\n",
    "                writer.writerow(row)\n",
    "                av_acc_segment_subject_expertise[segment].append(row)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41c09e-d68c-4c73-abbf-031b6af7e4f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MK5 Motion smoothness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cec376-3ba8-4561-a3f2-b76654b1940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = {}\n",
    "for subject in subject_list:\n",
    "    ms[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        ms[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            ms[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time_int = time_vector_interp[subject][segment][run][tool + '_x'] - time_vector_interp[subject][segment][run][tool + '_x'][0]\n",
    "                time = duration_run[subject][segment][run] \n",
    "                \n",
    "                # need to emove NAN  from speed values to get true max value\n",
    "                speed_clean = [o for o in norm_tip_speed[subject][segment][run][tool] if np.isnan(o) == False]\n",
    "                vmax = max(speed_clean)\n",
    "                \n",
    "                data = np.array(norm_tip_jerk[subject][segment][run][tool])**2\n",
    "                # need to emove NAN before integrating\n",
    "                bool_tmp = np.isnan(data)\n",
    "                inv_bool_tmp = [not elem for elem in bool_tmp]\n",
    "                data_clean = [o for o in data if np.isnan(o) == False]\n",
    "                time_clean = time_int[inv_bool_tmp]\n",
    "                int_jerk2 = (scipy.integrate.cumtrapz(data_clean, time_clean, initial=0))[-1] #integrating jerk \n",
    "                \n",
    "                ms[subject][segment][run][tool] = -np.log(time**3/vmax**2 * int_jerk2)\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "ms_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    ms_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK5_MS','ms_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                val_tweezer = ms[subject][segment][run]['tweezer']\n",
    "                val_nh = ms[subject][segment][run]['needle_holder2']\n",
    "                row = [cat, val_tweezer, val_nh]\n",
    "                writer.writerow(row)\n",
    "                ms_segment_subject_expertise[segment].append(row)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a4e8b-2050-4ec6-a566-b0f75a7bd0d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK6 Angular length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e413663-c3b5-4ae2-bde2-e8786d1f4682",
   "metadata": {},
   "outputs": [],
   "source": [
    "angular_length = {}\n",
    "for subject in subject_list:\n",
    "    angular_length [subject]={}\n",
    "    for segment in segment_list:     \n",
    "        angular_length [subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            angular_length [subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time = time_vector_interp[subject][segment][run][tool + '_x'] - time_vector_interp[subject][segment][run][tool + '_x'][0]\n",
    "                data = norm_w[subject][segment][run][tool]\n",
    "                \n",
    "                # need to emove NAN before integrating\n",
    "                bool_tmp = np.isnan(data)\n",
    "                inv_bool_tmp = [not elem for elem in bool_tmp]\n",
    "                data_clean = [o for o in data if np.isnan(o) == False]\n",
    "                time_clean = time[inv_bool_tmp]\n",
    "\n",
    "                angular_length [subject][segment][run][tool] = (scipy.integrate.cumtrapz(data_clean, time_clean, initial=0))[-1]\n",
    "\n",
    "                \n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "AL_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    AL_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK6_AL','PL_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                al_tweezer = angular_length [subject][segment][run]['tweezer']\n",
    "                al_nh = angular_length [subject][segment][run]['needle_holder2']\n",
    "                row = [cat, al_tweezer, al_nh]\n",
    "                writer.writerow(row)\n",
    "                AL_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e0d2e2-0e84-45ac-92a1-b89c305a374e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK8 Traveled distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd6ddd5b-290a-41ed-82c1-ed189f9358bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_travel_x = {}\n",
    "range_travel_y = {}\n",
    "range_travel_z = {}\n",
    "\n",
    "for subject in subject_list:   \n",
    "    range_travel_x[subject] = {}\n",
    "    range_travel_y[subject] = {}\n",
    "    range_travel_z[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        range_travel_x[subject][segment] = {}\n",
    "        range_travel_y[subject][segment] = {}\n",
    "        range_travel_z[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            range_travel_x[subject][segment][run] = {}\n",
    "            range_travel_y[subject][segment][run] = {}\n",
    "            range_travel_z[subject][segment][run] = {}\n",
    "            for tool in tools_name:\n",
    "                range_travel_x[subject][segment][run][tool] = []\n",
    "                range_travel_y[subject][segment][run][tool] = []\n",
    "                range_travel_z[subject][segment][run][tool] = []\n",
    "                \n",
    "                \n",
    "\n",
    "for subject in subject_list: \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]:\n",
    "            for tool in tools_name:\n",
    "                # remove Nan values\n",
    "                pos_x_clean  = [o for o in pos_x_tip_filter[subject][segment][run][tool] if np.isnan(o) == False]\n",
    "                pos_y_clean  = [o for o in pos_y_tip_filter[subject][segment][run][tool] if np.isnan(o) == False]\n",
    "                pos_z_clean  = [o for o in pos_z_tip_filter[subject][segment][run][tool] if np.isnan(o) == False]\n",
    "                \n",
    "                range_travel_x[subject][segment][run][tool] = max(pos_x_clean ) - min(pos_x_clean )\n",
    "                range_travel_y[subject][segment][run][tool] = max(pos_y_clean ) - min(pos_y_clean )      \n",
    "                range_travel_z[subject][segment][run][tool] = max(pos_z_clean ) - min(pos_z_clean )\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "TD_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    TD_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK8_TD','TD_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer_x','val_tweezer_y','val_tweezer_z','val_nh_x','val_nh_y','val_nh_z']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                row = [cat, range_travel_x[subject][segment][run]['tweezer'],range_travel_y[subject][segment][run]['tweezer'],range_travel_z[subject][segment][run]['tweezer'],\n",
    "                       range_travel_x[subject][segment][run]['needle_holder2'],range_travel_y[subject][segment][run]['needle_holder2'],range_travel_z[subject][segment][run]['needle_holder2']]\n",
    "                writer.writerow(row)\n",
    "                TD_segment_subject_expertise[segment].append(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee352cf-ca3c-4c29-aed1-3bf5c70427e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK7 max covered volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4487a1-205d-46d3-8df0-9dd119127a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_volume={}\n",
    "for subject in subject_list: \n",
    "    range_volume[subject]={}\n",
    "    for segment in segment_list:\n",
    "        range_volume[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            range_volume[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                range_volume[subject][segment][run][tool]= range_travel_x[subject][segment][run][tool]*range_travel_y[subject][segment][run][tool]*range_travel_z[subject][segment][run][tool]\n",
    "                \n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "VTD_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    VTD_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK7_VTD','VTD_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                row = [cat, range_volume[subject][segment][run]['tweezer'],range_volume[subject][segment][run]['needle_holder2']]\n",
    "                writer.writerow(row)\n",
    "                VTD_segment_subject_expertise[segment].append(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c79a5-644f-4a1e-9989-e530568a8cfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## MK9 economy of volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f86bb99f-5dcf-4682-b11b-0d5007b98422",
   "metadata": {},
   "outputs": [],
   "source": [
    "eov={}\n",
    "for subject in subject_list: \n",
    "    eov[subject]={}\n",
    "    for segment in segment_list:\n",
    "        eov[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            eov[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                eov[subject][segment][run][tool] = 100/(PL[subject][segment][run][tool] )*(range_volume[subject][segment][run][tool])**(1/3) #nan alreadzy removed in PL\n",
    "                \n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "eov_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    eov_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK9_EOV','EOV_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                row = [cat, eov[subject][segment][run]['tweezer'],eov[subject][segment][run]['needle_holder2']]\n",
    "                writer.writerow(row)\n",
    "                eov_segment_subject_expertise[segment].append(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e56c0-98d6-47e2-9993-0721d6c1e6b2",
   "metadata": {},
   "source": [
    "## MK10 Bimanual dexterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7817f21f-efa4-42fa-b1a1-3d55ccf97510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not same size, take first part, subject S3run R4segment 530\n",
      "not same size, take first part, subject S4run R4segment 530\n",
      "not same size, take first part, subject S5run R5segment 540\n",
      "not same size, take first part, subject S6run R5segment 560\n",
      "not same size, take first part, subject S7run R1segment 510\n",
      "not same size, take first part, subject S7run R1segment 530\n",
      "not same size, take first part, subject S7run R1segment 540\n",
      "not same size, take first part, subject S7run R1segment 541\n",
      "not same size, take first part, subject S8run R3segment 500\n",
      "not same size, take first part, subject S8run R4segment 510\n",
      "not same size, take first part, subject S9run R3segment 510\n",
      "not same size, take first part, subject S12run R3segment 530\n",
      "not same size, take first part, subject S12run R1segment 540\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BD={}\n",
    "for subject in subject_list: \n",
    "    BD[subject]={}\n",
    "    for segment in segment_list:\n",
    "        BD[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            BD[subject][segment][run]=[]\n",
    "            \n",
    "            # data coming from interpolation with the same time vector: for one position, the data from the 2 tools correspond to the same timestamp\n",
    "            data_nh = np.array(norm_tip_speed[subject][segment][run][\"needle_holder2\"]) \n",
    "            data_tweezer = np.array(norm_tip_speed[subject][segment][run][\"tweezer\"])\n",
    "            \n",
    "            \n",
    "            #case if we miss last values of one tool (miss the tracking of the last values, set to 0 in the raw data)\n",
    "            # = the interpolation is not filling this hole, so the number of values is not the same for the two tools (ex S3 r4 seg 530)\n",
    "            # take for the two tools the maximum number of values available for both tools\n",
    "            if len(data_nh )!= len(data_tweezer ): \n",
    "                print(\"not same size, take first part, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(data_tweezer), len(data_nh ))\n",
    "                data_nh = np.array(norm_tip_speed[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "                data_tweezer = np.array(norm_tip_speed[subject][segment][run][\"tweezer\"][0:M])\n",
    "\n",
    "        \n",
    "            # need to emove NAN before taking correlation\n",
    "            #remove Nan from tweezer and corresponding values in the nh\n",
    "            bool_tweezer = np.isnan(data_tweezer)\n",
    "            inv_bool_tweezer = [not elem for elem in bool_tweezer]\n",
    "            data_clean_tweezer_tmp = np.array([o for o in data_tweezer if np.isnan(o) == False]) \n",
    "            data_clean_nh_tmp = data_nh[inv_bool_tweezer] \n",
    "            #remove nan from nh and corresponding values in the tweezer\n",
    "            bool_nh = np.isnan(data_clean_nh_tmp)\n",
    "            inv_bool_nh = [not elem for elem in bool_nh]\n",
    "            data_clean_nh = [o for o in data_clean_nh_tmp if np.isnan(o) == False] \n",
    "            data_clean_tweezer = data_clean_tweezer_tmp[inv_bool_nh ] \n",
    "\n",
    "            # check that you have the same number of points in the teo tools\n",
    "            # should be ok as the coresp. nan were removed for the 2 tools\n",
    "            if len(data_clean_tweezer )!= len(data_clean_nh ):\n",
    "                print(\"not same size clean data = pb, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                \n",
    "            # compute correlation\n",
    "            tmp_mat_BD = np.corrcoef(data_clean_tweezer, data_clean_nh) \n",
    "\n",
    "            BD[subject][segment][run]= tmp_mat_BD[0,1]\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "BD_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    BD_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK10_BD','V2BD_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_BD']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                row = [cat, BD[subject][segment][run]]\n",
    "                writer.writerow(row)\n",
    "                BD_segment_subject_expertise[segment].append(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a160d536-0972-4825-903e-60c6b1526891",
   "metadata": {},
   "source": [
    "### directional (speed x, y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ca7af353-38b8-45b4-8f98-e263a99d84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not same size, take first part, direction x, subject S3run R4segment 530\n",
      "not same size, take first part, direction y, subject S3run R4segment 530\n",
      "not same size, take first part, direction z, subject S3run R4segment 530\n",
      "not same size, take first part, direction x, subject S4run R4segment 530\n",
      "not same size, take first part, direction y, subject S4run R4segment 530\n",
      "not same size, take first part, direction z, subject S4run R4segment 530\n",
      "not same size, take first part, direction x, subject S5run R5segment 540\n",
      "not same size, take first part, direction y, subject S5run R5segment 540\n",
      "not same size, take first part, direction z, subject S5run R5segment 540\n",
      "not same size, take first part, direction x, subject S6run R5segment 560\n",
      "not same size, take first part, direction y, subject S6run R5segment 560\n",
      "not same size, take first part, direction z, subject S6run R5segment 560\n",
      "not same size, take first part, direction x, subject S7run R1segment 510\n",
      "not same size, take first part, direction y, subject S7run R1segment 510\n",
      "not same size, take first part, direction z, subject S7run R1segment 510\n",
      "not same size, take first part, direction x, subject S7run R1segment 530\n",
      "not same size, take first part, direction y, subject S7run R1segment 530\n",
      "not same size, take first part, direction z, subject S7run R1segment 530\n",
      "not same size, take first part, direction x, subject S7run R1segment 540\n",
      "not same size, take first part, direction y, subject S7run R1segment 540\n",
      "not same size, take first part, direction z, subject S7run R1segment 540\n",
      "not same size, take first part, direction x, subject S7run R1segment 541\n",
      "not same size, take first part, direction y, subject S7run R1segment 541\n",
      "not same size, take first part, direction z, subject S7run R1segment 541\n",
      "not same size, take first part, direction x, subject S8run R3segment 500\n",
      "not same size, take first part, direction y, subject S8run R3segment 500\n",
      "not same size, take first part, direction z, subject S8run R3segment 500\n",
      "not same size, take first part, direction x, subject S8run R4segment 510\n",
      "not same size, take first part, direction y, subject S8run R4segment 510\n",
      "not same size, take first part, direction z, subject S8run R4segment 510\n",
      "not same size, take first part, direction x, subject S9run R3segment 510\n",
      "not same size, take first part, direction y, subject S9run R3segment 510\n",
      "not same size, take first part, direction z, subject S9run R3segment 510\n",
      "not same size, take first part, direction x, subject S12run R3segment 530\n",
      "not same size, take first part, direction y, subject S12run R3segment 530\n",
      "not same size, take first part, direction z, subject S12run R3segment 530\n",
      "not same size, take first part, direction x, subject S12run R1segment 540\n",
      "not same size, take first part, direction y, subject S12run R1segment 540\n",
      "not same size, take first part, direction z, subject S12run R1segment 540\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BD_x={}\n",
    "BD_y={}\n",
    "BD_z={}\n",
    "for subject in subject_list: \n",
    "    BD_x[subject]={}\n",
    "    BD_y[subject]={}\n",
    "    BD_z[subject]={}\n",
    "    for segment in segment_list:\n",
    "        BD_x[subject][segment] = {}\n",
    "        BD_y[subject][segment] = {}\n",
    "        BD_z[subject][segment] = {}\n",
    "        for run in run_list[subject]:\n",
    "            BD_x[subject][segment][run]=[]\n",
    "            BD_y[subject][segment][run]=[]\n",
    "            BD_z[subject][segment][run]=[]\n",
    "            \n",
    "            # data coming from interpolation with the same time vector: for one position, the data from the 2 tools correspond to the same timestamp\n",
    "            data_nh_x = np.array(speed_x_tip_estimator[subject][segment][run][\"needle_holder2\"]) \n",
    "            data_tweezer_x = np.array(speed_x_tip_estimator[subject][segment][run][\"tweezer\"])\n",
    "            data_nh_y = np.array(speed_y_tip_estimator[subject][segment][run][\"needle_holder2\"]) \n",
    "            data_tweezer_y = np.array(speed_y_tip_estimator[subject][segment][run][\"tweezer\"])\n",
    "            data_nh_z = np.array(speed_z_tip_estimator[subject][segment][run][\"needle_holder2\"]) \n",
    "            data_tweezer_z = np.array(speed_z_tip_estimator[subject][segment][run][\"tweezer\"])\n",
    "            \n",
    "            #case if we miss last values of one tool (miss the tracking of the last values, set to 0 in the raw data)\n",
    "            # = the interpolation is not filling this hole, so the number of values is not the same for the two tools (ex S3 r4 seg 530)\n",
    "            # take for the two tools the maximum number of values available for both tools\n",
    "            if len(data_nh_x )!= len(data_tweezer_x ): \n",
    "                print(\"not same size, take first part, direction x, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(data_tweezer_x), len(data_nh_x ))\n",
    "                data_nh_x = np.array(speed_x_tip_estimator[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "                data_tweezer_x = np.array(speed_x_tip_estimator[subject][segment][run][\"tweezer\"][0:M])\n",
    "            \n",
    "            if len(data_nh_y )!= len(data_tweezer_y ): \n",
    "                print(\"not same size, take first part, direction y, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(data_tweezer_y), len(data_nh_y))\n",
    "                data_nh_y= np.array(speed_y_tip_estimator[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "                data_tweezer_y = np.array(speed_y_tip_estimator[subject][segment][run][\"tweezer\"][0:M])\n",
    "                \n",
    "            if len(data_nh_z )!= len(data_tweezer_z ): \n",
    "                print(\"not same size, take first part, direction z, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(data_tweezer_z), len(data_nh_z ))\n",
    "                data_nh_z = np.array(speed_z_tip_estimator[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "                data_tweezer_z = np.array(speed_z_tip_estimator[subject][segment][run][\"tweezer\"][0:M])\n",
    "\n",
    "        \n",
    "            # need to emove NAN before taking correlation\n",
    "            #remove Nan from tweezer and corresponding values in the nh\n",
    "            bool_tweezer_x = np.isnan(data_tweezer_x)\n",
    "            inv_bool_tweezer_x = [not elem for elem in bool_tweezer_x]\n",
    "            data_clean_tweezer_tmp_x = np.array([o for o in data_tweezer_x if np.isnan(o) == False]) \n",
    "            data_clean_nh_tmp_x = data_nh_x[inv_bool_tweezer_x] \n",
    "            #remove nan from nh and corresponding values in the tweezer\n",
    "            bool_nh_x = np.isnan(data_clean_nh_tmp_x)\n",
    "            inv_bool_nh_x = [not elem for elem in bool_nh_x]\n",
    "            data_clean_nh_x = [o for o in data_clean_nh_tmp_x if np.isnan(o) == False] \n",
    "            data_clean_tweezer_x = data_clean_tweezer_tmp_x[inv_bool_nh_x ] \n",
    "\n",
    "            # check that you have the same number of points in the teo tools\n",
    "            # should be ok as the coresp. nan were removed for the 2 tools\n",
    "            if len(data_clean_tweezer_x )!= len(data_clean_nh_x ):\n",
    "                print(\"not same size clean data_x = pb, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                \n",
    "            # compute correlation\n",
    "            tmp_mat_BD_x = np.corrcoef(data_clean_tweezer_x, data_clean_nh_x) \n",
    "            BD_x[subject][segment][run]= tmp_mat_BD_x[0,1]\n",
    "            \n",
    "            bool_tweezer_y = np.isnan(data_tweezer_y)\n",
    "            inv_bool_tweezer_y = [not elem for elem in bool_tweezer_y]\n",
    "            data_clean_tweezer_tmp_y = np.array([o for o in data_tweezer_y if np.isnan(o) == False]) \n",
    "            data_clean_nh_tmp_y = data_nh_y[inv_bool_tweezer_y] \n",
    "            bool_nh_y = np.isnan(data_clean_nh_tmp_y)\n",
    "            inv_bool_nh_y = [not elem for elem in bool_nh_y]\n",
    "            data_clean_nh_y = [o for o in data_clean_nh_tmp_y if np.isnan(o) == False] \n",
    "            data_clean_tweezer_y = data_clean_tweezer_tmp_y[inv_bool_nh_y] \n",
    "            if len(data_clean_tweezer_y )!= len(data_clean_nh_y ):\n",
    "                print(\"not same size clean data_y = pb, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "            tmp_mat_BD_y = np.corrcoef(data_clean_tweezer_y, data_clean_nh_y) \n",
    "            BD_y[subject][segment][run]= tmp_mat_BD_y[0,1]\n",
    "            \n",
    "            \n",
    "            bool_tweezer_z = np.isnan(data_tweezer_z)\n",
    "            inv_bool_tweezer_z = [not elem for elem in bool_tweezer_z]\n",
    "            data_clean_tweezer_tmp_z = np.array([o for o in data_tweezer_z if np.isnan(o) == False]) \n",
    "            data_clean_nh_tmp_z = data_nh_z[inv_bool_tweezer_z] \n",
    "            bool_nh_z = np.isnan(data_clean_nh_tmp_z)\n",
    "            inv_bool_nh_z = [not elem for elem in bool_nh_z]\n",
    "            data_clean_nh_z = [o for o in data_clean_nh_tmp_z if np.isnan(o) == False] \n",
    "            data_clean_tweezer_z = data_clean_tweezer_tmp_z[inv_bool_nh_z ] \n",
    "            if len(data_clean_tweezer_z )!= len(data_clean_nh_z ):\n",
    "                print(\"not same size clean data_z = pb, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "            tmp_mat_BD_z = np.corrcoef(data_clean_tweezer_z, data_clean_nh_z) \n",
    "            BD_z[subject][segment][run]= tmp_mat_BD_z[0,1]\n",
    "            \n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12','S9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MK10_BD','BD_DIR_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_BD_x','val_BD_y','val_BD_z']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                row = [cat, BD_x[subject][segment][run],BD_y[subject][segment][run],BD_z[subject][segment][run]]\n",
    "                writer.writerow(row)\n",
    "    f.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1928b-9167-48fc-87a0-7d0d1811f8a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# METRICS TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342139d-77ce-4454-ada5-30b48edb35ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MT1: completion time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49120d88-56fa-4a1e-8bb4-912733158f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list_time = ['S2','S3','S4','S5','S6','S7','S8','S10','S11','S12'] #removed subject 9 because clear outlier\n",
    "# removed subject 1 because not used for optitrack\n",
    "\n",
    "duration_run_segments = {}\n",
    "mean_duration_run_segments ={}\n",
    "std_duration_run_segments ={}\n",
    "for subject in subject_list_time:\n",
    "    duration_run_segments[subject] = {} \n",
    "    mean_duration_run_segments[subject] = {} \n",
    "    std_duration_run_segments[subject] = {}  \n",
    "    for segment in segment_list:\n",
    "        duration_run_segments[subject][segment] = [] \n",
    "        mean_duration_run_segments[subject][segment] = []\n",
    "        std_duration_run_segments[subject][segment] = []\n",
    "\n",
    "        \n",
    "        \n",
    "for subject in subject_list_time:\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject]: \n",
    "            # take the duration of the 3 runs for each segment, based on the time value of the optitrack recordings (most reliable)\n",
    "            duration_run_segments[subject][segment].append(np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0] )\n",
    "        # compute mean and std value over the 3 runs\n",
    "        mean_duration_run_segments[subject][segment] = np.mean(duration_run_segments[subject][segment])\n",
    "        std_duration_run_segments[subject][segment] = np.std(duration_run_segments[subject][segment])\n",
    "\n",
    "        \n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "time_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    time_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','time','time_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                      \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','value']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                # compute again duration, can use duration_run_segments\n",
    "                time = np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0]\n",
    "                row = [cat, time]\n",
    "                writer.writerow(row)\n",
    "                time_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70fd5f-01e6-4c35-ba7e-9e08a0c51c65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MT2: Idle time (need v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d56b4078-0b46-4dac-aa05-48b72cf873ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not same size, take first part, subject S3run R4segment 530\n",
      "not same size, take first part, subject S4run R4segment 530\n",
      "not same size, take first part, subject S5run R5segment 540\n",
      "not same size, take first part, subject S6run R5segment 560\n",
      "not same size, take first part, subject S7run R1segment 510\n",
      "not same size, take first part, subject S7run R1segment 530\n",
      "not same size, take first part, subject S7run R1segment 540\n",
      "not same size, take first part, subject S7run R1segment 541\n",
      "not same size, take first part, subject S8run R3segment 500\n",
      "not same size, take first part, subject S8run R4segment 510\n",
      "not same size, take first part, subject S12run R3segment 530\n",
      "not same size, take first part, subject S12run R1segment 540\n"
     ]
    }
   ],
   "source": [
    "#compute amount of time that the speed of the tip is below a threshold\n",
    "\n",
    "#fixed threshold\n",
    "threshold_idle = 0.008 #threshold speed, m/s\n",
    "# choice of threshold based on one example of an expert surgeon, based on the mean value of the absolute speed of the tool when we consider the tool still (R4, S10, s500)\n",
    "idle_time ={}\n",
    "for subject in subject_list_time:\n",
    "    idle_time[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        idle_time[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            idle_time[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                # threshold based on a percentage of the average velocity\n",
    "                #threshold_idle = 5/100 * av_vel[subject][segment][run][tool] \n",
    "                \n",
    "                time = time_vector_interp[subject][segment][run][tool + '_x']\n",
    "                data = (pd.DataFrame(norm_tip_speed[subject][segment][run][tool]))[0] #speed of tip\n",
    "                idle_time[subject][segment][run][tool] = 1/120*len(data[data<threshold_idle]) #time = nb of values * 1/frequency of acquisition\n",
    "\n",
    "# time with both hands speed under threshold\n",
    "idle_time_both_hands ={}\n",
    "for subject in subject_list_time:\n",
    "    idle_time_both_hands[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        idle_time_both_hands[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            # threshold based on a percentage of the average velocity\n",
    "            #threshold_idle = 5/100 * av_vel[subject][segment][run][tool] \n",
    "            \n",
    "            idle_time_both_hands[subject][segment][run]={}\n",
    "            time = time_vector_interp[subject][segment][run]['tweezer_x']\n",
    "            data_tweezer = (np.array(norm_tip_speed[subject][segment][run]['tweezer']))#[0] #speed of tip tweezer\n",
    "            data_nh = (np.array(norm_tip_speed[subject][segment][run]['needle_holder2']))#[0] #speed of tip nh\n",
    "            \n",
    "            if len(data_nh )!= len(data_tweezer ): \n",
    "                print(\"not same size, take first part, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(data_tweezer), len(data_nh ))\n",
    "                data_nh = np.array(norm_tip_speed[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "                data_tweezer = np.array(norm_tip_speed[subject][segment][run][\"tweezer\"][0:M])\n",
    "\n",
    "            count = 0\n",
    "\n",
    "            for i in range(len(data_tweezer)-1):\n",
    "                if (data_tweezer[i]< threshold_idle) and (data_nh[i] < threshold_idle):\n",
    "                    count = count +1\n",
    "                        \n",
    "            idle_time_both_hands[subject][segment][run] = 1/120*count #time = nb of values * 1/frequency of acquisition\n",
    "                #               idle_time_both_hands \n",
    "\n",
    "        \n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "idle_time_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    idle_time_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    #print(segment)\n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MT2_idle_time','idle_time_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer', 'val_nh', 'val_both_hands']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            #print(subject)\n",
    "            for run in run_list[subject]:\n",
    "                \n",
    "                time_tweezers = idle_time[subject][segment][run]['tweezer']\n",
    "                time_nh = idle_time[subject][segment][run]['needle_holder2']\n",
    "                time_both_hands = idle_time_both_hands[subject][segment][run]\n",
    "                row = [cat, time_tweezers, time_nh, time_both_hands]\n",
    "                writer.writerow(row)\n",
    "                idle_time_segment_subject_expertise[segment].append(row)\n",
    "                \n",
    "                # to check the values \n",
    "                #print('RUN: ' + run + ' Tweezers ' + str(time_tweezers) + ' Total: ' + str(np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0]))\n",
    "                \n",
    "    f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea98d4b-58e1-4bab-9087-af458398b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plots to test visually different thresholds\n",
    "\n",
    "for segment in segment_list: \n",
    "    #print(segment)\n",
    "    data_tw_novice = np.array(idle_time_segment_subject_expertise[segment])[0:6,1]\n",
    "    data_nh_novice = np.array(idle_time_segment_subject_expertise[segment])[0:6,2]\n",
    "    data_bh_novice = np.array(idle_time_segment_subject_expertise[segment])[0:6,3]\n",
    "    data_tw_int = np.array(idle_time_segment_subject_expertise[segment])[6:21,1]\n",
    "    data_nh_int = np.array(idle_time_segment_subject_expertise[segment])[6:21,2]\n",
    "    data_bh_int = np.array(idle_time_segment_subject_expertise[segment])[6:21,3]\n",
    "    data_tw_exp = np.array(idle_time_segment_subject_expertise[segment])[21:30,1]\n",
    "    data_nh_exp = np.array(idle_time_segment_subject_expertise[segment])[21:30,2]\n",
    "    data_bh_exp = np.array(idle_time_segment_subject_expertise[segment])[21:30,3]\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3,figsize=(10, 2.8))\n",
    "    \n",
    "    ax1 = axs[0]\n",
    "    ax2 = axs[1]\n",
    "    ax3 = axs[2]\n",
    "\n",
    "    bplot = ax1.boxplot([data_tw_novice.astype(float),data_tw_int.astype(float),data_tw_exp.astype(float)], notch=None, sym=None, vert=None, whis=None, positions=None,\n",
    "                              widths=None, patch_artist=True, bootstrap=None, usermedians=None, conf_intervals=None, meanline=None,\n",
    "                              showmeans=None, showcaps=None, showbox=None, showfliers=None, boxprops=None, labels=None, flierprops=None, medianprops=None, meanprops=None,\n",
    "                              capprops=None, whiskerprops=None, manage_ticks=True, autorange=False, zorder=None, data=None)\n",
    "    colors = ['lightblue', 'lightgreen','lightpink']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    plt.ylabel('Time [s]')\n",
    "    ax1.set_title('tweezer, Segment: ' + str(segment), fontdict=None, loc='center', pad=None)\n",
    "    ax1.grid(axis = 'y')   \n",
    "    \n",
    "    bplot = ax2.boxplot([data_nh_novice.astype(float),data_nh_int.astype(float),data_nh_exp.astype(float)], notch=None, sym=None, vert=None, whis=None, positions=None,\n",
    "                              widths=None, patch_artist=True, bootstrap=None, usermedians=None, conf_intervals=None, meanline=None,\n",
    "                              showmeans=None, showcaps=None, showbox=None, showfliers=None, boxprops=None, labels=None, flierprops=None, medianprops=None, meanprops=None,\n",
    "                              capprops=None, whiskerprops=None, manage_ticks=True, autorange=False, zorder=None, data=None)\n",
    "    colors = ['lightblue', 'lightgreen','lightpink']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    plt.ylabel('Time [s]')\n",
    "    ax2.set_title('Segment: ' + str(segment)+' ,needle holder', fontdict=None, loc='center', pad=None)\n",
    "    ax2.grid(axis = 'y')   \n",
    "    bplot = ax3.boxplot([data_bh_novice.astype(float),data_bh_int.astype(float),data_bh_exp.astype(float)], notch=None, sym=None, vert=None, whis=None, positions=None,\n",
    "                              widths=None, patch_artist=True, bootstrap=None, usermedians=None, conf_intervals=None, meanline=None,\n",
    "                              showmeans=None, showcaps=None, showbox=None, showfliers=None, boxprops=None, labels=None, flierprops=None, medianprops=None, meanprops=None,\n",
    "                              capprops=None, whiskerprops=None, manage_ticks=True, autorange=False, zorder=None, data=None)\n",
    "    colors = ['lightblue', 'lightgreen','lightpink']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    plt.ylabel('Time [s]')\n",
    "    ax3.set_title('Segment: ' + str(segment)+ ' ,both hands', fontdict=None, loc='center', pad=None)\n",
    "    ax3.grid(axis = 'y')    \n",
    "\n",
    "    if not os.path.exists(join('..','data_paper' , 'PLOTS', 'MT2_idle_time')):\n",
    "             os.makedirs(join('..','data_paper', 'PLOTS', 'MT2_idle_time'))\n",
    "\n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'tps_activity_time_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "    plt.savefig(join('..', 'data_paper' , 'PLOTS', 'MT2_idle_time', 'th_'+str(threshold_idle)+'_segment'  + segment + '.png'),bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9bd33b-b7f0-4090-96f7-a83c9a6ed3f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MT3: act percentage considering time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9e378a48-4ccb-44f5-b21e-a569e6608e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pc_time ={}\n",
    "pc_time_both_hands ={}\n",
    "for subject in subject_list_time:\n",
    "    pc_time[subject]={}\n",
    "    pc_time_both_hands[subject]={}\n",
    "    for segment in segment_list:     \n",
    "        pc_time[subject][segment]={}\n",
    "        pc_time_both_hands[subject][segment]={}\n",
    "        for run in run_list[subject]:\n",
    "            pc_time[subject][segment][run]={}\n",
    "            pc_time_both_hands[subject][segment][run]={}\n",
    "            for tool in tools_name:\n",
    "                time = np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0] #duration\n",
    "                pc_time[subject][segment][run][tool] = (time - idle_time[subject][segment][run][tool])/time*100\n",
    "            pc_time_both_hands[subject][segment][run] = (time - idle_time_both_hands[subject][segment][run])/time*100\n",
    "\n",
    "expert_subjects = ['S4','S10','S3']\n",
    "intermediate_subjects = ['S2','S5','S6','S8','S11']\n",
    "novice_subjects = ['S7', 'S12']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "pc_time_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    pc_time_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_paper' )\n",
    "    rs_csv = join(folder,'ANOVA','MT3_pc_time','pc_time_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    writer = csv.writer(f)\n",
    "    header = ['specialty','val_tweezer','val_nh','val_both_hands']\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject]:\n",
    "                time_tweezer = pc_time[subject][segment][run]['tweezer']\n",
    "                time_nh = pc_time[subject][segment][run]['needle_holder2']\n",
    "                time_both_hands = pc_time_both_hands[subject][segment][run]\n",
    "                row = [cat, time_tweezer, time_nh, time_both_hands]\n",
    "                writer.writerow(row)\n",
    "                pc_time_segment_subject_expertise[segment].append(row)\n",
    "    f.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
