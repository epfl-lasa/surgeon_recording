{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34b1710-0c0c-4436-944e-b306f029615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surgeon_recording.synchronization import Synchro\n",
    "from surgeon_recording.reader import Reader\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from scipy import signal as sp\n",
    "import math\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from natsort import natsorted\n",
    "from plotly import subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "import plotly.express as px\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from tabulate import tabulate\n",
    "import scipy.interpolate as inter\n",
    "\n",
    "from pyquaternion import Quaternion\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e1ac11-4a4b-4eb3-b38f-ae501edc5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c3c044-ea78-4f6c-9cc1-f6747180198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_list = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "segment_list = ['500','510','530','540','541','560']\n",
    "\n",
    "sensors = ['optitrack', 'emg', 'TPS_calibrated']\n",
    "\n",
    "tools_tweezer = ['tweezer_x', 'tweezer_y', 'tweezer_z']\n",
    "tools_scissors = ['scissors_x', 'scissors_y', 'scissors_z'] \n",
    "\n",
    "#tools_verif_holder = ['needle_holder_x', 'needle_holder_y', 'needle_holder_z'] #subject 1 (not same name for needle holder, but not used for optitrack analzsis anyway because bad tracking)\n",
    "tools_verif_holder = ['needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z'] #subject 2 to 12\n",
    "\n",
    "# data path, to be adapted\n",
    "path_to_data_folder = '/home/anaelle/git/surgeon_recording/data_exp'              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f6ee4-b27c-41b0-89d2-7e5696556156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# DATA READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa286b87-3893-48e0-b21d-a7f6520d5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_segments = {}\n",
    "mean_segments = {}\n",
    "emg_segment_subject={}\n",
    "tps_segment_subject={}\n",
    "abs_diff_tps = {}\n",
    "range_raw_tps_subject = {}\n",
    "recording_session = {}\n",
    "run_list = {}\n",
    "run_list_emg = {}\n",
    "headers = {}\n",
    "file_list = {}\n",
    "\n",
    "# runs used for each subject for the EMG data. Could be improved to maximize the number of runs available by differentiating for each segment.\n",
    "# was not done here as emg analysis was done rapidly and not thoroughly\n",
    "run_list_emg['1'] = ['1','2','3','4','5']\n",
    "run_list_emg['2'] = ['1','3','4','6','7']\n",
    "run_list_emg['3'] = ['2','3','6', '7']\n",
    "run_list_emg['4'] = ['1','3','4','5','6']\n",
    "run_list_emg['5'] = ['3', '5']\n",
    "run_list_emg['6'] = ['1','5']\n",
    "run_list_emg['7'] = ['1','3','4','6','7']\n",
    "run_list_emg['8'] = ['3','4', '6']\n",
    "run_list_emg['9'] = ['2','3','5', '7']\n",
    "run_list_emg['10'] = ['1','2','4','5','6']\n",
    "run_list_emg['11'] = ['3','4', '5']\n",
    "run_list_emg['12'] = ['1','2','3']\n",
    "\n",
    "# for optitrack and TPS: maximize the number of available runs for each segment separately\n",
    "run_list = {}\n",
    "for subject in subject_list:\n",
    "    run_list[subject] = {}\n",
    "\n",
    "# for subjects 1,2,3,4,7,8,10,11,12: same runs for all segments\n",
    "for segment in segment_list:\n",
    "    run_list['1'][segment] = ['1','2', '3','4','5']\n",
    "    run_list['2'][segment] = ['1','3','4','6','7']\n",
    "    run_list['3'][segment] = ['2','3','4','6', '7']\n",
    "    run_list['4'][segment] = ['1','3','4','5','6']\n",
    "    run_list['7'][segment] = ['1','3','4','6','7']\n",
    "    run_list['8'][segment] = ['1','2','3','4', '6']\n",
    "    run_list['10'][segment] = ['1','2','4','5','6']\n",
    "    run_list['12'][segment] = ['1','2','3']\n",
    "    run_list['11'][segment] = ['1','3','4','5']\n",
    "\n",
    "# for the other: set manually the runs for each segment\n",
    "run_list['5']['500'] = ['3', '5', '6']\n",
    "run_list['5']['510'] = ['1','3', '5', '6']\n",
    "run_list['5']['530'] = ['1','3', '5', '6']\n",
    "run_list['5']['540'] = ['1','3', '5', '6']\n",
    "run_list['5']['541'] = ['1','3', '5', '6']\n",
    "run_list['5']['560'] = ['1','3', '5']\n",
    "\n",
    "run_list['6']['500'] = ['1','2','3','5']\n",
    "run_list['6']['510'] = ['1','2','3','5']\n",
    "run_list['6']['530'] = ['1','2','3','5']\n",
    "run_list['6']['541'] = ['1','2','3','5']\n",
    "run_list['6']['540'] = ['1','2','5']\n",
    "run_list['6']['560'] = ['1','3','5']\n",
    "\n",
    "run_list['9']['540'] = ['2','3','5', '7']\n",
    "run_list['9']['541'] = ['2','3','5', '7'] \n",
    "run_list['9']['560'] = ['2','3','5', '7']\n",
    "run_list['9']['500'] = ['2','3','4','5', '7']\n",
    "run_list['9']['510'] = ['2','3','4','5', '7']\n",
    "run_list['9']['530'] = ['2','3','4','5', '7']\n",
    "\n",
    "# name of the folder (dat of the recording) for each subject\n",
    "recording_session['1'] = '70622'\n",
    "recording_session['2'] = '70622'\n",
    "recording_session['3'] = '80622'\n",
    "recording_session['4'] = '80622'\n",
    "recording_session['5'] = '80622'\n",
    "recording_session['6'] = '90622'\n",
    "recording_session['7'] = '90622'\n",
    "recording_session['8'] = '90622'\n",
    "recording_session['9'] = '90622'\n",
    "recording_session['10']= '100622'\n",
    "recording_session['11']= '100622'\n",
    "recording_session['12']= '100622'\n",
    "\n",
    "# data structure\n",
    "for subject in subject_list:\n",
    "    data_segments[subject] = {}\n",
    "    mean_segments[subject]= {}\n",
    "    file_list[subject] = {}\n",
    "    emg_segment_subject[subject] = {}\n",
    "    tps_segment_subject[subject] = {}\n",
    "    abs_diff_tps[subject] = {}\n",
    "    range_raw_tps_subject[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        data_segments[subject][segment]= {}\n",
    "        file_list[subject][segment] = {}\n",
    "        mean_segments[subject][segment]= {}\n",
    "        emg_segment_subject[subject][segment]={}\n",
    "        tps_segment_subject[subject][segment]={}\n",
    "        abs_diff_tps[subject][segment] = {}\n",
    "        range_raw_tps_subject[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            data_segments[subject][segment][run] = {}\n",
    "            mean_segments[subject][segment][run]= {}\n",
    "            file_list[subject][segment][run] = {}\n",
    "            abs_diff_tps[subject][segment][run] = {}\n",
    "            for sensor in sensors:\n",
    "                data_segments[subject][segment][run][sensor]= {}\n",
    "                mean_segments[subject][segment][run][sensor]= {}\n",
    "                file_list[subject][segment][run][sensor] = []\n",
    "\n",
    "for sensor in sensors:\n",
    "    headers[sensor] = []\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd796fbf-bc41-4434-9749-dc1df20a0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for optitrack and tps\n",
    "for subject in subject_list:        \n",
    "        for sensor in ['optitrack', 'TPS_calibrated']:\n",
    "            for segment in segment_list:\n",
    "                for run in run_list[subject][segment]:\n",
    "                    data_folder = join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION' )\n",
    "                    file_list[subject][segment][run][sensor] = join(data_folder, 'segment_nb_' + segment + '_' + sensor +'.csv')\n",
    "\n",
    "                    file = open(file_list[subject][segment][run][sensor])\n",
    "                    reader = csv.DictReader(file)\n",
    "                    headers[sensor] = reader.fieldnames\n",
    "\n",
    "                    # get the right names from the columns of the csv files, according to each sensor\n",
    "                    if sensor == 'optitrack':\n",
    "                        tools = headers[sensor][3:-1] \n",
    "                    if sensor == 'TPS_calibrated':\n",
    "                        fingers_cal = headers[sensor][15:-1]\n",
    "\n",
    "                    data = pd.read_csv(file_list[subject][segment][run][sensor])\n",
    "        \n",
    "                    # store the data in data_segments variable\n",
    "                    if sensor == 'TPS_calibrated':\n",
    "                        for finger in fingers_cal:                    \n",
    "                            data_segments[subject][segment][run][sensor][finger]= data[finger]\n",
    "                            data_segments[subject][segment][run][sensor]['rel_time'] = data[' relative_time']\n",
    "\n",
    "                    if sensor == 'optitrack':\n",
    "                        for tool in tools:\n",
    "                            data_segments[subject][segment][run][sensor][tool]= data[tool]\n",
    "                            data_segments[subject][segment][run][sensor]['rel_time'] = data['relative_time']              \n",
    "                            \n",
    "# read data for emg (separated because did not continue the analysis thoroughly)                        \n",
    "for subject in subject_list:   \n",
    "    for run in run_list_emg[subject]:\n",
    "        data_folder = join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION' )\n",
    "        for sensor in ['emg']:\n",
    "            for segment in segment_list:\n",
    "                file_list[subject][segment][run][sensor] = join(data_folder, 'segment_nb_' + segment + '_' + sensor +'.csv')\n",
    "\n",
    "                file = open(file_list[subject][segment][run][sensor])\n",
    "                reader = csv.DictReader(file)\n",
    "                headers[sensor] = reader.fieldnames\n",
    "\n",
    "                if sensor == 'emg':\n",
    "                    channels = headers['emg'][4:]\n",
    "\n",
    "                data = pd.read_csv(file_list[subject][segment][run][sensor])\n",
    "\n",
    "                if sensor == 'emg':\n",
    "                    for channel in channels:                    \n",
    "                        data_segments[subject][segment][run][sensor][channel]= data[channel]\n",
    "                        data_segments[subject][segment][run][sensor]['rel_time'] = data['relative_time']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dbef6-a806-407c-a619-c36260b3357a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# EMG analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c0e5c-8220-40f1-8ec1-79f4c1ff5cec",
   "metadata": {},
   "source": [
    "## EMG signals processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd52aa9-b833-42db-8442-9122c4fb8b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG processing: take the enveloppe of the signal with 2 methods: RMS or butterworth filters\n",
    "# More complete processing for the paper: code on matlab\n",
    "\n",
    "fs = 1000 #approximate sampling frequency for emg\n",
    "fny = fs/2 #nyquist frequency\n",
    "fco = 25  #cut off frequency\n",
    "rms_window = 20 #window size for rms\n",
    "\n",
    "sensor = 'emg'\n",
    "\n",
    "for subject in subject_list:   \n",
    "        for segment in segment_list:\n",
    "            for channel in channels:  \n",
    "                emg_segment_subject[subject][segment][channel]=[]\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for run in run_list_emg[subject]:\n",
    "        for segment in segment_list:\n",
    "            \n",
    "            for channel in channels:  \n",
    "                data_current = np.array(data_segments[subject][segment][run][sensor][channel])\n",
    "                # Remove all occurrences of elements with value above 1000 (outliers)\n",
    "                data_current = data_current[data_current < 1000]\n",
    "                data_current = data_current[data_current > -1000]\n",
    "                # remove missing data points\n",
    "                data_current = data_current[data_current != 0]  \n",
    "\n",
    "                N = 4\n",
    "                plt.ion\n",
    "                \n",
    "                # take enveloppe using butterworth filter\n",
    "                [b, a] = sp.butter(N, 1.16*fco/fny)\n",
    "                rec_signal = abs(data_current)\n",
    "                butt_signal = sp.filtfilt(b, a, rec_signal)\n",
    "                \n",
    "                # take enveloppe using rms windowing\n",
    "                rms_env = np.sqrt(np.convolve(np.square(rec_signal), np.ones(rms_window)/rms_window, mode='same'))\n",
    "\n",
    "                #PLOT to compare enveloppes, zoom on 1 part\n",
    "                start_zoom = 1\n",
    "                stop_zoom = 1000\n",
    "                df = pd.DataFrame({\n",
    "                    'rectified signal':rec_signal[start_zoom:stop_zoom],\n",
    "                    'Butterworth':butt_signal[start_zoom:stop_zoom],\n",
    "                    'RMS':rms_env[start_zoom:stop_zoom]\n",
    "                })\n",
    "                fig = px.line(df)\n",
    "                # showing the plot\n",
    "                #fig.show()\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'emg_plots' )):\n",
    "                    os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'emg_plots'))\n",
    "                fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION','emg_plots', 'segment' + segment + '_' + channel +'_zoom.png'))\n",
    "\n",
    "                #PLOT to compare enveloppes\n",
    "                df = pd.DataFrame({\n",
    "                    'line2':rec_signal,\n",
    "                    'line1':butt_signal,\n",
    "                    'line3':rms_env\n",
    "                })\n",
    "                fig = px.line(df)\n",
    "                # showing the plot\n",
    "                #fig.show()\n",
    "                fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION','emg_plots', 'segment' + segment + '_' + channel +'_tot.png'))\n",
    "                \n",
    "                \n",
    "                # save mean values, for each subject, each run and each channel\n",
    "                mean_segments[subject][segment][run][sensor][channel] = np.mean(butt_signal)\n",
    "                # save the enveloppe values for one subject, one channel, one segment, several runs\n",
    "                emg_segment_subject[subject][segment][channel].append(butt_signal)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb7995-9e71-420d-a07f-4e6f509faed7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## plot emg means on colormap, per run, per subject and per subject for all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22029c-a577-4860-be51-9e4b8db85ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'emg'\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "            fig = go.Figure()\n",
    "            x_values = []\n",
    "            y_values_tot = []\n",
    "            y_min = 0\n",
    "            y_max = 50\n",
    "            y_limit = 1.5\n",
    "            \n",
    "            #plot means per subject for all runs        \n",
    "            for i, channel in enumerate(channels):\n",
    "                x_values.append(i)\n",
    "                tot_signal = np.concatenate(emg_segment_subject[subject][segment][channel]) #put all values for the several runs together\n",
    "                y_values_tot.append(np.mean(tot_signal)) # get the mean values for each channel\n",
    "            \n",
    "            y_values_tot = (np.array(y_values_tot) - y_min) / (y_max - y_min) #normalisation for the colormap (1 on the color bar is ymax)\n",
    "\n",
    "            fig.add_trace(go.Scatter( x=x_values, y=y_values_tot, marker=dict(size=16, cmax=1,cmin=0, color=y_values_tot, colorbar=dict(title='Colorbar, 1=' + str(y_max) +' [uV]'), \n",
    "                        colorscale=\"rainbow\"),mode=\"markers\"))\n",
    "            \n",
    "            fig.update_layout(title='Mean value of EMG enveloppes over runs, one subject', xaxis_title='EMG channels', yaxis_title='EMG data', width=1025, height=500, yaxis_range=[0,y_limit])\n",
    "            \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'emg_colormap')):\n",
    "                    os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'emg_colormap'))\n",
    "\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','emg_colormap',  'colormap_subject'+ subject + '_segment' + segment + '_' +'.png'))\n",
    "            \n",
    "            \n",
    "            # plot means per subject and per run\n",
    "            for run in run_list_emg[subject]:\n",
    "                fig = go.Figure()\n",
    "                x_values = []\n",
    "                y_values = []\n",
    "\n",
    "                for i, channel in enumerate(channels):\n",
    "                    x_values.append(i)\n",
    "                    y_values.append(mean_segments[subject][run][sensor][segment][channel]) #put the mean values together for all the channels\n",
    "\n",
    "                y_values = (np.array(y_values) - y_min) / (y_max - y_min) #normalisation for the colormap (1 on the color bar is ymax)\n",
    "\n",
    "                fig.add_trace(go.Scatter(x=x_values, y=y_values, marker=dict( size=16, cmax=1,cmin=0, color=y_values, colorbar=dict(title='Colorbar, 1=' + str(y_max) +' [uV]'),\n",
    "                        colorscale=\"rainbow\"), mode=\"markers\"))\n",
    "                \n",
    "                fig.update_layout(title='Mean value of EMG enveloppes, one run', xaxis_title='EMG channels', yaxis_title='EMG data', width=1025, height=500, yaxis_range=[0,y_limit])\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'PLOTS','emg_colormap')):\n",
    "                        os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'PLOTS','emg_colormap'))\n",
    "                fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'PLOTS', 'emg_colormap', 'colormap_subject'+ 'subject' + '_segment' + segment + '_run' + run +'.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f56232-6380-4417-a90b-4b6a8b361f8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot means with colormap, per expertise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff0e3a-8691-4e39-9a00-5e1f4a2500e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'emg'\n",
    "expert_subjects = ['4','10','3']\n",
    "novice_subjects = ['7', '12','9']\n",
    "category = ['novice', 'expert']\n",
    "\n",
    "y_min = 0\n",
    "y_max = 50\n",
    "y_limit= 2\n",
    "\n",
    "subject_expertise = {\n",
    "    'expert': expert_subjects,\n",
    "    'novice': novice_subjects\n",
    "}\n",
    "\n",
    "emg_segment_subject_expertise = {}\n",
    "for cat in category: \n",
    "    emg_segment_subject_expertise[cat] = {}\n",
    "    for segment in segment_list:\n",
    "        emg_segment_subject_expertise[cat][segment] = {}\n",
    "        for channel in channels:\n",
    "            emg_segment_subject_expertise[cat][segment][channel] = []\n",
    "    \n",
    "# put together the data from the runs of the subjects with the same expertise (group), for each channel separatley\n",
    "for cat in category:               \n",
    "    for subject in subject_expertise[cat]:   \n",
    "        for segment in segment_list:\n",
    "                for channel in channels:\n",
    "                    emg_segment_subject_expertise[cat][segment][channel].append(emg_segment_subject[subject][segment][channel]) \n",
    "\n",
    "# plot as a colormap the means per groups\n",
    "for cat in category:               \n",
    "    for subject in subject_expertise[cat]:   \n",
    "        for segment in segment_list:\n",
    "                fig = go.Figure(layout_yaxis_range=[0,1])\n",
    "                x_values = []\n",
    "                y_values_tot = []\n",
    "                            \n",
    "                for i, channel in enumerate(channels):\n",
    "                    x_values.append(i)\n",
    "                    tot_signal = np.concatenate(np.concatenate(emg_segment_subject_expertise[cat][segment][channel]))\n",
    "                    y_values_tot.append(np.mean(tot_signal)) # take the mean value for each expertise\n",
    "\n",
    "                y_values_tot = (np.array(y_values_tot) - y_min) / (y_max - y_min) #normalisation for the colorbar\n",
    "\n",
    "                fig.add_trace(go.Scatter(x=x_values, y=y_values_tot, marker=dict( size=16,cmax=1,cmin=0,color=y_values_tot,colorbar=dict(title='Colorbar, 1=' + str(y_max) +' [uV]'),\n",
    "                        colorscale=\"rainbow\"), mode=\"markers\"))\n",
    "                fig.update_layout(title='Mean value of EMG enveloppes for' + cat + ' subjects',xaxis_title='EMG channels', yaxis_title='EMG data', width=1025, height=500,yaxis_range=[0,y_limit])\n",
    "\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, 'PLOTS', 'plots_expertise' )):\n",
    "                        os.makedirs(join(path_to_data_folder,'PLOTS','plots_expertise'))\n",
    "                fig.write_image(join('..', 'data_exp', 'PLOTS', 'plots_expertise', 'colormap_segment' + segment + '_' + cat +'.png'))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e202b7-6113-4ebb-bc32-733a6eec6a1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Time data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b9cf5-e692-4c14-b172-083cecd0f437",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Time data  for entire run (560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d44d6c28-6494-4aa7-a6c3-5a6ca3caa2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject nb 1      mean duration of entire procedure over runs = 126.1549999999992\n",
      "subject nb 2      mean duration of entire procedure over runs = 163.5716666666649\n",
      "subject nb 3      mean duration of entire procedure over runs = 63.75\n",
      "subject nb 4      mean duration of entire procedure over runs = 83.17666666666555\n",
      "subject nb 5      mean duration of entire procedure over runs = 160.49999999999878\n",
      "subject nb 6      mean duration of entire procedure over runs = 176.53611111111118\n",
      "subject nb 7      mean duration of entire procedure over runs = 198.22999999999337\n",
      "subject nb 8      mean duration of entire procedure over runs = 107.9949999999997\n",
      "subject nb 9      mean duration of entire procedure over runs = 363.87291666666533\n",
      "subject nb 10      mean duration of entire procedure over runs = 51.03166666666666\n",
      "subject nb 11      mean duration of entire procedure over runs = 89.99375000000032\n",
      "subject nb 12      mean duration of entire procedure over runs = 220.7361111111113\n"
     ]
    }
   ],
   "source": [
    "# the time data are based on the timestamps obtained with the optitrack data as theaz are the most reliable timestamps and optitrack was the most reliable sensor (did not stop unexpectidly)\n",
    "\n",
    "duration_run = {}\n",
    "mean_duration_run ={}\n",
    "\n",
    "# compute and print duration of the entire task for each subject\n",
    "for subject in subject_list:\n",
    "    duration_run[subject] = []\n",
    "    for run in run_list[subject]['560']:                      \n",
    "        duration_run[subject].append(np.array(data_segments[subject]['560'][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject]['560'][run]['optitrack']['rel_time'])[0] )\n",
    "        \n",
    "    mean_duration_run[subject] = np.mean(duration_run[subject])\n",
    "    print('subject nb ' + str(subject) + '      mean duration of entire procedure over runs = ' + str(mean_duration_run[subject]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b80586-6e78-43fe-897e-ee6b759b9495",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Time data for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8643f78c-f3f8-4fc4-9675-e6bd812758d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_new = ['2','3','4','5','6','1'] #segment notation used for the master thesis report\n",
    "# Link with main notation: 2 = 500, 3 = 510, 4 = 530, 5 = 540, 6 = 541, 1 = 560\n",
    "\n",
    "\n",
    "duration_run_segments = {}\n",
    "mean_duration_run_segments ={}\n",
    "std_duration_run_segments ={}\n",
    "for subject in subject_list:\n",
    "    duration_run_segments[subject] = {} \n",
    "    mean_duration_run_segments[subject] = {} \n",
    "    std_duration_run_segments[subject] = {}  \n",
    "    for segment in segment_list:\n",
    "        duration_run_segments[subject][segment] = [] \n",
    "        mean_duration_run_segments[subject][segment] = []\n",
    "        std_duration_run_segments[subject][segment] = []\n",
    "        \n",
    "# get time duration for all the segments and for all subjects + mean and std values    \n",
    "# put in one variable the values for the different runs of one subject for one segment (ex 3 values if 3 runs)\n",
    "for subject in subject_list:\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]: \n",
    "            duration_run_segments[subject][segment].append(np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0] )        \n",
    "        mean_duration_run_segments[subject][segment] = np.mean(duration_run_segments[subject][segment])\n",
    "        std_duration_run_segments[subject][segment] = np.std(duration_run_segments[subject][segment])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3424b0e-6915-455b-98ef-6365a1a849cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PLOTS TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0b9e4-1bb3-4b88-923d-75e758deaec4",
   "metadata": {},
   "source": [
    "### Plot mean vs ALI and groups Novice, Intermediate, Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a22e4-1388-47b5-8634-ff00eb892474",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_order = ['10','3','4','11','8','2','1','5','6','7','12'] #removed subject 9 for time as it was an outlier\n",
    "ALI_score= [3,4,4,6,6,6,7,7,7,9,10]\n",
    "\n",
    "# groups definition\n",
    "subject_order_novice = ['7','12']\n",
    "ALI_novice = [9,10]\n",
    "subject_order_intermediate = ['11','8','2','1','5','6']\n",
    "ALI_intermediate = [6,6,6,7,7,7]\n",
    "subject_order_expert = ['10','3','4']\n",
    "ALI_expert = [3,4,4]\n",
    "\n",
    "for k, segment in enumerate(segment_list):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    \n",
    "    # put in one variable the values of the different subjects for each group\n",
    "    for subject in subject_order_expert:\n",
    "        y1.append(mean_duration_run_segments[subject][segment]) #mean value over the different runs\n",
    "    for subject in subject_order_intermediate:\n",
    "        y2.append(mean_duration_run_segments[subject][segment])\n",
    "    for subject in subject_order_novice:\n",
    "        y3.append(mean_duration_run_segments[subject][segment])     \n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    plt.scatter(ALI_expert, y1, s = 120 ,color='blue', marker = 'o', label ='Experts')\n",
    "    plt.scatter(ALI_intermediate, y2, s = 120 ,color='blue', marker = '^', label = 'Intermediates')\n",
    "    plt.scatter(ALI_novice, y3, s = 120 ,color='blue', marker = '*', label = 'Novices')\n",
    "\n",
    "    plt.ylabel('Average time [s]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    plt.xlim([2, 11])\n",
    "    plt.ylim([0, max(max(y1),max(y2),max(y3))+15])\n",
    "    plt.xticks(ticks=ticks, labels=ticks)\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'TIME')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'TIME'))\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.55, 1.05))\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME', 'ALI_time_segment_wo_error' + segment  +'.png'), bbox_inches='tight')\n",
    "    # comment the legend and save without legend for the report    \n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME','no_legend', 'ALI_time_segment_wo_error' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220cb7c-00b7-435c-a62a-3cc4d4ac15e4",
   "metadata": {},
   "source": [
    "### Plots means duration VS specialty and years of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08778d50-e799-40da-a01b-3e16270e17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the means values according to the number of years of experience, and showing the specialties\n",
    "\n",
    "#groups definition\n",
    "subject_order_neuro = ['1','2','6','5','8','3','10']\n",
    "experience_years_neuro = [3,4,3,5,7,12,24]\n",
    "subject_order_plastic = ['11']\n",
    "experience_years_plastic = [11]\n",
    "subject_order_maxilo = ['12']\n",
    "experience_years_maxilo = [10]\n",
    "subject_order_general = ['4']\n",
    "experience_years_general = [25]\n",
    "\n",
    "\n",
    "for k, segment in enumerate(segment_list):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    y4 = []\n",
    "    #put in one variable the values for subjects of the same groups, in the right order\n",
    "    for subject in subject_order_neuro:\n",
    "        y1.append(mean_duration_run_segments[subject][segment]) #mean values over the several runs\n",
    "    for subject in subject_order_plastic:\n",
    "        y2.append(mean_duration_run_segments[subject][segment])\n",
    "    for subject in subject_order_maxilo:\n",
    "        y3.append(mean_duration_run_segments[subject][segment])     \n",
    "    for subject in subject_order_general:\n",
    "        y4.append(mean_duration_run_segments[subject][segment])\n",
    "    x1= experience_years_neuro\n",
    "    x2= experience_years_plastic\n",
    "    x3=experience_years_maxilo\n",
    "    x4=experience_years_general\n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    plt.grid()\n",
    "\n",
    "    plt.scatter(x1, y1, s = 100 ,color='black', marker = 'o')\n",
    "    plt.scatter(x2, y2, s = 120, marker = '*', color='red')\n",
    "    plt.scatter(x3, y3, s = 120, marker = '+', color='orange')\n",
    "    plt.scatter(x4, y4, s = 120, marker = '^', color='green')\n",
    "\n",
    "    plt.ylabel('Average time [s]')\n",
    "    plt.xlabel('Years experience')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.xticks(np.arange(1, 26, 2))\n",
    "    plt.ylim([0, max(max(y1),max(y2),max(y3),max(y4))+15])\n",
    "   \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'TIME')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'TIME'))\n",
    "            \n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.05))\n",
    "    #lgd = plt.legend( loc='upper center', bbox_to_anchor=(1.3, 1.05))\n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME', 'years_time_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME','no_legend', 'years_time_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aec85d-adb0-4bd5-8e75-43b0cde16b11",
   "metadata": {},
   "source": [
    "### Plot mean duration vs nb of years of experience in microsurgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c36bd5-3ac0-4ee2-8d02-5f434dcdda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed novice with no experience in microsurgery + expert general surgeon (= kept neurosurgeons)\n",
    "subject_order = ['1', '2', '6','5','8','11','3','10'] \n",
    "# estimated years of experience in microsurgery\n",
    "experience_years = [3,4,3,5,7,11,12,24]\n",
    "\n",
    "\n",
    "for segment in segment_list:\n",
    "    x = []\n",
    "    y = []\n",
    "    #put the mean duration values over the runs for each subject in one var, in the order of the subject definition\n",
    "    for subject in subject_order:\n",
    "        y.append(mean_duration_run_segments[subject][segment])\n",
    "        \n",
    "    x= experience_years\n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    plt.plot(x, y,'*')\n",
    "    plt.xticks(np.arange(1, 26, 2))\n",
    "    plt.ylabel('Average time [s]')\n",
    "    plt.xlabel('Years experience [s]')\n",
    "    plt.title('Segment: ' + str(segment), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()  \n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'TIME')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'TIME'))\n",
    "\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME', 'years_micro_time_segment' + segment  +'.png'))\n",
    "\n",
    "    #plt.show()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840da03-d383-4e16-a982-a3a35bbd4723",
   "metadata": {},
   "source": [
    "### Boxplot for the duration of each segment, vs the ali score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64511b8c-249d-4f52-8d48-807fdac43b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "subject_order = ['10','3','4','11','8','2','1','5','6','7','12']    \n",
    "ALI_score= [3,4,4,6,6,6,7,7,7,9,10]\n",
    "positions = [0,1.75,2.25,5.6,6,6.4,7.6,8,8.4,12,14] #to separate the boxplot of the subjects with the same ALI score\n",
    "\n",
    "for k, segment in enumerate(segment_list):\n",
    "    x = []\n",
    "    y = []\n",
    "    f = plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    # put together the duration values for each run of each subjects together, in the order defined by the order of the subjects \n",
    "    for i, subject in enumerate(subject_order):\n",
    "        y.append(duration_run_segments[subject][segment]) #duration_run_segments has the values of the different runs for one subject and one segment\n",
    "        \n",
    "    x= ALI_score\n",
    "    bplot = plt.boxplot(y,patch_artist=True, positions=positions, widths=(0.5, 0.5, 0.5, 0.4,0.4,0.4,0.4,0.4,0.4,0.5,0.5))\n",
    "    \n",
    "    colors = ['lightblue', 'lightblue', 'lightgreen','lightblue','lightgreen','lightpink','lightblue','lightgreen','lightpink','lightblue', 'lightblue']\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    plt.ylabel('Time [s]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid(axis = 'y')\n",
    "    #bplot.yaxis.grid(True)\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "    plt.xlim(-2, len(ticks)*2)\n",
    "    plt.ylim(bottom = 0)\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'TIME')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'TIME'))\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'TIME', 'ALI_time_segment_boxplot' + segment  +'.png'),bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a8e8e6-20c9-4f00-9808-5e7901b313a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## one way anova time VS categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217b208-7745-4a7f-bd58-ec35816150a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group definition\n",
    "expert_subjects = ['4','10','3']\n",
    "intermediate_subjects = ['1','2','5','6','8','11']\n",
    "novice_subjects = ['7', '12']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "# store the data to perform ANOVA here\n",
    "time_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    time_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    #create a csv file to write the data inside\n",
    "    rs_csv = join(folder,'ANOVA','time','time_data_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode         \n",
    "    writer = csv.writer(f)\n",
    "    #write 1st row\n",
    "    header = ['specialty','value']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                # get the duration for each run and each subject, in the order defined by the categories (first all novice, then all intermediate, then all experts)\n",
    "                time = np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[-1] - np.array(data_segments[subject][segment][run]['optitrack']['rel_time'])[0]\n",
    "                # writ in the file the duration values, specifying the category corresponding (get the values of all the runs separately, for ex we have 9 novice data points for \n",
    "                # 3 novice subjects with 3 runs\n",
    "                row = [cat, time]\n",
    "                writer.writerow(row)\n",
    "                time_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "# can perform ANOVA on python but matlab was used \n",
    "\"\"\"\n",
    "time_expertise_dataframe = {}\n",
    "for segment, values in time_segment_subject_expertise.items():\n",
    "    time_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value\"])\n",
    "    \n",
    "time_anova_results = {}\n",
    "for segment, dataframe in time_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value ~ C(category)', data=dataframe).fit()\n",
    "    time_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(time_anova_results[segment])\n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c8042-2ca8-4c06-bc38-c7b11ef42d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TPS DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decdb81c-acd4-4c80-9bc7-9ba59cf11484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## data review / processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d0bbe-92d3-40d2-be01-bc371f7fb3ae",
   "metadata": {},
   "source": [
    "### Compute the derivative and the range (max - min values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812bfa5b-4d7e-4a6e-a919-22c973aa9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'TPS_calibrated'\n",
    "subject_list_tps_activity = ['10','9','3','7','6','5','4']\n",
    "segment_list_tps_activity =['560','540','500','510','541','530']\n",
    "\n",
    "\n",
    "# data structure\n",
    "for subject in subject_list:   \n",
    "        for segment in segment_list:\n",
    "            for finger in fingers_cal:  \n",
    "                tps_segment_subject[subject][segment][finger]=[]\n",
    "                range_raw_tps_subject[subject][segment][finger] = []\n",
    "                for run in run_list[subject][segment]:\n",
    "                    abs_diff_tps[subject][segment][run][finger] = []\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #CONVERSION EN SECONDES\n",
    "            \n",
    "            for finger in fingers_cal:  \n",
    "                data_current = np.array(data_segments[subject][segment][run][sensor][finger])\n",
    "                #Newton diff method for derivative\n",
    "                diff_tps = (data_current[1:-1] - data_current[0:-2])/(time_current[1:-1] - time_current[0:-2])\n",
    "                #take abs value of derivative to take into account press and release variations\n",
    "                abs_diff_tps[subject][segment][run][finger] = abs(diff_tps)\n",
    "                \n",
    "                # compute range value to have measurement of how much force is applied\n",
    "                range_raw_tps = max(data_current) - min(data_current)\n",
    "                \n",
    "                #put together the values of the absolute derivative of the force/ the ranges of the different runs for one subject, for each fingers and each segment\n",
    "                tps_segment_subject[subject][segment][finger].append(abs(diff_tps)) \n",
    "                range_raw_tps_subject[subject][segment][finger].append(range_raw_tps)\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a06d9e-6ea3-4ec1-8e8a-936ab66cdbde",
   "metadata": {},
   "source": [
    "### Compute the activity = sum of abs od derivative for the active fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030b9521-219b-40c3-a1fc-3851a185ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tps activity = sum derivative active fingers\n",
    "sensor = 'TPS_calibrated'\n",
    "\n",
    "#definition of the active fingers for the subjects (not all subjects have active fingers)\n",
    "RH_fingers = {\n",
    "    '10':[fingers_cal[5],fingers_cal[3] ], #thumb, index right\n",
    "    '9':[fingers_cal[5],fingers_cal[3] ],\n",
    "    '3':[fingers_cal[5]],\n",
    "    '4':[fingers_cal[5]],\n",
    "    '5':[fingers_cal[5]],\n",
    "    '6':[fingers_cal[5],fingers_cal[3]],\n",
    "    '7':[fingers_cal[5],fingers_cal[3] ]\n",
    "    }\n",
    "\n",
    "LH_fingers = {\n",
    "    '10':[fingers_cal[2],fingers_cal[0],fingers_cal[1] ], #thumb, index, middle left\n",
    "    '9':[fingers_cal[2],fingers_cal[0],fingers_cal[1] ],\n",
    "    '3':[fingers_cal[2],fingers_cal[0],fingers_cal[1] ],\n",
    "    '6':[fingers_cal[2],fingers_cal[0],fingers_cal[1] ],\n",
    "    '5':[fingers_cal[2],fingers_cal[1] ],\n",
    "    '4':[fingers_cal[2],fingers_cal[0] ],\n",
    "    '7':[fingers_cal[2],fingers_cal[0],fingers_cal[1] ] \n",
    "    }\n",
    "\n",
    "# data structure\n",
    "sum_derivative_RH = {}\n",
    "sum_derivative_LH = {}\n",
    "for subject in subject_list_tps_activity:   \n",
    "    sum_derivative_RH[subject]={}\n",
    "    sum_derivative_LH[subject]={}\n",
    "    for segment in segment_list_tps_activity:\n",
    "        sum_derivative_RH[subject][segment] = {}\n",
    "        sum_derivative_LH[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            sum_derivative_RH[subject][segment][run]=[]\n",
    "            sum_derivative_LH[subject][segment][run]=[]\n",
    "            \n",
    "\n",
    "\n",
    "for subject in subject_list_tps_activity:   \n",
    "    for segment in segment_list_tps_activity:\n",
    "        for run in run_list[subject][segment]:\n",
    "            \n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #convert to s (tps data in ms)\n",
    "            # create a vector that can store data for each timestamp\n",
    "            sum_derivative_RH[subject][segment][run] = np.zeros(len(time_current)-2)\n",
    "            sum_derivative_LH[subject][segment][run] = np.zeros(len(time_current)-2)\n",
    "            \n",
    "            # add the signals obtained of the absolute value of the derivative for the active fingers for each hand\n",
    "            # = add the numerical value of the derivative of the force for all active fingers, at each timestamp\n",
    "            # = to have a global signal for the entire hand = determine activity from the whole hand (as several fingers are used simultaneously to press on the tool)\n",
    "            # = ACTIVITY SIGNAL\n",
    "            for finger in RH_fingers[subject]:\n",
    "                sum_derivative_RH[subject][segment][run] = sum_derivative_RH[subject][segment][run] + (abs_diff_tps[subject][segment][run][finger])\n",
    "                \n",
    "            for finger in LH_fingers[subject]:\n",
    "                sum_derivative_LH[subject][segment][run]= sum_derivative_LH[subject][segment][run] + (abs_diff_tps[subject][segment][run][finger])\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643a749-c6df-4c6c-a273-50b18ac9ab1a",
   "metadata": {},
   "source": [
    "### Compute tps activity metrics: normalised activity signal, activity peaks, mean number of activity peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1499a66-8143-431a-a1c1-44117071d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_list_tps_activity =['560','500','510','530','540','541']\n",
    "segment_new = ['1','2','3','4','5','6'] #corresponding notation in the report\n",
    "\n",
    "# data structure\n",
    "nb_peaks_derivative_RH={}\n",
    "nb_peaks_derivative_LH={}\n",
    "mean_nb_peak_derivative_RH = {}\n",
    "mean_nb_peak_derivative_LH = {}\n",
    "sum_derivative_RH_norm={}\n",
    "sum_derivative_LH_norm={}\n",
    "for subject in subject_list_tps_activity:   \n",
    "    nb_peaks_derivative_RH[subject]={}\n",
    "    nb_peaks_derivative_LH[subject]={}\n",
    "    mean_nb_peak_derivative_RH[subject] = {}\n",
    "    mean_nb_peak_derivative_LH[subject]= {}\n",
    "    sum_derivative_RH_norm[subject]={}\n",
    "    sum_derivative_LH_norm[subject]={}\n",
    "    for segment in segment_list_tps_activity:\n",
    "        nb_peaks_derivative_RH[subject][segment] = {}\n",
    "        nb_peaks_derivative_LH[subject][segment] = {}\n",
    "        mean_nb_peak_derivative_RH[subject][segment] = []\n",
    "        mean_nb_peak_derivative_LH[subject][segment] =[]\n",
    "        sum_derivative_RH_norm[subject][segment] = {}\n",
    "        sum_derivative_LH_norm[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            nb_peaks_derivative_RH[subject][segment][run]=[]\n",
    "            nb_peaks_derivative_LH[subject][segment][run]=[]\n",
    "            sum_derivative_RH_norm[subject][segment][run]=[]\n",
    "            sum_derivative_LH_norm[subject][segment][run]=[]\n",
    "\n",
    "for subject in subject_list_tps_activity:   \n",
    "    for segment in segment_list_tps_activity:\n",
    "        tmp_mean_nb_peak_R = []\n",
    "        tmp_mean_nb_peak_L = []\n",
    "        for run in run_list[subject][segment]:\n",
    "            tmp_R = sum_derivative_RH[subject][segment][run]/max(sum_derivative_RH[subject][segment][run]) #normalize the activity signal by the maximum value\n",
    "            tmp_L = sum_derivative_LH[subject][segment][run]/max(sum_derivative_LH[subject][segment][run])\n",
    "            sum_derivative_RH_norm[subject][segment][run] = tmp_R #store the normalized activity signal\n",
    "            sum_derivative_LH_norm[subject][segment][run] = tmp_L\n",
    "            \n",
    "            # function to determine the peak values in a signal\n",
    "            nb_peaks_derivative_RH[subject][segment][run] = sp.find_peaks(tmp_R, height=0.12, threshold=0.01, distance=15, prominence=None, width=0, wlen=None, rel_height=1, plateau_size=None)\n",
    "            nb_peaks_derivative_LH[subject][segment][run] = sp.find_peaks(tmp_L, height=0.15, threshold=0.01, distance=15, prominence=None, width=3, wlen=None, rel_height=3, plateau_size=None)\n",
    "        \n",
    "            # put together the number of peaks found in each run\n",
    "            tmp_mean_nb_peak_R.append(len(nb_peaks_derivative_RH[subject][segment][run][1]['peak_heights'])) \n",
    "            tmp_mean_nb_peak_L.append( len(nb_peaks_derivative_LH[subject][segment][run][1]['peak_heights']))\n",
    "            #print(\"subject: \" + subject + \" run: \" + run + \"segment\" + str(segment) + \"nb peak RH \" + str(len(nb_peaks_derivative_RH[subject][run][segment][1]['peak_heights'])))\n",
    "            #print(\"subject: \" + subject + \" run: \" + run + \"segment\" + str(segment) + \"nb peak LH: \" + str(len(nb_peaks_derivative_LH[subject][run][segment][1]['peak_heights'])))\n",
    "    \n",
    "        # take the mean value of the number of peaks over the different run for one subject and one segment\n",
    "        mean_nb_peak_derivative_RH[subject][segment]=np.mean(tmp_mean_nb_peak_R)  \n",
    "        mean_nb_peak_derivative_LH[subject][segment]=np.mean(tmp_mean_nb_peak_L)\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean peak nb RH: \" + str((mean_nb_peak_derivative_RH[subject][segment])))\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean peak nb LH: \" + str((mean_nb_peak_derivative_LH[subject][segment])))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4dfa3d-a327-42c8-bbfa-b12967874947",
   "metadata": {},
   "source": [
    "### Compute tps activity metrics: nb of points above threshold, pc of time/ points above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b741e5-2d82-48c5-bff0-2c2b6efface4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sum_derivative_LRH_pc={}\n",
    "sum_derivative_RH_pc={}\n",
    "sum_derivative_LH_pc={}\n",
    "sum_derivative_LRH_pc= {}\n",
    "mean_sum_derivative_RH_pc={}\n",
    "mean_sum_derivative_LH_pc={}\n",
    "mean_sum_derivative_RH_nb_points={}\n",
    "mean_sum_derivative_LH_nb_points={}\n",
    "nb_points_derivative_RH={}\n",
    "nb_points_derivative_LH={}\n",
    "for subject in subject_list_tps_activity:   \n",
    "    sum_derivative_RH_pc[subject]={}\n",
    "    sum_derivative_LH_pc[subject]={}\n",
    "    sum_derivative_LRH_pc[subject]={}\n",
    "    mean_sum_derivative_RH_pc[subject]={}\n",
    "    mean_sum_derivative_LH_pc[subject]={}\n",
    "    mean_sum_derivative_LRH_pc[subject]={}\n",
    "    mean_sum_derivative_RH_nb_points[subject]={}\n",
    "    mean_sum_derivative_LH_nb_points[subject]={}\n",
    "    nb_points_derivative_RH[subject]={}\n",
    "    nb_points_derivative_LH[subject]={}\n",
    "    for segment in segment_list_tps_activity:\n",
    "        sum_derivative_RH_pc[subject][segment] = {}\n",
    "        sum_derivative_LH_pc[subject][segment] = {}\n",
    "        sum_derivative_LRH_pc[subject][segment]={}\n",
    "        mean_sum_derivative_RH_nb_points[subject][segment] = []\n",
    "        mean_sum_derivative_LH_nb_points[subject][segment] = []\n",
    "        mean_sum_derivative_RH_pc[subject][segment]=[]\n",
    "        mean_sum_derivative_LH_pc[subject][segment]=[]\n",
    "        mean_sum_derivative_LRH_pc[subject][segment] =[]\n",
    "        nb_points_derivative_RH[subject][segment]={}\n",
    "        nb_points_derivative_LH[subject][segment]={}\n",
    "        for run in run_list[subject][segment]:\n",
    "            sum_derivative_RH_pc[subject][segment][run]=[]\n",
    "            sum_derivative_LH_pc[subject][segment][run]=[]\n",
    "            sum_derivative_LRH_pc[subject][segment][run] = []\n",
    "            nb_points_derivative_RH[subject][segment][run]=[]\n",
    "            nb_points_derivative_LH[subject][segment][run]=[]\n",
    "\n",
    "\n",
    "for subject in subject_list_tps_activity:   \n",
    "    for segment in segment_list_tps_activity:\n",
    "        tmp_mean_L = []\n",
    "        tmp_mean_LR = []\n",
    "        tmp_mean_R = []\n",
    "        tmp_mean_R_nb_points=[]\n",
    "        tmp_mean_L_nb_points=[]\n",
    "\n",
    "        for run in run_list[subject][segment]:\n",
    "            tmp_R = sum_derivative_RH[subject][segment][run]/max(sum_derivative_RH[subject][segment][run])\n",
    "            tmp_L = sum_derivative_LH[subject][segment][run]/max(sum_derivative_LH[subject][segment][run])\n",
    "            \n",
    "            # take the percentage of points above a threshold \n",
    "            sum_derivative_RH_pc[subject][segment][run] = len(tmp_R[tmp_R > 0.1])/len(tmp_R)*100\n",
    "            sum_derivative_LH_pc[subject][segment][run] = len(tmp_L[tmp_L > 0.1])/len(tmp_L)*100\n",
    "            \n",
    "            # sum the signals of the 2 hands to take the percentage of points above the theshold considering the activity of the 2 hands\n",
    "            tmp_LR = tmp_R + tmp_L\n",
    "            sum_derivative_LRH_pc[subject][segment][run] = len(tmp_LR[tmp_LR > 0.1])/len(tmp_R)*100\n",
    "            \n",
    "            #number of points above threshold (not percentage)\n",
    "            nb_points_derivative_RH[subject][segment][run] = len(tmp_R[tmp_R > 0.1])\n",
    "            nb_points_derivative_LH[subject][segment][run] = len(tmp_L[tmp_L > 0.1])\n",
    "                        \n",
    "            #print(\"subject: \" + subject + \" run: \" + run + \"segment\" + str(segment) + \"percentage RH: \" + str(sum_derivative_RH_pc[subject][run][segment]))\n",
    "            #print(\"subject: \" + subject + \" run: \" + run + \"segment\" + str(segment) + \"percentage LH: \" + str(sum_derivative_LH_pc[subject][run][segment]))\n",
    "                        \n",
    "            # put together the values for the different runs for each subject for each segment\n",
    "            tmp_mean_R.append(sum_derivative_RH_pc[subject][segment][run])           \n",
    "            tmp_mean_L.append(sum_derivative_LH_pc[subject][segment][run])\n",
    "            tmp_mean_LR.append(sum_derivative_LRH_pc[subject][segment][run])\n",
    "            \n",
    "            tmp_mean_R_nb_points.append(nb_points_derivative_RH[subject][segment][run])\n",
    "            tmp_mean_L_nb_points.append(nb_points_derivative_LH[subject][segment][run])\n",
    "            \n",
    "            \n",
    "        # compute the mean values of the metrics considering the different runs\n",
    "        mean_sum_derivative_RH_pc[subject][segment]=np.mean(tmp_mean_R)  \n",
    "        mean_sum_derivative_LH_pc[subject][segment]=np.mean(tmp_mean_L)\n",
    "        mean_sum_derivative_LRH_pc[subject][segment]=np.mean(tmp_mean_LR)\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean percentage RH: \" + str( mean_sum_derivative_RH_pc[subject][segment]))\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean percentage LH: \" + str(mean_sum_derivative_LH_pc[subject][segment]))\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean percentage all: \" + str(mean_sum_derivative_LRH_pc[subject][segment]))\n",
    "       \n",
    "        mean_sum_derivative_RH_nb_points[subject][segment]=np.mean(tmp_mean_R_nb_points)  \n",
    "        mean_sum_derivative_LH_nb_points[subject][segment]=np.mean(tmp_mean_L_nb_points)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388588e-fdd2-445c-bc4b-684587caf320",
   "metadata": {},
   "source": [
    "### Compute tps activity metrics: time above threshold and time statistics (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8a5974-b71a-411d-9215-3d9c2ccc3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_derivative_RH={}\n",
    "time_derivative_LH={}\n",
    "mean_time_derivative_RH={}\n",
    "mean_time_derivative_LH={}\n",
    "std_time_derivative_RH={}\n",
    "std_time_derivative_LH={}\n",
    "for subject in subject_list_tps_activity:   \n",
    "    time_derivative_RH[subject]={}\n",
    "    time_derivative_LH[subject]={}\n",
    "    mean_time_derivative_RH[subject]={}\n",
    "    mean_time_derivative_LH[subject]={}\n",
    "    std_time_derivative_RH[subject]={}\n",
    "    std_time_derivative_LH[subject]={}\n",
    "    for segment in segment_list_tps_activity:\n",
    "        time_derivative_RH[subject][segment]={}\n",
    "        time_derivative_LH[subject][segment]={}\n",
    "        mean_time_derivative_RH[subject][segment]=[]\n",
    "        mean_time_derivative_LH[subject][segment]=[]\n",
    "        std_time_derivative_RH[subject][segment]=[]\n",
    "        std_time_derivative_LH[subject][segment]=[]\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_derivative_RH[subject][segment][run]=[]\n",
    "            time_derivative_LH[subject][segment][run]=[]\n",
    "            nb_points_derivative_RH[subject][segment][run]=[]\n",
    "            nb_points_derivative_LH[subject][segment][run]=[]\n",
    "\n",
    "\n",
    "for subject in subject_list_tps_activity:   \n",
    "    for segment in segment_list_tps_activity:\n",
    "        tmp_mean_L = []\n",
    "        tmp_mean_LR = []\n",
    "        tmp_mean_R = []\n",
    "        tmp_mean_R_time=[]\n",
    "        tmp_mean_L_time=[]\n",
    "        for run in run_list[subject][segment]:\n",
    "            tmp_R = sum_derivative_RH[subject][segment][run]/max(sum_derivative_RH[subject][segment][run])\n",
    "            tmp_L = sum_derivative_LH[subject][segment][run]/max(sum_derivative_LH[subject][segment][run])\n",
    "            \n",
    "            # take amount of time (approximate) corresponding to the number of points above the threshold (dividing by the sampling freqeuncy)\n",
    "            time_derivative_RH[subject][segment][run] = len(tmp_R[tmp_R > 0.1])/40\n",
    "            time_derivative_LH[subject][segment][run] = len(tmp_L[tmp_L > 0.1])/40\n",
    "            \n",
    "            # put the value sobtained for the different runs for one subject, one segment\n",
    "            tmp_mean_R_time.append(time_derivative_RH[subject][segment][run])\n",
    "            tmp_mean_L_time.append(time_derivative_LH[subject][segment][run])\n",
    "\n",
    "        # compute the mean and std values when considering the values over the different runs\n",
    "        mean_time_derivative_RH[subject][segment]=np.mean(tmp_mean_R_time)  \n",
    "        mean_time_derivative_LH[subject][segment]=np.mean(tmp_mean_L_time)\n",
    "        std_time_derivative_RH[subject][segment]=np.std(tmp_mean_R_time)  \n",
    "        std_time_derivative_LH[subject][segment]=np.std(tmp_mean_L_time)\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean time RH: \" + str( mean_time_derivative_RH[subject][segment]))\n",
    "        #print(\"subject: \" + subject  + \" segment\" + str(segment) + \" mean time LH: \" + str(mean_time_derivative_LH[subject][segment]))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38bac2d-a7ef-4657-8625-5cde48dc2f27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TPS PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b973b-48f4-4fc8-ac36-f001cbf6b2fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot tps colormap for each run and for every run of 1 subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7268b286-f212-4c5c-940e-48b9094bc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'TPS_calibrated'\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "            fig = go.Figure()\n",
    "            x_values = []\n",
    "            y_values_tot = []\n",
    "            y_min = 0\n",
    "            y_limit_diff = 5\n",
    "            y_limit_range =5\n",
    "            y_max_range = 2\n",
    "            y_max_diff = 0.5\n",
    "\n",
    "            for i, finger in enumerate(fingers_cal):\n",
    "                x_values.append(i)\n",
    "                tot_signal = np.concatenate(tps_segment_subject[subject][segment][finger]) #tous les runs pour un subject, valeur abs de la derivee\n",
    "                y_values_tot.append(np.mean(tot_signal)) #valeur moyenne pour un sujet\n",
    "            \n",
    "            y_values_tot = (np.array(y_values_tot) - y_min) / (y_max_diff - y_min)\n",
    "\n",
    "            fig.add_trace(go.Scatter(x=x_values,y=y_values_tot, marker=dict(size=16,cmax=1,cmin=0,color=y_values_tot,colorbar=dict(title='Colorbar, 1=' + str(y_max_diff) + '[lbs/s]'),\n",
    "                    colorscale=\"rainbow\"),mode=\"markers\"))\n",
    "            \n",
    "            fig.update_layout(title='Mean abs value of derivative, one subject',xaxis_title='left_index,  left_middle,  left_thumb, right_index, right_middle, right_thumb',\n",
    "                   yaxis_title='TPS data',yaxis_range=[0,y_limit_diff])\n",
    "            \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS')):\n",
    "                    os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS'))\n",
    "\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS', 'TPS_diff_colormap_subject' +subject + '_segment' + segment + '_' +'.png'))\n",
    "            \n",
    "          \n",
    "        \n",
    "            fig = go.Figure()\n",
    "            x_values = []\n",
    "            y_values_tot = []\n",
    "\n",
    "            for i, finger in enumerate(fingers_cal):\n",
    "                x_values.append(i)\n",
    "                y_values_tot.append(np.mean(range_raw_tps_subject[subject][segment][finger])) #ajoute a y les valeurs moyennes des range des run pour chaque doigt\n",
    "\n",
    "            y_values_tot = (np.array(y_values_tot) - y_min) / (y_max_range - y_min)\n",
    "\n",
    "            fig.add_trace(go.Scatter(x=x_values,y=y_values_tot,marker=dict(size=16,cmax=1,cmin=0,color=y_values_tot,colorbar=dict(title='Colorbar, 1=' + str(y_max_range) + '[lbs]'),\n",
    "                    colorscale=\"rainbow\"), mode=\"markers\"))\n",
    "            \n",
    "            fig.update_layout(title='Mean value of ranges, one subject',xaxis_title='left_index,  left_middle,  left_thumb, right_index, right_middle, right_thumb',\n",
    "                   yaxis_title='TPS data',yaxis_range=[0,y_limit_range])\n",
    "\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS', 'TPS_range_colormap_subject' +subject + '_segment' + segment + '_' +'.png'))\n",
    "\n",
    "            \n",
    "            \n",
    "                \n",
    "            #figures for each run separately\n",
    "            for j, run in enumerate(run_list[subject][segment]):\n",
    "                fig = go.Figure()\n",
    "                x_values = []\n",
    "                y_values = []      \n",
    "                            \n",
    "                for i, finger in enumerate(fingers_cal):\n",
    "                    x_values.append(i)\n",
    "\n",
    "                    mean_signal = np.mean(tps_segment_subject[subject][segment][finger][j]) #moyenne pour 1 run pour un subject, valeur abs de la derivee\n",
    "                    y_values.append(mean_signal)\n",
    "\n",
    "                y_values = (np.array(y_values) - y_min) / (y_max_diff - y_min)\n",
    "                \n",
    "\n",
    "                fig.add_trace(go.Scatter(x=x_values, y=y_values, marker=dict(size=16, cmax=1,cmin=0,color=y_values,colorbar=dict(title='Colorbar, 1=' + str(y_max_diff) + '[lbs/s]'),\n",
    "                        colorscale=\"rdylgn_r\"),mode=\"markers\"))\n",
    "                \n",
    "                fig.update_layout(title='Mean abs value of derivative, one run', xaxis_title='left_index,  left_middle,  left_thumb, right_index, right_middle, right_thumb',\n",
    "                   yaxis_title='TPS data', yaxis_range=[0,y_limit_diff])\n",
    "\n",
    "\n",
    "                if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'PLOTS','TPS_colormap')):\n",
    "                            os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'PLOTS', 'TPS_colormap'))\n",
    "\n",
    "                fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'PLOTS', 'TPS_colormap', 'TPS_diff_colormapsubject' +subject + '_segment' + segment + 'run_' + run +'.png'))\n",
    "\n",
    "                \n",
    "            for j, run in enumerate(run_list[subject][segment]):\n",
    "                fig = go.Figure()\n",
    "                x_values = []\n",
    "                y_values = []\n",
    "\n",
    "                for i, finger in enumerate(fingers_cal):\n",
    "                    x_values.append(i)\n",
    "                    y_values.append(np.array(range_raw_tps_subject[subject][segment][finger][j]))\n",
    "                    \n",
    "                y_values = (np.array(y_values) - y_min) / (y_max_range - y_min)\n",
    "\n",
    "                fig.add_trace(go.Scatter(x=x_values,y=y_values,marker=dict(size=16,cmax=1,cmin=0,color=y_values,colorbar=dict(title='Colorbar, 1=' + str(y_max_range) + '[lbs]'),\n",
    "                        colorscale=\"rdylgn_r\"), mode=\"markers\"))\n",
    "                \n",
    "                fig.update_layout(title='Values of ranges, one run', xaxis_title='left_index,  left_middle,  left_thumb, right_index, right_middle, right_thumb',\n",
    "                   yaxis_title='TPS data', yaxis_range=[0,y_limit_range])\n",
    "\n",
    "                fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'PLOTS', 'TPS_colormap', 'TPS_range_colormapsubject' +subject + '_segment' + segment + 'run_' + run +'.png'))\n",
    "\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf9d33-d6e7-41b6-9009-4928bf628db0",
   "metadata": {},
   "source": [
    "### plots raw signal and derivative (absolute value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "20731c5e-abb8-4005-b447-192c6e7b73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'TPS_calibrated'\n",
    "\n",
    "for subject in subject_list:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #CONVERSION EN SECONDES\n",
    "            \n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                fingers_cal[0]: data_segments[subject][segment][run][sensor][fingers_cal[0]][1:-1],\n",
    "                fingers_cal[1]: data_segments[subject][segment][run][sensor][fingers_cal[1]][1:-1],\n",
    "                fingers_cal[2]: data_segments[subject][segment][run][sensor][fingers_cal[2]][1:-1],\n",
    "                fingers_cal[3]: data_segments[subject][segment][run][sensor][fingers_cal[3]][1:-1],\n",
    "                fingers_cal[4]: data_segments[subject][segment][run][sensor][fingers_cal[4]][1:-1],\n",
    "                fingers_cal[5]: data_segments[subject][segment][run][sensor][fingers_cal[5]][1:-1],\n",
    "                'Derivation, abs value, left index':abs_diff_tps[subject][segment][run][fingers_cal[0]],\n",
    "                'Derivation, abs value, left middle':abs_diff_tps[subject][segment][run][fingers_cal[1]],\n",
    "                'Derivation, abs value, left thumb':abs_diff_tps[subject][segment][run][fingers_cal[2]],\n",
    "                'Derivation, abs value, right index':abs_diff_tps[subject][segment][run][fingers_cal[3]],\n",
    "                'Derivation, abs value, right middle':abs_diff_tps[subject][segment][run][fingers_cal[4]],\n",
    "                'Derivation, abs value, right thumb':abs_diff_tps[subject][segment][run][fingers_cal[5]]\n",
    "            })\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[0]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[0]))\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[1]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[1]))\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[2]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[2]))\n",
    "\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[3]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[3]))\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[4]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[4]))\n",
    "            fig.add_trace(go.Scatter(y=df[fingers_cal[5]], x=time_current-time_current[0],\n",
    "                    mode='lines', name=fingers_cal[5]))\n",
    "            #fig.show()\n",
    "            \n",
    "    \n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'tps_plots' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'tps_plots'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION','tps_plots', 'segment' + segment  +'_raw_cal.png'))\n",
    "    \n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, left index'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, left index'))\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, left middle'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, left middle'))\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, left thumb'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, left thumb'))\n",
    "\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, right index'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, right index'))\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, right middle'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, right middle'))\n",
    "            fig.add_trace(go.Scatter(y=df['Derivation, abs value, right thumb'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Derivation, abs value, right thumb'))\n",
    "            #fig.show()\n",
    "            \n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION','tps_plots', 'segment' + segment +'_abs_derivative.png'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cae2ed-2a95-4a85-a1fe-0e51cc9a70cb",
   "metadata": {},
   "source": [
    "### Plots finger activity (= sum of abs derivative of force for active fingers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36389de1-73f9-4729-a727-3ca978976b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tps activity = sum derivative active fingers\n",
    "\n",
    "sensor = 'TPS_calibrated'\n",
    "\n",
    "subject_list_tps_activity = ['10','9','3','7','6','5','4']\n",
    "segment_list_tps_activity =['560','540','500','510','541','530']\n",
    "   \n",
    "\n",
    "for subject in subject_list_tps_activity:   \n",
    "    for segment in segment_list_tps_activity:\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #CONVERSION EN SECONDES\n",
    "                \n",
    "            df = pd.DataFrame({\n",
    "                'Activity right hand':sum_derivative_RH[subject][segment][run]/max(sum_derivative_RH[subject][segment][run]),\n",
    "                'Activity left hand':sum_derivative_LH[subject][segment][run]/max(sum_derivative_LH[subject][segment][run]),\n",
    "                \n",
    "            })\n",
    "            \n",
    "            fig  = go.Figure()\n",
    "            fig = make_subplots(rows=2, cols=1) \n",
    "            \n",
    "            fig.add_trace(go.Scatter(y=df['Activity right hand'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Right hand'),1,1)\n",
    "            fig.add_trace(go.Scatter(y=df['Activity left hand'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Left hand'),2,1)\n",
    "            \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment), xaxis_title='Time', yaxis_title='TPS derivative', width=1025, height=500)\n",
    "            \n",
    "            fig.update_yaxes(range=[0, 0.5])\n",
    "            #fig.show()\n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','tps_plots_activity', 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0dca33-cfe7-4d84-9485-eab0d44e2f39",
   "metadata": {},
   "source": [
    "### Plot mean activity time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcf9b3-0e83-42f0-b155-97f034049784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.axisbelow'] = True\n",
    "\n",
    "segment_list_tps_activity =['560','500','510','530','540','541']\n",
    "segment_new = ['1','2','3','4','5','6'] #new name of segments for the master thesis report\n",
    "    \n",
    "                \n",
    "subject_order = ['10','3','4','5','6','7','9']\n",
    "ALI_score = [3,4,4,7,7,9,9]#given in the order of the subjects\n",
    "\n",
    "        \n",
    "for k, segment in enumerate(segment_list_tps_activity):\n",
    "    eb1 = []\n",
    "    x = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    e1 = []\n",
    "    e2 = []\n",
    "    for subject in subject_order:\n",
    "        y1.append(mean_time_derivative_RH[subject][segment])\n",
    "        y2.append(mean_time_derivative_LH[subject][segment])\n",
    "        #if want to add the std on the errobars:\n",
    "        #e1.append(std_time_derivative_RH[subject][segment])  \n",
    "        #e2.append(std_time_derivative_LH[subject][segment])\n",
    "        \n",
    "    x= ALI_score\n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    \n",
    "    # if we want to have errobars with the std values:\n",
    "    #eb1 = plt.errorbar(x, y1, e1,lw=1, linestyle = 'None', marker='o')\n",
    "    #eb1 = plt.errorbar(x, y2, e2,lw=1, linestyle = 'None', marker='^')\n",
    "    \n",
    "    # Scatter plots, without errors:\n",
    "    plt.scatter(x, y1, s = 120 ,color='green', marker = 'o', label = 'Right hand')\n",
    "    plt.scatter(x, y2, s = 120 ,color='red', marker = '^', label = 'Left hand')\n",
    "\n",
    "    plt.ylabel('Mean time activity [s]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(3, 10, 1))\n",
    "    plt.xlim([2, 10])\n",
    "    \n",
    "    # adapt limits\n",
    "    plt.ylim(bottom = 0)\n",
    "    if segment == '560':\n",
    "        plt.ylim([0, 35])\n",
    "    else:\n",
    "        plt.ylim([0, 8])\n",
    "    \n",
    "    #uncomment to have legend\n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.05))\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'tps_activity')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'tps_activity'))\n",
    "    \n",
    "    # save plot with legend\n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'tps_activity_time_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "    #save plot without legend\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'no_legend', 'tps_activity_time_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e06935-c765-4c4b-83bf-d2febd6612f9",
   "metadata": {},
   "source": [
    "### plot mean number of peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82013248-8bcd-437f-95c5-5ca856702701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, segment in enumerate(segment_list_tps_activity):\n",
    "    eb1 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "\n",
    "    for subject in subject_order:\n",
    "        y1.append(mean_nb_peak_derivative_RH[subject][segment])\n",
    "        y2.append(mean_nb_peak_derivative_LH[subject][segment])\n",
    "        \n",
    "    x= ALI_score\n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "    plt.scatter(x, y1, s = 120 ,color='blue', marker = 'o', label = 'Right hand')\n",
    "    plt.scatter(x, y2, s = 120 ,color='orange', marker = '^', label = 'Left hand')\n",
    "\n",
    "    plt.ylabel('Nb of peaks [-]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(3, 10, 1))\n",
    "    plt.ylim(bottom = 0)\n",
    "    plt.xlim([2, 10])\n",
    "\n",
    "    # adapt limits\n",
    "    if segment == '560':\n",
    "        plt.yticks(np.arange(0, max([max(y1), max(y2)])+10, 25))\n",
    "        plt.ylim([0, 225])\n",
    "    else:\n",
    "        plt.ylim([0, 45])\n",
    "    \n",
    "    # uncomment to have legend\n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.05))\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'tps_activity')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'tps_activity'))\n",
    "    # save with legend\n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'tps_activity_nb_peak' + segment  +'.png'), bbox_inches='tight')\n",
    "    #save without legend\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity','no_legend', 'tps_activity_nb_peak' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661979c0-6840-4a54-8f56-fe5c3e5eb622",
   "metadata": {},
   "source": [
    "### Plot the activity signals and highlights the computed peaks on the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed1776-082f-48f3-9894-8ed899ec2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list_tps_activity:   \n",
    "    for run in run_list[subject][segment]:\n",
    "        for segment in ['560']:    \n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #CONVERSION EN SECONDES\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                    'Activity right hand':sum_derivative_RH[subject][segment][run]/max(sum_derivative_RH[subject][segment][run]),\n",
    "                    'Activity left hand':sum_derivative_LH[subject][segment][run]/max(sum_derivative_LH[subject][segment][run]),\n",
    "            })\n",
    "\n",
    "            fig  = go.Figure()\n",
    "            fig = make_subplots(rows=2, cols=1) \n",
    "            \n",
    "            # plot righ hand: activity and peaks\n",
    "            fig.add_trace(go.Scatter(y=df['Activity right hand'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Right hand'),1,1)\n",
    "            fig.add_trace(go.Scatter(y=nb_peaks_derivative_RH[subject][segment][run][1]['peak_heights'], x=time_current[nb_peaks_derivative_RH[subject][segment][run][0]]-time_current[0],\n",
    "                     mode = 'markers', name='Right hand peaks, nb: ' + str(len(nb_peaks_derivative_RH[subject][segment][run][1]['peak_heights']))),1,1)\n",
    "            \n",
    "            # plot left hand: activity and peaks\n",
    "            fig.add_trace(go.Scatter(y=df['Activity left hand'], x=time_current-time_current[0],\n",
    "                    mode='lines', name='Left hand'),2,1)\n",
    "            fig.add_trace(go.Scatter(y=nb_peaks_derivative_LH[subject][segment][run][1]['peak_heights'], x=time_current[nb_peaks_derivative_LH[subject][segment][run][0]]-time_current[0],\n",
    "                    mode='markers', name='Left hand peaks, nb: ' + str(len(nb_peaks_derivative_LH[subject][segment][run][1]['peak_heights']))),2,1)\n",
    "\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                   xaxis_title='Time', yaxis_title='TPS derivative', width=1025, height=500)\n",
    "\n",
    "            fig.update_yaxes(range=[0, 1])\n",
    "            #fig.show()\n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_peaks' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_peaks'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','tps_plots_activity_peaks', 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afec99b-d35a-4ed9-9413-22f9a684daf1",
   "metadata": {},
   "source": [
    "### plot mean values of the percentage of activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1e433-f3da-46d5-a336-ce0029180da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "for k, segment in enumerate(segment_list_tps_activity):\n",
    "    x = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "\n",
    "    for subject in subject_order:\n",
    "        y1.append(mean_sum_derivative_RH_pc[subject][segment])\n",
    "        y2.append(mean_sum_derivative_LH_pc[subject][segment])\n",
    "        y3.append(mean_sum_derivative_LRH_pc[subject][segment])\n",
    "\n",
    "    x= ALI_score\n",
    "    fig, axs = plt.subplots(1,3,figsize=(19.5, 4.5))\n",
    "        \n",
    "    ax1 = axs[0]\n",
    "    ax2 = axs[1]\n",
    "    ax3 = axs[2]\n",
    "\n",
    "    ax1.scatter(x, y1, s = 120 ,color='green', marker = 'o', label = 'Right hand')\n",
    "    ax2.scatter(x, y2, s = 120 ,color='red', marker = '^', label = 'Left hand')\n",
    "    ax3.scatter(x, y3, s = 120 ,color='blue', marker = '*', label = 'Both hand')\n",
    "    \n",
    "    legend_elements = [Line2D([0], [0],  marker='o', color='w', label='Right hand', markerfacecolor='green',  markeredgecolor = 'green',markersize=12),\n",
    "                      Line2D([0], [0], marker='^', color='w', label='Left hand', markerfacecolor='red', markeredgecolor = 'red', markersize=12),\n",
    "                      Line2D([0], [0], marker='*', color='w', label='Both hand', markerfacecolor='blue',  markeredgecolor = 'blue',markersize=12)]\n",
    "    \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    ax3.grid()\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='ALI score', ylabel='Percentage of activity')\n",
    "\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    ax1.set_xlim([2, 11])\n",
    "    ax2.set_xlim([2, 11])\n",
    "    ax3.set_xlim([2, 11])\n",
    "    \n",
    "    ax1.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax1.set_title(\"Right hand\")\n",
    "    ax2.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax2.set_title(\"Left hand\")\n",
    "    ax3.set_xticks(ticks=ticks, labels=ticks)    \n",
    "    ax3.set_title(\"Two hands\")\n",
    "    \n",
    "    fig.suptitle(\"Segment \" + segment_new[k], x = 0.15, fontsize=25)    \n",
    "    fig.subplots_adjust(hspace=0.8, top=0.8)\n",
    "    plt.xticks(np.arange(3, 10, 1))\n",
    "\n",
    "    # adapt limits to data\n",
    "    if segment == '560':\n",
    "        ax1.set_ylim([0, 15])    \n",
    "        ax2.set_ylim([0, 15])\n",
    "        ax3.set_ylim([0, 25])\n",
    "    else:\n",
    "        if segment == '541':\n",
    "            ax1.set_ylim([0, 60])    \n",
    "            ax2.set_ylim([0, 60])\n",
    "            ax3.set_ylim([0, 85])\n",
    "        \n",
    "        else:\n",
    "            ax1.set_ylim([0, 50])    \n",
    "            ax2.set_ylim([0, 50])\n",
    "            ax3.set_ylim([0, 85])\n",
    "\n",
    "    # uncomment to have legend\n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.05))\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder , 'PLOTS', 'tps_activity')):\n",
    "             os.makedirs(join(path_to_data_folder , 'PLOTS', 'tps_activity'))\n",
    "            \n",
    "    # to save with legend\n",
    "    #plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'tps_activity_time_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "    #save without legend\n",
    "    plt.savefig(join('..', 'data_exp' , 'PLOTS', 'tps_activity', 'no_legend', 'tps_activity_time_PC_segment' + segment  +'.png'),bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdafab3-b0c0-4d67-8c67-7538ebd21630",
   "metadata": {},
   "source": [
    "### Plot Activity signal of each separate fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f571e-d716-4a0d-b139-9c620a6cf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only plotted for some subjects and for the whole task to test, can add the other subjects/ segments\n",
    "subject_list_tps_activity = ['10','3','9']\n",
    "segment_list_tps_activity = ['560']\n",
    "\n",
    "for subject in subject_list_tps_activity:\n",
    "    for segment in segment_list_tps_activity:\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_current =  np.array(data_segments[subject][segment][run][sensor]['rel_time']/1000) #CONVERSION EN SECONDES\n",
    "            \n",
    "            fig  = go.Figure()\n",
    "            fig = make_subplots(rows=len(LH_fingers[subject]), cols=1)\n",
    "            \n",
    "            # plot the activity of each active finger on a subplot, left hand\n",
    "            for i, finger in enumerate(LH_fingers[subject]):\n",
    "                fig.add_trace(go.Scatter(y=abs_diff_tps[subject][segment][run][finger], x=time_current-time_current[0],\n",
    "                    mode='lines', name=finger),i+1,1)\n",
    "                \n",
    "            fig.update_xaxes(title_text=\"Time [s]\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Time [s] \", row=2, col=1)\n",
    "            fig.update_xaxes(title_text=\"Time [s]\", row=3, col=1)\n",
    "            fig.update_yaxes(title_text=\"[lbs/s]\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"[lbs/s]\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"[lbs/s]\", row=3, col=1)\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment), width=1025,height=500)\n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_LH' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_LH'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','tps_plots_activity_LH', 'separate_fingers_act_run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "            \n",
    "            fig  = go.Figure()\n",
    "            fig = make_subplots(rows=len(LH_fingers[subject]), cols=1)\n",
    "            \n",
    "            # same for right hand\n",
    "            for i, finger in enumerate(LH_fingers[subject]):\n",
    "                fig.add_trace(go.Scatter(y=np.array(data_segments[subject][segment][run][sensor][finger]), x=time_current-time_current[0],\n",
    "                    mode='lines', name=finger),i+1,1)\n",
    "                \n",
    "            fig.update_xaxes(title_text=\"Time [s]\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Time [s] \", row=2, col=1)\n",
    "            fig.update_xaxes(title_text=\"Time [s]\", row=3, col=1)\n",
    "            fig.update_yaxes(title_text=\"TPS force [lbs]\", row=1, col=1)\n",
    "            fig.update_yaxes(title_text=\"TPS force [lbs]\", row=2, col=1)\n",
    "            fig.update_yaxes(title_text=\"TPS force [lbs]\", row=3, col=1)\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment), height=500)\n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_LH' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'tps_plots_activity_LH'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','tps_plots_activity_LH', 'separate_fingers_force_run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "            \n",
    "            \n",
    "    for i, finger in enumerate(LH_fingers[subject]):        \n",
    "        print('Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment) + ' Finger' + finger + ' Mean range:   ' + str(np.mean(range_raw_tps_subject[subject][segment][finger])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee56c0f-752c-47cc-aed2-c203d178e4b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TPS: ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727d823-24b5-4e3f-a999-d4dbb37b6323",
   "metadata": {},
   "source": [
    "### one way anova test for the nb of movements (nb of activity peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caee635-8698-45c0-8197-0b08e2d9cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the data was put in a csv to make the test using matlab afterwards\n",
    "# direct anova test on python was also tested but not used (same results but matlab easier for plots)\n",
    "\n",
    "subject_list_tps_activity = ['10','9','3','7','6','5','4']\n",
    "\n",
    "#create the groups\n",
    "expert_subjects = ['4','10','3']\n",
    "intermediate_subjects = ['5','6']\n",
    "novice_subjects = ['7', '9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "nb_peaks_act_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    nb_peaks_act_segment_subject_expertise[segment] = []\n",
    "    \n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    # one csv file for each segment\n",
    "    rs_csv = join(folder,'ANOVA','TPS','nb_activity_peak_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w')       \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','value_nb_peaks_RH', 'value_nb_peaks_LH']\n",
    "    # write the header to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                # write every values for each run and each subject (without averaging values)\n",
    "                nb_peak_RH = (len(nb_peaks_derivative_RH[subject][segment][run][1]['peak_heights']))\n",
    "                nb_peak_LH = (len(nb_peaks_derivative_LH[subject][segment][run][1]['peak_heights']))\n",
    "                # write row with the corresponding group and values\n",
    "                row = [cat, nb_peak_RH, nb_peak_LH]\n",
    "                writer.writerow(row)\n",
    "                nb_peaks_act_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "                    \n",
    "# create dataframe for anova test \n",
    "nb_peaks_act_expertise_dataframe = {}\n",
    "for segment, values in nb_peaks_act_segment_subject_expertise.items():\n",
    "    nb_peaks_act_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_nb_peaks_RH\", \"value_nb_peaks_LH\"])\n",
    "    \n",
    "nb_peaks_act_anova_results = {}\n",
    "for segment, dataframe in nb_peaks_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_peaks_RH ~ C(category)', data=dataframe).fit()\n",
    "    nb_peaks_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(nb_peaks_act_anova_results[segment])\n",
    "print(\"-----------\")\n",
    "\n",
    "for segment, dataframe in nb_peaks_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_peaks_LH ~ C(category)', data=dataframe).fit()\n",
    "    nb_peaks_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(nb_peaks_act_anova_results[segment])\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65df67-e8fd-4089-98b1-f81f3f780933",
   "metadata": {},
   "source": [
    "### one way anova test for the activity time (time above threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3801c26-c517-4755-aee7-6c4bee50676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list_tps_activity = ['10','9','3','7','6','5','4']\n",
    "\n",
    "expert_subjects = ['4','10','3']\n",
    "intermediate_subjects = ['5','6']\n",
    "novice_subjects = ['7', '9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "time_act_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    time_act_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','TPS','time_activity_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w')                       \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','value_time_RH', 'value_time_LH']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                time_act_RH = time_derivative_RH[subject][segment][run]\n",
    "                time_act_LH = time_derivative_LH[subject][segment][run]\n",
    "                # write row with data and corresponding category\n",
    "                row = [cat, time_act_RH, time_act_LH]\n",
    "                writer.writerow(row)\n",
    "                time_act_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "                  \n",
    "\n",
    "time_act_expertise_dataframe = {}\n",
    "for segment, values in time_act_segment_subject_expertise.items():\n",
    "    time_act_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_time_RH\", \"value_time_LH\"])\n",
    "    \n",
    "time_act_anova_results = {}\n",
    "for segment, dataframe in time_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_time_RH ~ C(category)', data=dataframe).fit()\n",
    "    time_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(time_act_anova_results[segment])\n",
    "print(\"-----------\")\n",
    "for segment, dataframe in time_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_time_LH ~ C(category)', data=dataframe).fit()\n",
    "    time_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(time_act_anova_results[segment])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281032e4-2798-4874-8881-90638ad02fee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### one way anova test for the percentage of activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42435f6c-e318-42e3-adba-45c26b929416",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list_tps_activity = ['10','9','3','7','6','5','4']\n",
    "\n",
    "# expertise groups\n",
    "expert_subjects = ['4','10','3']\n",
    "intermediate_subjects = ['5','6']\n",
    "novice_subjects = ['7', '9']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "pc_act_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    pc_act_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','TPS','time_activity_PC_SEGMENT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','value_PC_RH', 'value_PC_LH', 'value_PC_LRH']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                pc_act_RH = sum_derivative_RH_pc[subject][segment][run]\n",
    "                pc_act_LH = sum_derivative_LH_pc[subject][segment][run]\n",
    "                pc_act_LRH = sum_derivative_LRH_pc[subject][segment][run]\n",
    "                # write data with coresponding category\n",
    "                row = [cat, pc_act_RH, pc_act_LH,pc_act_LRH]\n",
    "                writer.writerow(row)\n",
    "                pc_act_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "                \n",
    "\n",
    "pc_act_expertise_dataframe = {}\n",
    "for segment, values in pc_act_segment_subject_expertise.items():\n",
    "    pc_act_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_PC_RH\", \"value_PC_LH\",\"value_PC_LRH\"])\n",
    "    \n",
    "pc_act_anova_results = {}\n",
    "for segment, dataframe in pc_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_PC_RH ~ C(category)', data=dataframe).fit()\n",
    "    pc_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(pc_act_anova_results[segment])\n",
    "print(\"-----------\")\n",
    "\n",
    "for segment, dataframe in pc_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_PC_LH ~ C(category)', data=dataframe).fit()\n",
    "    pc_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(pc_act_anova_results[segment])\n",
    "print(\"-----------\")\n",
    "\n",
    "for segment, dataframe in pc_act_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_PC_LRH ~ C(category)', data=dataframe).fit()\n",
    "    pc_act_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(segment)\n",
    "    print(pc_act_anova_results[segment])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad977f6c-465d-4304-900b-1fe28df3eb4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optitrack data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf43a4-2d28-455a-89dd-8eaa5af5319a",
   "metadata": {},
   "source": [
    "## data review optitrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26d567-68ef-44e0-9029-256cd01d82b2",
   "metadata": {},
   "source": [
    "### remove 0 values (loss of tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cdbb8-1cf5-4e8d-a25f-a0cb2f2b799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'optitrack'\n",
    "subject_list_optitrack = ['2','3','4','5','6','7','8','9','10','11','12'] #remove subject 1 because bad tracking\n",
    "\n",
    "segment_list_optitrack = ['500','510','530','540','541']\n",
    "segment_new_optitrack = ['2','3','4','5','6']\n",
    "\n",
    "# variables with the tool names (position and quaternions) for tweezers and needle holder\n",
    "tools_position = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z']\n",
    "tools_quaternions = [ 'tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "# all tools\n",
    "tools = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'scissors_x', 'scissors_y', 'scissors_z', 'scissors_qx', 'scissors_qy', 'scissors_qz', 'scissors_qw', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "#data structure\n",
    "optitrack_segment_subject = {}\n",
    "optitrack_non_zero= {}\n",
    "optitrack_non_zero_time = {}\n",
    "for subject in subject_list_optitrack:   \n",
    "    optitrack_segment_subject[subject] = {}\n",
    "    optitrack_non_zero[subject]= {}\n",
    "    optitrack_non_zero_time[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        optitrack_segment_subject[subject][segment] = {}\n",
    "        optitrack_non_zero[subject][segment]= {}\n",
    "        optitrack_non_zero_time[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            optitrack_segment_subject[subject][segment][run] = {}\n",
    "            optitrack_non_zero[subject][segment][run]= {}\n",
    "            optitrack_non_zero_time[subject][segment][run] = {}\n",
    "            for tool in tools:  \n",
    "                optitrack_segment_subject[subject][segment][run][tool]=[]\n",
    "                optitrack_non_zero[subject][segment][run][tool] = []\n",
    "                optitrack_non_zero_time[subject][segment][run] [tool] = []\n",
    "\n",
    "# Remove 0 values from the data (loss of tracking) and tacking the corresponding time data to keep the data-time correspondance\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            for tool in tools:\n",
    "                time_current = data_segments[subject][segment][run][sensor]['rel_time']        \n",
    "                data_current = data_segments[subject][segment][run][sensor][tool]\n",
    "                \n",
    "                optitrack_segment_subject[subject][segment][run][tool] = data_current\n",
    "                optitrack_non_zero[subject][segment][run][tool] = data_current[data_current != 0] # data without 0 values\n",
    "                optitrack_non_zero_time[subject][segment][run][tool] = time_current[data_current != 0] # time corresponding to the data without the 0 values\n",
    "\n",
    "# get percentages of tracking to estimate quality of tracking\n",
    "for tool in ['tweezer_x', 'needle_holder2_x']:\n",
    "    for subject in subject_list_optitrack:   \n",
    "        for segment in ['560']:\n",
    "            for run in run_list[subject][segment]:             \n",
    "                print(\"subject: \" + subject + \" segment: \" + segment + \" run; \" + run + \" tool: \" + tool + str(len(optitrack_non_zero[subject][segment][run][tool])/len(optitrack_segment_subject[subject][segment][run][tool] )*100))\n",
    "            print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecfd73-c464-4731-817d-0368c3e97c9d",
   "metadata": {},
   "source": [
    "### compute speed and jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beeb5ef-c1cd-4135-b03e-c66e9ba2ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable definition\n",
    "iff_optitrack = {}\n",
    "diff_optitrack_time= {}\n",
    "acc_optitrack = {}\n",
    "acc_optitrack_time= {}\n",
    "butt_signal_speed_optitrack={}\n",
    "butt_signal_acc_optitrack={}\n",
    "acc_optitrack_filtered_speed={}\n",
    "jerk_optitrack_filtered_speed={}\n",
    "jerk_optitrack_filtered_speed_time={}\n",
    "for subject in subject_list_optitrack:   \n",
    "    diff_optitrack[subject]={}\n",
    "    diff_optitrack_time[subject] ={}\n",
    "    acc_optitrack[subject] ={}\n",
    "    acc_optitrack_time[subject]= {}\n",
    "    butt_signal_speed_optitrack[subject]={}\n",
    "    butt_signal_acc_optitrack[subject]={}\n",
    "    acc_optitrack_filtered_speed[subject]={}\n",
    "    jerk_optitrack_filtered_speed[subject]={}\n",
    "    jerk_optitrack_filtered_speed_time[subject]={}\n",
    "    for segment in segment_list:\n",
    "        diff_optitrack[subject][segment] = {}\n",
    "        diff_optitrack_time[subject][segment]={}\n",
    "        acc_optitrack[subject][segment]={}\n",
    "        acc_optitrack_time[subject][segment]= {}\n",
    "        butt_signal_speed_optitrack[subject][segment]={}\n",
    "        butt_signal_acc_optitrack[subject][segment]={}\n",
    "        acc_optitrack_filtered_speed[subject][segment]={}\n",
    "        jerk_optitrack_filtered_speed[subject][segment]={}\n",
    "        jerk_optitrack_filtered_speed_time[subject][segment]={}\n",
    "        for run in run_list[subject][segment]:\n",
    "            diff_optitrack[subject][segment][run]={}\n",
    "            diff_optitrack_time[subject][segment][run]={}\n",
    "            acc_optitrack[subject][segment][run]= {}\n",
    "            acc_optitrack_time[subject][segment][run]={}\n",
    "            butt_signal_speed_optitrack[subject][segment][run]={}\n",
    "            butt_signal_acc_optitrack[subject][segment][run]={}\n",
    "            acc_optitrack_filtered_speed[subject][segment][run]={}\n",
    "            jerk_optitrack_filtered_speed[subject][segment][run]={}\n",
    "            jerk_optitrack_filtered_speed_time[subject][segment][run]={}\n",
    "            for tool in tools:\n",
    "                diff_optitrack[subject][segment][run][tool] = []\n",
    "                diff_optitrack_time[subject][segment][run][tool] = []\n",
    "                acc_optitrack[subject][segment][run][tool] = []\n",
    "                acc_optitrack_time[subject][segment][run][tool] = []\n",
    "                butt_signal_speed_optitrack[subject][segment][run][tool] = []\n",
    "                butt_signal_acc_optitrack[subject][segment][run][tool] =[]\n",
    "                acc_optitrack_filtered_speed[subject][segment][run][tool] = []\n",
    "                jerk_optitrack_filtered_speed[subject][segment][run][tool] =[]\n",
    "                jerk_optitrack_filtered_speed_time[subject][segment][run][tool] = []\n",
    "\n",
    "\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "         for run in run_list[subject][segment]:\n",
    "            for tool in tools_position:\n",
    "                \n",
    "                data_current = np.array(optitrack_non_zero[subject][segment][run][tool] )\n",
    "                time_current = np.array(optitrack_non_zero_time[subject][segment][run][tool] )\n",
    "                \n",
    "                #compute derivative (speed)\n",
    "                #Newton diff method\n",
    "                diff_optitrack[subject][segment][run][tool] = (data_current[1:] - data_current[0:-1])/(time_current[1:] - time_current[0:-1])\n",
    "                #diff_optitrack[subject][segment][run][tool] = np.diff(data_current)/np.diff(time_current) #does the same\n",
    "                \n",
    "                # get corresponding time vector \n",
    "                diff_optitrack_time[subject][segment][run][tool] = ((time_current[1:]) + (time_current[0:-1]))/2\n",
    "                \n",
    "                # compute 2nd derivative (acceleration)\n",
    "                acc_optitrack[subject][segment][run][tool] = np.diff(diff_optitrack[subject][segment][run][tool])/np.diff(diff_optitrack_time[subject][segment][run][tool])\n",
    "                #acc_optitrack[subject][segment][run][tool] = (data_current[1:] - data_current[0:-1])/(time_current[1:] - time_current[0:-1])\n",
    "                \n",
    "                #get corresponding time vector\n",
    "                acc_optitrack_time[subject][segment][run][tool] = (np.array(diff_optitrack_time[subject][segment][run][tool][1:]) +  np.array(diff_optitrack_time[subject][segment][run][tool][0:-1]))/2\n",
    "                \n",
    "                # tested several filtering\n",
    "                # filtering the data: butterworth filter\n",
    "                fs = 120\n",
    "                fco_s = 5\n",
    "                fco_a = 10\n",
    "                fny = fs/2\n",
    "                N = 4\n",
    "                # filter speed\n",
    "                [b, a] = sp.butter(N, 1.16*fco_s/fny,  btype='low')\n",
    "                butt_signal_speed_optitrack[subject][segment][run][tool] = sp.filtfilt(b, a, diff_optitrack[subject][segment][run][tool])\n",
    "                # filter acceleration\n",
    "                [b, a] = sp.butter(N, 1.16*fco_a/fny,  btype='low')\n",
    "                butt_signal_acc_optitrack[subject][segment][run][tool] = sp.filtfilt(b, a, acc_optitrack[subject][segment][run][tool])\n",
    "                    \n",
    "                # get acceleration from the filtered speed\n",
    "                acc_optitrack_filtered_speed[subject][segment][run][tool] = np.diff(butt_signal_speed_optitrack[subject][segment][run][tool])/np.diff(diff_optitrack_time[subject][segment][run][tool])\n",
    "                 \n",
    "                # get jerk from the filtered speed and corespo. time vector    \n",
    "                jerk_optitrack_filtered_speed[subject][segment][run][tool] = np.diff(acc_optitrack_filtered_speed[subject][segment][run][tool])/np.diff(acc_optitrack_time[subject][segment][run][tool])\n",
    "                jerk_optitrack_filtered_speed_time[subject][segment][run][tool] =  (np.array(acc_optitrack_time[subject][segment][run][tool][1:]) +  np.array(acc_optitrack_time[subject][segment][run][tool][0:-1]))/2\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7b112-7b7a-415b-8680-f31cd03fce03",
   "metadata": {},
   "source": [
    "### data interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74addf5-c2b3-4016-a7dd-6fc9846f47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpole = {}\n",
    "time_vector_interp = {}\n",
    "interpolated_data = {}\n",
    "# tools with tweezers and nh, with positions ans quaternions\n",
    "tools3 = ['tweezer_x', 'tweezer_y', 'tweezer_z', 'tweezer_qx', 'tweezer_qy', 'tweezer_qz', 'tweezer_qw', 'needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z', 'needle_holder2_qx', 'needle_holder2_qy', 'needle_holder2_qz', 'needle_holder2_qw']\n",
    "\n",
    "# definition data\n",
    "for subject in subject_list_optitrack:   \n",
    "    Interpole[subject] = {}\n",
    "    time_vector_interp[subject]= {}\n",
    "    interpolated_data[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        Interpole[subject][segment] = {}\n",
    "        time_vector_interp[subject][segment]= {}\n",
    "        interpolated_data[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            Interpole[subject][segment][run] = {}\n",
    "            time_vector_interp[subject][segment][run]= {}\n",
    "            interpolated_data[subject][segment][run] = {}\n",
    "            for tool in tools:\n",
    "                Interpole[subject][segment][run][tool] = {}\n",
    "                time_vector_interp[subject][segment][run][tool]= {}\n",
    "                interpolated_data[subject][segment][run][tool] = {}\n",
    "\n",
    "# Interpolate position data to fill the gaps from loss of tracking (where we had 0 values)\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            for tool in tools3:\n",
    "                data = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                time = np.array(optitrack_non_zero_time[subject][segment][run][tool])\n",
    "                # create interpolation function\n",
    "                Interpole[subject][segment][run][tool] = inter.interp1d(time, data )\n",
    "                # time for the interpolation\n",
    "                time_step = 1/120\n",
    "                time_vector_interp[subject][segment][run][tool] = np.arange(time.min(),time.max()-time_step,time_step )\n",
    "                interpolated_data[subject][segment][run][tool] = Interpole[subject][segment][run][tool](time_vector_interp[subject][segment][run][tool])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a4a6b8-0b35-429e-84e1-159612149df9",
   "metadata": {},
   "source": [
    "### Compute the transformation matrix from marker to tip and marker to tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114aa26-4f8d-4a69-a770-034552008bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded tool and tooltip rotation and position in form [qw,qx,qy,qz,tx,ty,tz,1]\n",
    "#  Quaternion((w, x, y, z)) function: Creates a unit quaternion 1 + 0i + 0j + 0k\n",
    "# approximation for the 1st set of recorded data (not exact as fell several times + position measured afterwards, the marker was not placed exactly at same location)\n",
    "\n",
    "tools2 = [\"tweezer\", \"needle_holder2\"]\n",
    "tools_transf = {\n",
    "    \"tweezer\": {\n",
    "        \"marker_tip\": [-0.14002110139417,0.011598759188847,0.914789185044361,-0.378701883396705,0.203922977186312,0.225921215462611,0.337081560202788,1],     # the one from the fixed marker for tip measurement\n",
    "        \"tip\":  [-0.659606319391634,0.047673735107731,-0.082923699619772,-0.520023288973384,0.173957278833967,0.147784077313054,0.464396291508238,1]    # marker to rpz tip\n",
    "        \n",
    "    },\n",
    "\n",
    "    \"needle_holder2\":  {\n",
    "        \"marker_tip\": [-0.921827204331451,0.195545852165725,0.143764196798494,-0.302187299435028,0.181443717514124,0.300805392655367,0.335198482109228,1],\n",
    "        \"tip\":  [-0.864763969868174,-0.013123148775895,-0.07854127306968,-0.49579974858757,0.170293133709981,0.248165722222222,0.464240151600753,1]\n",
    "\n",
    "    }       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701dc06f-ed74-4749-9e4b-969e91762e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in tools2:\n",
    "    print(tool)\n",
    "    \n",
    "    marker_tip_quaternion = Quaternion(tools_transf[tool][\"marker_tip\"][:4])  #Return homogeneous rotation matrix from quaternion. = on calcule la matrice de rotation qui correspond aux quaternions du tool (chiffres en haut) #ATTENTION: normalise le quaternion a 1 donc pas exactemetn meme valeurs\n",
    "    T_marker_tip_fixed = marker_tip_quaternion.transformation_matrix         # deja en 4*4 matrix\n",
    "    \n",
    "    marker_tip_translation_vector = np.array((tools_transf[tool][\"marker_tip\"][-4:])) #Return matrix to translate by direction vector = on calcule la matrice de translation qui correspond aux positions du tool (chiffres en haut)\n",
    "    T_marker_tip_fixed[:,-1] = marker_tip_translation_vector       #matrice de transformation pour passer de mon objet au centre du reference frame  sa position actuelle (marker de l'outils)\n",
    "        \n",
    "\n",
    "    tip_quaternion = Quaternion(tools_transf[tool][\"tip\"][:4]) #matrice de rotation des quaternions du tip #ATTENTION: normalise le quaternion a 1 donc pas exactemetn meme valeurs\n",
    "    T_tip = tip_quaternion.transformation_matrix\n",
    "  \n",
    "    tip_translation_vector = np.array((tools_transf[tool][\"tip\"][-4:])) #-4 car 4 dernieres valeurs\n",
    "    T_tip[:,-1] = tip_translation_vector       #matrice de transformation pour passer de mon objet au centre du reference frame  sa position actuelle (tip de l'outils)\n",
    "    \n",
    "    T_marker_tip_fixed_inv = LA.inv(T_marker_tip_fixed)  \n",
    "    #T_marker_inv = np.identity(4)\n",
    "    #T_marker_inv[:3, :3] = LA.inv(T_tool[:3, :3])\n",
    "    #T_marker_inv[:3, -1] = -T_tool_inv[:3, :3].dot(T_tool[:3, -1]) #msimplement une autre maniere de la calculer l'inverse !!!!!!!!!!!!!!\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "## ORIGIN TO TIP, BASED ON MARKER POSITION\n",
    "     \n",
    "    T_marker_tip = T_marker_tip_fixed_inv.dot(T_tip) #Matrice mTtip = marker to tip\n",
    "    q_marker_tip = Quaternion(matrix = T_marker_tip)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a4dab-600e-42d2-a460-e41110abe189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put them in the format to compute oTmarker\n",
    "sensor = 'optitrack'\n",
    "translation_vector = {}\n",
    "quaternion_vector = {}\n",
    "position_vector_tip = {}\n",
    "position_vector_top = {}\n",
    "vector_top_to_tip = {}\n",
    "pos_x = {}\n",
    "pos_y = {}\n",
    "pos_z = {}\n",
    "pos_x_tip = {}\n",
    "pos_y_tip = {}\n",
    "pos_z_tip = {}\n",
    "#for tool in tools:\n",
    "#                            data_segments[subject][segment][run][sensor][tool]= data[tool]\n",
    "#                            data_segments[subject][segment][run][sensor]['rel_time'] = data['relative_time']   \n",
    "for subject in subject_list_optitrack:\n",
    "    translation_vector[subject] = {}\n",
    "    quaternion_vector[subject] = {}\n",
    "    position_vector_tip[subject] = {}\n",
    "    position_vector_top[subject] = {}\n",
    "\n",
    "    vector_top_to_tip[subject] = {}\n",
    "    pos_x[subject]= {}\n",
    "    pos_y[subject]= {}\n",
    "    pos_z[subject]= {}\n",
    "\n",
    "    pos_x_tip[subject]= {}\n",
    "    pos_y_tip[subject]= {}\n",
    "    pos_z_tip[subject]= {}\n",
    "    for segment in segment_list:\n",
    "        translation_vector[subject][segment] = {}\n",
    "        quaternion_vector[subject][segment] = {}\n",
    "        position_vector_tip[subject][segment] = {}\n",
    "        position_vector_top[subject][segment] = {}\n",
    "\n",
    "        vector_top_to_tip[subject][segment] = {}\n",
    "        pos_x[subject][segment]= {}\n",
    "        pos_y[subject][segment]= {}\n",
    "        pos_z[subject][segment]= {}\n",
    "        pos_x_tip[subject][segment]= {}\n",
    "        pos_y_tip[subject][segment]= {}\n",
    "        pos_z_tip[subject][segment]= {}        \n",
    "        for run in run_list[subject][segment]:\n",
    "            translation_vector[subject][segment][run] = {}\n",
    "            quaternion_vector[subject][segment][run] = {}\n",
    "            position_vector_tip[subject][segment][run] = {}\n",
    "            position_vector_top[subject][segment][run] = {}\n",
    "            vector_top_to_tip[subject][segment][run] = {}\n",
    "            pos_x[subject][segment][run]= {}\n",
    "            pos_y[subject][segment][run]= {}\n",
    "            pos_z[subject][segment][run]= {}\n",
    "            pos_x_tip[subject][segment][run]= {}\n",
    "            pos_y_tip[subject][segment][run]= {}\n",
    "            pos_z_tip[subject][segment][run]= {}\n",
    "            \n",
    "            for tool in tools2:\n",
    "                #T_marker_tip = []\n",
    "                #[T_marker_top, T_marker_tip] = get_transformation_matrix(tool)\n",
    "                \n",
    "                translation_vector[subject][segment][run][tool] = []\n",
    "                quaternion_vector[subject][segment][run][tool]  = []\n",
    "                position_vector_tip[subject][segment][run][tool]  = []\n",
    "                position_vector_top[subject][segment][run][tool]  = []\n",
    "                vector_top_to_tip[subject][segment][run][tool] = []\n",
    "                pos_x[subject][segment][run][tool] = []\n",
    "                pos_y[subject][segment][run][tool] = []\n",
    "                pos_z[subject][segment][run][tool] = []\n",
    "                pos_x_tip[subject][segment][run][tool] = []\n",
    "                pos_y_tip[subject][segment][run][tool] = []\n",
    "                pos_z_tip[subject][segment][run][tool] = []\n",
    "                for i in range(len(interpolated_data[subject][segment][run][tool + '_' + 'x'])):\n",
    "                    current_trans_vect = np.array([np.array(interpolated_data[subject][segment][run][tool + '_' + 'x'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'y'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'z'])[i],1])\n",
    "                    translation_vector[subject][segment][run][tool].append(current_trans_vect)\n",
    "                    current_quaternion = np.array([np.array(interpolated_data[subject][segment][run][tool + '_' + 'qw'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qx'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qy'])[i], np.array(interpolated_data[subject][segment][run][tool + '_' + 'qz'])[i]])\n",
    "                    #ajoute a la suite pour une action, 1 sujet, un outils et un sgment le vecteur ieme vecteur x,y,z \n",
    "                    q = Quaternion(current_quaternion)\n",
    "                    quaternion_vector[subject][segment][run][tool].append(current_quaternion)                       \n",
    "                   \n",
    "                    T_marker = q.transformation_matrix        \n",
    "                    T_marker[:,-1] = current_trans_vect\n",
    "                    \n",
    "                    tmp_pos_tip = T_marker.dot(T_marker_tip)[0:3,-1]\n",
    "                    tmp_pos_top = current_trans_vect[0:3]\n",
    "                    \n",
    "                    position_vector_tip[subject][segment][run][tool].append(tmp_pos_tip) #prend le vecteur de translation de la matrice obtenue qui correspond a la position par rapport au referentiel\n",
    "                    position_vector_top[subject][segment][run][tool].append(tmp_pos_top)\n",
    "                    \n",
    "                    tmp_top_to_tip = np.subtract(tmp_pos_tip, tmp_pos_top)\n",
    "                    \n",
    "                    vector_top_to_tip[subject][segment][run][tool].append(tmp_top_to_tip) #format x,y,y\n",
    "                \n",
    "                pos_x[subject][segment][run][tool] = [item[0] for item in vector_top_to_tip[subject][segment][run][tool]]  #que les x\n",
    "                pos_y[subject][segment][run][tool] = [item[1] for item in vector_top_to_tip[subject][segment][run][tool]]  \n",
    "                pos_z[subject][segment][run][tool] = [item[2] for item in vector_top_to_tip[subject][segment][run][tool]]\n",
    "                \n",
    "                pos_x_tip[subject][segment][run][tool] = [item[0] for item in position_vector_tip[subject][segment][run][tool]]  #que les x\n",
    "                pos_y_tip[subject][segment][run][tool] = [item[1] for item in position_vector_tip[subject][segment][run][tool]]  \n",
    "                pos_z_tip[subject][segment][run][tool] = [item[2] for item in position_vector_tip[subject][segment][run][tool]]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b99071-bc2c-4f2b-96fa-9bbd6278cb58",
   "metadata": {},
   "source": [
    "## compute speed of tip and norm of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2cfa6ba0-957d-4ad8-bdab-da1585b8e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_x_tip = {}\n",
    "diff_y_tip = {}\n",
    "diff_z_tip = {}\n",
    "diff_tip_vector = {}\n",
    "norm_tip_speed = {}\n",
    "for subject in subject_list_optitrack:   \n",
    "    diff_x_tip[subject] = {}\n",
    "    diff_y_tip[subject] = {}\n",
    "    diff_z_tip[subject] = {}\n",
    "    diff_tip_vector[subject] = {}\n",
    "    norm_tip_speed[subject] = {}\n",
    "    for segment in segment_list:\n",
    "        diff_x_tip[subject][segment] = {}\n",
    "        diff_y_tip[subject][segment] = {}\n",
    "        diff_z_tip[subject][segment] = {}\n",
    "        diff_tip_vector[subject][segment] = {}\n",
    "        norm_tip_speed[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "            diff_x_tip[subject][segment][run] = {}\n",
    "            diff_y_tip[subject][segment][run] = {}\n",
    "            diff_z_tip[subject][segment][run] = {}\n",
    "            diff_tip_vector[subject][segment][run] = {}\n",
    "            norm_tip_speed[subject][segment][run] = {}\n",
    "            for tool in tools2:\n",
    "                diff_x_tip[subject][segment][run][tool] = []\n",
    "                diff_y_tip[subject][segment][run][tool] = []\n",
    "                diff_z_tip[subject][segment][run][tool] = []\n",
    "                diff_tip_vector[subject][segment][run][tool] = []\n",
    "                norm_tip_speed[subject][segment][run][tool] = []\n",
    "\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "         for run in run_list[subject][segment]:\n",
    "            for tool in tools2:\n",
    "                data_current_x = np.array(pos_x_tip[subject][segment][run][tool]) # position tip from NON ZERO values of position of marker\n",
    "                data_current_y = np.array(pos_y_tip[subject][segment][run][tool])\n",
    "                data_current_z = np.array(pos_z_tip[subject][segment][run][tool])\n",
    "\n",
    "                time_current = np.array(time_vector_interp[subject][segment][run][tool + '_' + 'x'] )\n",
    "                \n",
    "                diff_x_tip[subject][segment][run][tool] = (data_current_x[1:] - data_current_x[0:-1])/(time_current[1:] - time_current[0:-1])\n",
    "                diff_y_tip[subject][segment][run][tool] = (data_current_y[1:] - data_current_y[0:-1])/(time_current[1:] - time_current[0:-1])\n",
    "                diff_z_tip[subject][segment][run][tool] = (data_current_z[1:] - data_current_z[0:-1])/(time_current[1:] - time_current[0:-1])\n",
    "\n",
    "                diff_optitrack_time[subject][segment][run][tool] = ((time_current[1:]) + (time_current[0:-1]))/2\n",
    "                \n",
    "                for i in range(len(diff_x_tip[subject][segment][run][tool])):\n",
    "                    v = [diff_x_tip[subject][segment][run][tool][i], diff_y_tip[subject][segment][run][tool][i], diff_z_tip[subject][segment][run][tool][i]]\n",
    "                    diff_tip_vector[subject][segment][run][tool].append(v)\n",
    "                    norm_tip_speed[subject][segment][run][tool].append(LA.norm(v,2)) \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ab500-d5f2-4666-9154-e9b41e3df693",
   "metadata": {},
   "source": [
    "## Metrics Optitrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8a713-af83-468b-89b6-3ca1038637b1",
   "metadata": {},
   "source": [
    "### find ranges (max hand travel distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed6216-106a-4fd9-98f1-404ddc640470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "range_travel = {}\n",
    "mean_run_range_travel = {}\n",
    "for subject in subject_list_optitrack:   \n",
    "    range_travel[subject] = {}\n",
    "    mean_run_range_travel[subject] = {}\n",
    "    for segment in segment_list_optitrack:\n",
    "        range_travel[subject][segment] = {}\n",
    "        mean_run_range_travel[subject][segment] = {}\n",
    "        for run in run_list[subject][segment]:\n",
    "        \n",
    "            range_travel[subject][segment][run] = {}\n",
    "            \n",
    "            for tool in tools_position:\n",
    "                range_travel[subject][segment][run][tool] = []\n",
    "                \n",
    "                mean_run_range_travel[subject][segment][tool] = []\n",
    "                \n",
    "                \n",
    "data = []\n",
    "col_names = ['Subject', 'Segment', tools_position[0], tools_position[1], tools_position[2],  tools_position[3],  tools_position[4],  tools_position[5]]\n",
    "for subject in subject_list_optitrack: \n",
    "    for segment in segment_list_optitrack:\n",
    "        for tool in tools_position:\n",
    "            for run in run_list[subject][segment]:\n",
    "            \n",
    "                range_travel[subject][segment][run][tool] = max(optitrack_non_zero[subject][segment][run][tool]) - min(optitrack_non_zero[subject][segment][run][tool])\n",
    "                mean_run_range_travel[subject][segment][tool].append(range_travel[subject][segment][run][tool])\n",
    "                \n",
    "            mean_run_range_travel[subject][segment][tool] = np.mean( mean_run_range_travel[subject][segment][tool])  \n",
    "        \n",
    "        data.append([subject, segment, mean_run_range_travel[subject][segment][tools_position[0]]*1000,\n",
    "                     mean_run_range_travel[subject][segment][tools_position[1]]*1000, \n",
    "                     mean_run_range_travel[subject][segment][tools_position[2]]*1000,\n",
    "                    mean_run_range_travel[subject][segment][tools_position[3]]*1000,\n",
    "                    mean_run_range_travel[subject][segment][tools_position[4]]*1000,\n",
    "                    mean_run_range_travel[subject][segment][tools_position[5]]*1000]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f574c2-d1b6-4020-a60a-3955b129909d",
   "metadata": {},
   "source": [
    "### jerk analzsis: number of jerky motions using the peaks of the jerk signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582512df-6164-4271-b476-e3580ad51d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_optitrack= {}\n",
    "nb_peaks_jerk={}\n",
    "mean_nb_peaks_jerk={}\n",
    "mean_duration_run={}\n",
    "for subject in subject_list_optitrack: \n",
    "    peaks_optitrack[subject]= {}\n",
    "    nb_peaks_jerk[subject]={}\n",
    "    mean_nb_peaks_jerk[subject]={}\n",
    "    mean_duration_run[subject]={}\n",
    "    for segment in segment_list:\n",
    "        peaks_optitrack[subject][segment]={}\n",
    "        nb_peaks_jerk[subject][segment] ={}\n",
    "        mean_nb_peaks_jerk[subject][segment] ={}\n",
    "        mean_duration_run[subject][segment] = {}\n",
    "        \n",
    "        for run in run_list[subject][segment]:\n",
    "            peaks_optitrack[subject][segment][run] = {}\n",
    "            nb_peaks_jerk[subject][segment][run]=[]\n",
    "\n",
    "            \n",
    "            for tool in tools_position:\n",
    "                peaks_optitrack[subject][segment][run][tool]=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        list_sum_peaks_subject_segment = []\n",
    "        list_duration_runs =[]\n",
    "        for run in run_list[subject][segment]:\n",
    "            nb_peaks_optitrack = []\n",
    "            \n",
    "            for tool in tools_position:\n",
    "                time_current = jerk_optitrack_filtered_speed_time[subject][segment][run][tool] \n",
    "                data = jerk_optitrack_filtered_speed[subject][segment][run][tool]\n",
    "                \n",
    "                peaks_optitrack[subject][segment][run][tool] = sp.find_peaks(data, height=10, threshold=None, distance=5, prominence=None, width=0, wlen=None, rel_height=1, plateau_size=None)\n",
    "                nb_peaks_optitrack.append(len(peaks_optitrack[subject][segment][run][tool][1]['peak_heights']))\n",
    "                \n",
    "                \n",
    "            nb_peaks_jerk[subject][segment][run] = sum(nb_peaks_optitrack) #somme des pic de jerk pour un sujet, un run , un segment\n",
    "            list_sum_peaks_subject_segment.append(sum(nb_peaks_optitrack)) #liste des sommes de pics pour un sujet, un segment, les runs\n",
    "            list_duration_runs.append(time_current[-1] - time_current[0])\n",
    "        mean_nb_peaks_jerk[subject][segment] = np.mean(list_sum_peaks_subject_segment)#moyenne du nb de pic pour un eujt un segment sur les runs\n",
    "        mean_duration_run[subject][segment] = np.mean(list_duration_runs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85e7ec-7db7-4a90-b36d-769ad34bb016",
   "metadata": {},
   "source": [
    "### compute correlation between speed of the 2 tools at tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3fdc9671-3226-4f5f-a89b-674b140027de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not same soze, take first part, subject 3run 4segment 530\n",
      "not same soze, take first part, subject 3run 7segment 530\n",
      "not same soze, take first part, subject 4run 4segment 530\n",
      "not same soze, take first part, subject 4run 5segment 560\n",
      "not same soze, take first part, subject 5run 5segment 540\n",
      "not same soze, take first part, subject 6run 5segment 560\n",
      "not same soze, take first part, subject 7run 1segment 510\n",
      "not same soze, take first part, subject 7run 1segment 530\n",
      "not same soze, take first part, subject 7run 1segment 540\n",
      "not same soze, take first part, subject 7run 1segment 541\n",
      "not same soze, take first part, subject 8run 3segment 500\n",
      "not same soze, take first part, subject 8run 4segment 510\n",
      "not same soze, take first part, subject 9run 3segment 510\n",
      "not same soze, take first part, subject 11run 5segment 540\n",
      "not same soze, take first part, subject 12run 3segment 530\n",
      "not same soze, take first part, subject 12run 1segment 540\n"
     ]
    }
   ],
   "source": [
    "BD = {}\n",
    "mean_BD = {}\n",
    "for subject in subject_list_optitrack:   \n",
    "    BD[subject]= {}\n",
    "    mean_BD[subject]={}\n",
    "    for segment in segment_list:\n",
    "        BD[subject][segment] = {}\n",
    "        mean_BD[subject][segment] =[]\n",
    "        for run in run_list[subject][segment]:\n",
    "            BD[subject][segment][run]  = []\n",
    "\n",
    "for subject in subject_list_optitrack:  \n",
    "    #print(subject)\n",
    "    for segment in segment_list:\n",
    "        #print(segment)\n",
    "        tmp_BD_mean = []\n",
    "        tmp_mat_BD = []\n",
    "        for run in run_list[subject][segment]:\n",
    "            #print(run)\n",
    "            if len(norm_tip_speed[subject][segment][run][\"tweezer\"]) != len(norm_tip_speed[subject][segment][run][\"needle_holder2\"]): #case if we miss last values of one tool = interpolation smaller donc pas meme nb de valeurs (ex S3 r4 seg 530)\n",
    "                print(\"not same size, take first part, subject \" + subject + \"run \" + run + \"segment \" + segment)\n",
    "                M = min(len(norm_tip_speed[subject][segment][run][\"tweezer\"]), len(norm_tip_speed[subject][segment][run][\"needle_holder2\"]))\n",
    "                tmp_mat_BD = np.corrcoef(norm_tip_speed[subject][segment][run][\"tweezer\"][0:M], norm_tip_speed[subject][segment][run][\"needle_holder2\"][0:M])\n",
    "            else:\n",
    "                tmp_mat_BD = np.corrcoef(norm_tip_speed[subject][segment][run][\"tweezer\"], norm_tip_speed[subject][segment][run][\"needle_holder2\"])\n",
    "\n",
    "            BD[subject][segment][run] = tmp_mat_BD[0,1]\n",
    "            tmp_BD_mean.append(BD[subject][segment][run])\n",
    "        mean_BD[subject][segment] = np.mean(tmp_BD_mean)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d119bda-5657-4508-a603-6e064c6f6a58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PLOTS Optitrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77438a-f564-4279-86d4-aca7043647d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots signaux total\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            time_current =  optitrack_non_zero_time[subject][segment][run][tool]\n",
    "            fig = go.Figure()\n",
    "            for tool in tools_position:  \n",
    "                \n",
    "                data_current = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='markers', name=tool))\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Optitrack data [m]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_position_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065db60-f1b1-4f61-83ca-a41ee4527da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98bc5d-4fc1-4beb-b529-5772dd72b28a",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69537511-e311-4a13-abb1-a8c653e9bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cda05-0786-4881-b434-b0f2a80c11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTS      \n",
    "#print(tabulate(data, headers=col_names, tablefmt=\"grid\"))\n",
    "\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','6','7','7','9','9','10']\n",
    "#subject_list_optitrack = ['2','3','4','5','6','7','8','9','10','11','12']\n",
    "\n",
    "\n",
    "for segment in segment_list_optitrack:\n",
    "    y1 = {}\n",
    "    for i,tool in enumerate(tools_position):\n",
    "        y1[i] = []\n",
    "\n",
    "        for subject in subject_order:\n",
    "            y1[i].append(mean_run_range_travel[subject][segment][tools_position[i]]*1000)\n",
    "          \n",
    "        x= ALI_score\n",
    "\n",
    "\n",
    "    fig  = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=3) \n",
    "\n",
    "    fig.add_trace(go.Scatter(y=y1[0], x=x, \n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[0]),1,1)\n",
    "    fig.add_trace(go.Scatter(y=y1[1], x=x,\n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[1]),1,2)\n",
    "    fig.add_trace(go.Scatter(y=y1[2], x=x,\n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[2]),1,3)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=3)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=3)\n",
    "    \n",
    "    \n",
    "    fig.update_layout(title='Segment:' + str(segment) ,\n",
    "               #xaxis_title='ALI',\n",
    "               #yaxis_title='Mean range[mm]',\n",
    "               width=1500,\n",
    "               height=500,\n",
    "                         )\n",
    "    fig.update_traces(\n",
    "        marker_size=12,\n",
    "        marker_line=dict(width=2, color='#2F4F4F'),\n",
    "        selector=dict(mode='markers+text'))\n",
    "    \n",
    "\n",
    "    #fig.update_yaxes(range=[0, 0.5])\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_hand_travel' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_hand_travel'))\n",
    "    fig.write_image(join('..', 'data_exp',  'PLOTS','optitrack_hand_travel', 'segment' + segment  +'tweezer.png'))\n",
    "    \n",
    "    \n",
    "    fig  = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=3) \n",
    "\n",
    "    fig.add_trace(go.Scatter(y=y1[3], x=x, text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[3]),1,1)\n",
    "    fig.add_trace(go.Scatter(y=y1[4], x=x, text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[4]),1,2)\n",
    "    fig.add_trace(go.Scatter(y=y1[5], x=x,text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name=tools_position[5]),1,3)\n",
    "    fig.update_traces(\n",
    "        marker_size=12,\n",
    "        marker_line=dict(width=2, color='#2F4F4F'),\n",
    "        selector=dict(mode='markers+text'))\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=3)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Mean range[mm]\", row=1, col=3)\n",
    "\n",
    "\n",
    "    fig.update_layout(title=' Segment:' + str(segment) ,\n",
    "               #xaxis_title='ALI',\n",
    "               #yaxis_title='Mean range[mm]',\n",
    "               width=1500,\n",
    "               height=500,\n",
    "                         )\n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_hand_travel' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_hand_travel'))\n",
    "    fig.write_image(join('..', 'data_exp',  'PLOTS','optitrack_hand_travel', 'segment' + segment  +'holder.png'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976683a-e9d1-4c3b-8012-0caba554e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 25}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "tool_plot = ['Tweezers', 'Needle Holder']\n",
    "\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','6','7','7','9','9','10']\n",
    "\n",
    "subject_order_novice = ['7','9','12']\n",
    "ALI_novice = [9,9,10]\n",
    "subject_order_intermediate = ['11','8','2','5','6']\n",
    "ALI_intermediate = [6,6,6,7,7]\n",
    "subject_order_expert = ['10','3','4']\n",
    "ALI_expert = [3,4,4]\n",
    "\n",
    "for k, segment in enumerate(segment_list_optitrack):\n",
    "    y1 = {}\n",
    "    y2 = {}\n",
    "    y3 = {}\n",
    "    for i,tool in enumerate(tools_position):\n",
    "        y1[i] = [] #dd\n",
    "        y2[i] = []\n",
    "        y3[i] = []\n",
    "        x1 = ALI_expert\n",
    "        x2 = ALI_intermediate\n",
    "        x3 = ALI_novice\n",
    "        for subject in subject_order_expert:\n",
    "            y1[i].append(mean_run_range_travel[subject][segment][tools_position[i]]*1000)\n",
    "        for subject in subject_order_intermediate:\n",
    "            y2[i].append(mean_run_range_travel[subject][segment][tools_position[i]]*1000)\n",
    "        for subject in subject_order_novice:\n",
    "            y3[i].append(mean_run_range_travel[subject][segment][tools_position[i]]*1000)    \n",
    "        #for subject in subject_order:\n",
    "         #   y1[i].append(mean_run_range_travel[subject][segment][tools_position[i]]*1000)\n",
    "          \n",
    "        x= ALI_score\n",
    "\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3,figsize=(16.5, 5))\n",
    "    \n",
    "    ax1 = axs[0]\n",
    "    ax2 = axs[1]\n",
    "    ax3 = axs[2]\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='ALI score', ylabel='Mean range[mm]')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    \n",
    "    ax1.scatter(x1, y1[1], s = 120 ,color='c', marker = 'o', edgecolor = 'black', label ='Experts')\n",
    "    ax1.scatter(x2, y2[1], s = 120 ,color='c', marker = '^', edgecolor = 'black',label = 'Intermediates')\n",
    "    ax1.scatter(x3, y3[1], s = 120 ,color='c', marker = '*',edgecolor = 'black',label = 'Novices')\n",
    "    \n",
    "    ax2.scatter(x1, y1[2], s = 120 ,color='c', marker = 'o',edgecolor = 'black', label ='Experts')\n",
    "    ax2.scatter(x2, y2[2], s = 120 ,color='c', marker = '^', edgecolor = 'black',label = 'Intermediates')\n",
    "    ax2.scatter(x3, y3[2], s = 120 ,color='c', marker = '*', edgecolor = 'black',label = 'Novices')\n",
    "    \n",
    "    ax3.scatter(x1, y1[3], s = 120 ,color='c', marker = 'o', edgecolor = 'black',label ='Experts')\n",
    "    ax3.scatter(x2, y2[3], s = 120 ,color='c', marker = '^',edgecolor = 'black', label = 'Intermediates')\n",
    "    ax3.scatter(x3, y3[3], s = 120 ,color='c', marker = '*', edgecolor = 'black', label = 'Novices')\n",
    "    \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    ax3.grid()\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "\n",
    "        \n",
    "    ax1.set_xlim([2, 11])\n",
    "    ax1.set_ylim([0, 100])\n",
    "    ax1.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax1.set_title(\"x direction\")\n",
    "    ax2.set_xlim([2, 11])\n",
    "    ax2.set_ylim([0, 100])\n",
    "    ax2.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax2.set_title(\"z direction\")\n",
    "    ax3.set_xlim([2, 11])\n",
    "    ax3.set_ylim([0, 100])\n",
    "    ax3.set_xticks(ticks=ticks, labels=ticks)    \n",
    "    ax3.set_title(\"y direction\")\n",
    "    \n",
    "    legend_elements = [Line2D([0], [0],  marker='o', color='w', label='Experts', markerfacecolor='w', markeredgecolor = 'black', markersize=12),\n",
    "                      Line2D([0], [0], marker='^', color='w', label='Intermediates', markerfacecolor='w',  markeredgecolor = 'black',markersize=12),\n",
    "                      Line2D([0], [0], marker='*', color='w', label='Novices', markerfacecolor='w',  markeredgecolor = 'black', markersize=12)]\n",
    "                    #Patch(facecolor='aqua', edgecolor='w', label=tools_position[0]),\n",
    "                    #Patch(facecolor='red', edgecolor='w', label=tools_position[1]),\n",
    "                    #Patch(facecolor='darkslategrey', edgecolor='w', label=tools_position[2])]\n",
    "    \n",
    "    #ax3.legend(handles=legend_elements, loc='upper right',bbox_to_anchor=(1.6, 1.03))\n",
    "    \n",
    "    fig.suptitle(\"Segment \" + segment_new_optitrack[k]+ \", \" + tool_plot[0], x = 0.17, fontsize=25)    \n",
    "    fig.subplots_adjust(wspace= 0.1, hspace=0.6, top=0.8)\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_hand_travel' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_hand_travel'))\n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_hand_travel', 'V2segment' + segment  +'tweezer_nolegend.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3,figsize=(16.5, 5))\n",
    "    \n",
    "    ax1 = axs[0]\n",
    "    ax2 = axs[1]\n",
    "    ax3 = axs[2]\n",
    "    \n",
    "    ax1.scatter(x1, y1[3], s = 120 ,color='limegreen', marker = 'o', edgecolor = 'black', label ='Experts')\n",
    "    ax1.scatter(x2, y2[3], s = 120 ,color='limegreen', marker = '^', edgecolor = 'black', label = 'Intermediates')\n",
    "    ax1.scatter(x3, y3[3], s = 120 ,color='limegreen', marker = '*', edgecolor = 'black', label = 'Novices')\n",
    "    \n",
    "    ax2.scatter(x1, y1[5], s = 120 ,color='limegreen', marker = 'o', edgecolor = 'black', label ='Experts')\n",
    "    ax2.scatter(x2, y2[5], s = 120 ,color='limegreen', marker = '^', edgecolor = 'black', label = 'Intermediates')\n",
    "    ax2.scatter(x3, y3[5], s = 120 ,color='limegreen', marker = '*', edgecolor = 'black', label = 'Novices')\n",
    "    \n",
    "    ax3.scatter(x1, y1[4], s = 120 ,color='limegreen', marker = 'o' ,edgecolor = 'black')\n",
    "    ax3.scatter(x2, y2[4], s = 120 ,color='limegreen', marker = '^',edgecolor = 'black')\n",
    "    ax3.scatter(x3, y3[4], s = 120 ,color='limegreen', marker = '*',edgecolor = 'black')\n",
    "    \n",
    "    legend_elements = [Line2D([0], [0],  marker='o', color='w', label='Experts', markerfacecolor='w',  markeredgecolor = 'black',markersize=12),\n",
    "                      Line2D([0], [0], marker='^', color='w', label='Intermediates', markerfacecolor='w', markeredgecolor = 'black', markersize=12),\n",
    "                      Line2D([0], [0], marker='*', color='w', label='Novices', markerfacecolor='w',  markeredgecolor = 'black',markersize=12)]\n",
    "                    #Patch(facecolor='violet', edgecolor='w', label=tools_position[3]),\n",
    "                   # Patch(facecolor='green', edgecolor='w', label=tools_position[5]),\n",
    "                   # Patch(facecolor='orange', edgecolor='w', label=tools_position[4])]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ax3.legend(handles=legend_elements, loc='upper right',bbox_to_anchor=(1.6, 1.03))\n",
    "    \n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    ax3.grid()\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='ALI score', ylabel='Mean range[mm]')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    #plt.legend(bbox_to_anchor=(1.65, 1.05))\n",
    "\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    ax1.set_xlim([2, 11])\n",
    "    ax1.set_ylim([0, 100])\n",
    "    ax1.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax1.set_title(\"x direction\")\n",
    "    ax2.set_xlim([2, 11])\n",
    "    ax2.set_ylim([0, 100])\n",
    "    ax2.set_xticks(ticks=ticks, labels=ticks)\n",
    "    ax2.set_title(\"z direction\")\n",
    "\n",
    "    ax3.set_xlim([2, 11])\n",
    "    ax3.set_ylim([0, 100])\n",
    "    ax3.set_xticks(ticks=ticks, labels=ticks)    \n",
    "    ax3.set_title(\"y direction\")\n",
    "    \n",
    "    fig.suptitle(\"Segment \" + segment_new_optitrack[k]+\", \" + tool_plot[1], x = 0.192, fontsize=25)    \n",
    "    fig.subplots_adjust(wspace= 0.1, hspace=0.5, top=0.8)\n",
    "   # plt.title('Segment: ' + segment, fontdict=None, loc='center', pad=None)\n",
    "\n",
    "    #plt.show()\n",
    "\n",
    "    \n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_hand_travel' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_hand_travel'))\n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_hand_travel', 'V2segment' + segment  +'holder_nolegend.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd19d9-e33b-413d-b8c1-f0fecd5b6438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace37661-b844-4175-bd9e-378c21901699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for subject in subject_list_optitrack: \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current =  diff_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = diff_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  diff_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = diff_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Speed [m/s]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_speed_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current = acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = acc_optitrack[subject][segment][run][tool] \n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = acc_optitrack[subject][segment][run][tool] \n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Acceleration [m/s2]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_acc_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current = diff_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = butt_signal_speed_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  diff_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = butt_signal_speed_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Speed [m/s]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_speed_filter_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "            \n",
    "            \n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current = acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = butt_signal_acc_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = butt_signal_acc_optitrack[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Speed [m/s]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_acc_filter_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))            \n",
    "            \n",
    "             \n",
    "for subject in subject_list_optitrack:\n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current = acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = acc_optitrack_filtered_speed[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  acc_optitrack_time[subject][segment][run][tool]\n",
    "                data_current = acc_optitrack_filtered_speed[subject][segment][run][tool]\n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Acceleration [m/s2]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_acc_filtered_speed_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))            \n",
    "                       \n",
    "for subject in subject_list_optitrack:\n",
    "    for segment in segment_list:\n",
    "         for run in run_list[subject][segment]:\n",
    "            \n",
    "            fig = go.Figure()\n",
    "            fig = make_subplots(rows=1, cols=2) \n",
    "            for tool in tools_position[0:3]:  \n",
    "                time_current = jerk_optitrack_filtered_speed_time[subject][segment][run][tool] \n",
    "                data_current = jerk_optitrack_filtered_speed[subject][segment][run][tool] \n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,1)\n",
    "                \n",
    "            for tool in tools_position[3:]:  \n",
    "                time_current =  jerk_optitrack_filtered_speed_time[subject][segment][run][tool] \n",
    "                data_current = jerk_optitrack_filtered_speed[subject][segment][run][tool] \n",
    "                \n",
    "                fig.add_trace(go.Scatter(y=data_current, x=time_current-data_segments[subject][segment][run][sensor]['rel_time'][0],\n",
    "                    mode='lines', name=tool),1,2)\n",
    "                \n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Jerk [m/s3]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_jerk_filtered_speed_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3b783-9472-4623-bfa3-ebcdc83f70d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646c64e-9a80-490c-a4d4-1a2b42c01d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "            \n",
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list: \n",
    "        for run in run_list[subject][segment]:\n",
    "           \n",
    "            fig  = go.Figure()\n",
    "            fig = make_subplots(rows=2, cols=1) \n",
    "            for tool in tools_position[0:3]:\n",
    "                time_current = jerk_optitrack_filtered_speed_time[subject][segment][run][tool] \n",
    "                data = jerk_optitrack_filtered_speed[subject][segment][run][tool]\n",
    "\n",
    "                fig.add_trace(go.Scatter(y=data, x=time_current-time_current[0],\n",
    "                        mode='lines', name=tool),1,1)\n",
    "                fig.add_trace(go.Scatter(y=peaks_optitrack[subject][segment][run][tool][1]['peak_heights'], x=time_current[peaks_optitrack[subject][segment][run][tool][0]]-time_current[0],\n",
    "                         mode = 'markers', name=tool + ' peaks, nb: ' + str(len(peaks_optitrack[subject][segment][run][tool][1]['peak_heights']))),1,1)\n",
    "\n",
    "            for tool in tools_position[3:]:\n",
    "                time_current = jerk_optitrack_filtered_speed_time[subject][segment][run][tool] \n",
    "                data = jerk_optitrack_filtered_speed[subject][segment][run][tool]\n",
    "                fig.add_trace(go.Scatter(y=data, x=time_current-time_current[0],\n",
    "                        mode='lines', name=tool),2,1)\n",
    "                fig.add_trace(go.Scatter(y=peaks_optitrack[subject][segment][run][tool][1]['peak_heights'], x=time_current[peaks_optitrack[subject][segment][run][tool][0]]-time_current[0],\n",
    "                        mode='markers', name=tool + ' peaks, nb: ' + str(len(peaks_optitrack[subject][segment][run][tool][1]['peak_heights']))),2,1)\n",
    "\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                   xaxis_title='Time',\n",
    "                   yaxis_title='Jerk',\n",
    "                   width=800,\n",
    "                   height=500,\n",
    "                             )\n",
    "\n",
    "            #fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "\n",
    "            #fig.show()\n",
    "\n",
    "\n",
    "\n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'jerk_peaks' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, 'PLOTS', 'jerk_peaks'))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, 'PLOTS','jerk_peaks', 'run'+ str(run) + '_segment' + segment  +'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798fd6f-fce0-410d-a8ff-96af99559d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ce59f4-8b11-4858-bc01-145b3943df48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### plots jerk VS ALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61e580-b652-4e45-989d-2eaf023eafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# un point somme jerk pour les 2 tools dans toutes les directions\n",
    "\n",
    "#subject_order = ['10','3','4','8','11','5','6','7','9','12']\n",
    "#ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','6','7','7','9','9','10']\n",
    "\n",
    "\n",
    "\n",
    "for segment in segment_list_optitrack:\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    for subject in subject_order:\n",
    "        y1.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        y2.append(mean_nb_peaks_jerk[subject][segment])\n",
    "          \n",
    "        x= ALI_score\n",
    "\n",
    "\n",
    "    fig  = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=2) \n",
    "\n",
    "    fig.add_trace(go.Scatter(y=y1, x=x, \n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name = \"ff\"),1,1)\n",
    "    fig.add_trace(go.Scatter(y=y2, x=x, \n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name = None),1,2)\n",
    "    \n",
    "    fig.update_traces(\n",
    "        marker_size=12,\n",
    "        marker_line=dict(width=2, color='#2F4F4F'),\n",
    "        selector=dict(mode='markers+text'))\n",
    "    \n",
    "    # Update xaxis properties\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"ALI score\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Sum nb of jerk motions / sum run time [s-1]\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean nb of jerk motions [-]\", row=1, col=2)\n",
    "\n",
    "    fig.update_layout(title='Segment:' + str(segment) ,\n",
    "               #xaxis_title='ALI score',\n",
    "               #yaxis_title='Mean nb of jerk motions [-]',\n",
    "               showlegend=False,\n",
    "               width=1200,\n",
    "               height=500,\n",
    "                         )\n",
    "\n",
    "    #fig.show()\n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_jerk' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_jerk'))\n",
    "    fig.write_image(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'jerk_VS_ali_segment' + segment  +'.png'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "subject_order_novice = ['7','9','12']\n",
    "ALI_novice = [9,9,10]\n",
    "subject_order_intermediate = ['11','8','2','5','6']\n",
    "ALI_intermediate = [6,6,6,7,7]\n",
    "subject_order_expert = ['10','3','4']\n",
    "ALI_expert = [3,4,4]\n",
    "\n",
    "\n",
    "for k, segment in enumerate(segment_list_optitrack):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "\n",
    "    \n",
    "    for subject in subject_order_expert:\n",
    "        y1.append(mean_nb_peaks_jerk[subject][segment])\n",
    "    for subject in subject_order_intermediate:\n",
    "        y2.append(mean_nb_peaks_jerk[subject][segment])\n",
    "    for subject in subject_order_novice:\n",
    "        y3.append(mean_nb_peaks_jerk[subject][segment])     \n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    plt.scatter(ALI_expert, y1, s = 120 ,color='blue', marker = 'o', label ='Experts')\n",
    "    plt.scatter(ALI_intermediate, y2, s = 120 ,color='blue', marker = '^', label = 'Intermediates')\n",
    "    plt.scatter(ALI_novice, y3, s = 120 ,color='blue', marker = '*', label = 'Novices')\n",
    "\n",
    "\n",
    "    plt.ylabel('Mean nb of jerk motions [-]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new_optitrack[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.5, 1.03))\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    plt.xlim([2, 11])\n",
    "    if segment == \"530\":\n",
    "        plt.ylim([-5, 130])\n",
    "    else:\n",
    "        plt.ylim([-5, 50])\n",
    "    #plt.ylim([0, max(max(y1),max(y2),max(y3))+15])\n",
    "    #plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "    plt.xticks(ticks=ticks, labels=ticks)\n",
    "    \n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'V2_jerk_VS_ali_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    #plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk','no_legend', 'V2_jerk_VS_ali_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for k, segment in enumerate(segment_list_optitrack):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    tmp1=[]\n",
    "    tmp2=[]\n",
    "    tmp3=[]\n",
    "    \n",
    "    #for subject in subject_order_expert:\n",
    "     #   y1.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "    #for subject in subject_order_intermediate:\n",
    "     #   y2.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "    #for subject in subject_order_novice:\n",
    "     #   y3.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        \n",
    "    for subject in subject_order_expert:\n",
    "        #y1.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp1.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y1.append(np.mean(tmp1))\n",
    "       \n",
    "    for subject in subject_order_intermediate:\n",
    "        #y2.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp2.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y2.append(np.mean(tmp2))\n",
    "    for subject in subject_order_novice:\n",
    "        #y3.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))    \n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp3.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y3.append(np.mean(tmp3))\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    plt.scatter(ALI_expert, y1, s = 120 ,color='black', marker = 'o', label ='Experts')\n",
    "    plt.scatter(ALI_intermediate, y2, s = 120 ,color='black', marker = '^', label = 'Intermediates')\n",
    "    plt.scatter(ALI_novice, y3, s = 120 ,color='black', marker = '*', label = 'Novices')\n",
    "\n",
    "\n",
    "    plt.ylabel('Mean nb of jerk motions / run time [s-1]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new_optitrack[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.03))\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    plt.xlim([2, 11])\n",
    "    if segment == \"530\":\n",
    "        plt.ylim([-0.4, 2.5])\n",
    "    else:\n",
    "        plt.ylim([-0.4, 2])\n",
    "\n",
    "    #plt.ylim([0, max(max(y1),max(y2),max(y3))+15])\n",
    "    #plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "    plt.xticks(ticks=ticks, labels=ticks)\n",
    "    \n",
    "    #plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'V2_T_jerk_VS_ALI_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk','no_legend', 'V2_T_jerk_VS_ALI_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c01b0-d395-4ff4-8e08-400a02f6f376",
   "metadata": {
    "tags": []
   },
   "source": [
    "### plots jerk VS experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbaf356-4232-4526-a382-b73066b27e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_order = ['6','2','5','8','11','12','3','4','10']\n",
    "experience_years = ['3','4','5','7','11','10','12','25','24']\n",
    "experience_years = [3,4,5,7,11,10,12,25,24]\n",
    "\n",
    "subject_order_neuro = ['6','2','5','8','3','10']\n",
    "experience_years_neuro = [3,4,5,7,12,24]\n",
    "\n",
    "subject_order_plastic = ['11']\n",
    "experience_years_plastic = [11]\n",
    "\n",
    "subject_order_maxilo = ['12']\n",
    "experience_years_maxilo = [10]\n",
    "\n",
    "subject_order_general = ['4']\n",
    "experience_years_general = [25]\n",
    "\n",
    "for segment in segment_list_optitrack:\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    for subject in subject_order:\n",
    "        y1.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        y2.append(mean_nb_peaks_jerk[subject][segment])\n",
    "          \n",
    "        x= experience_years\n",
    "\n",
    "\n",
    "    fig  = go.Figure()\n",
    "    fig = make_subplots(rows=1, cols=2) \n",
    "\n",
    "    fig.add_trace(go.Scatter(y=y1, x=x, \n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name = \"ff\"),1,1)\n",
    "\n",
    "   \n",
    "    fig.add_trace(go.Scatter(y=y2, x=x, \n",
    "            text = subject_order,\n",
    "            mode='markers+text',textposition='top right',textfont=dict(color='#2F4F4F'), name = None),1,2)\n",
    "    \n",
    "\n",
    "    \n",
    "    fig.update_traces(\n",
    "        marker_size=12,\n",
    "        marker_line=dict(width=2, color='#2F4F4F'),\n",
    "        selector=dict(mode='markers+text'))\n",
    "    \n",
    "    # Update xaxis properties\n",
    "    fig.update_xaxes(title_text=\"years of experience\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"years of experience\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Sum nb of jerk motions / sum run time [s-1]\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Mean nb of jerk motions [-]\", row=1, col=2)\n",
    "\n",
    "    fig.update_layout(title='Segment:' + str(segment) ,\n",
    "               #xaxis_title='ALI score',\n",
    "               #yaxis_title='Mean nb of jerk motions [-]',\n",
    "               showlegend=False,\n",
    "               width=1200,\n",
    "               height=500,\n",
    "                         )\n",
    "\n",
    "    #fig.show()\n",
    "    if not os.path.exists(join(path_to_data_folder, 'PLOTS' , 'optitrack_jerk' )):\n",
    "        os.makedirs(join(path_to_data_folder, 'PLOTS', 'optitrack_jerk'))\n",
    "    fig.write_image(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'jerk_VS_exp_segment' + segment  +'.png'))\n",
    "    \n",
    "\n",
    "for k, segment in enumerate(segment_list_optitrack):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    y4 = []\n",
    "\n",
    "    \n",
    "    for subject in subject_order_neuro:\n",
    "        y1.append(mean_nb_peaks_jerk[subject][segment])\n",
    "    for subject in subject_order_plastic:\n",
    "        y2.append(mean_nb_peaks_jerk[subject][segment])\n",
    "    for subject in subject_order_maxilo:\n",
    "        y3.append(mean_nb_peaks_jerk[subject][segment])     \n",
    "    for subject in subject_order_general:\n",
    "        y4.append(mean_nb_peaks_jerk[subject][segment])  \n",
    "        \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    plt.scatter(experience_years_neuro, y1, s = 120 ,color='blue', marker = 'o', label ='Neuro')\n",
    "    plt.scatter(experience_years_plastic, y2, s = 120 ,color='red', marker = '*', label = 'Plastic')\n",
    "    plt.scatter(experience_years_maxilo, y3, s = 120 ,color='orange', marker = '+', label = 'Maxillo')\n",
    "    plt.scatter(experience_years_general, y4, s = 120 ,color='green', marker = '^', label = 'General')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    plt.xticks(np.arange(1, 26, 2))\n",
    "   # plt.ylim([0, max(max(y1),max(y2),max(y3),max(y4))+15])\n",
    "    # To show the plot\n",
    "    #plt.legend(bbox_to_anchor=(1.5, 1.05))\n",
    "\n",
    "\n",
    "    plt.ylabel('Mean nb of jerk motions [-]')\n",
    "    plt.xlabel('Years experience')\n",
    "    plt.title('Segment: ' + str(segment_new_optitrack[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.4, 1.03))\n",
    "\n",
    "    if segment == \"530\":\n",
    "        plt.ylim([-0.5, 130])\n",
    "    else:\n",
    "        plt.ylim([-0.5, 50])\n",
    "    \n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'V2_jerk_VS_exp_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    #plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk','no_legend', 'V2_jerk_VS_exp_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for k, segment in enumerate(segment_list_optitrack):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "    y4 = []\n",
    "    tmp1= []\n",
    "    tmp2=[]\n",
    "    tmp3=[]\n",
    "    tmp4=[]\n",
    "    for subject in subject_order_neuro:\n",
    "        #y1.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp1.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y1.append(np.mean(tmp1))\n",
    "       \n",
    "    for subject in subject_order_plastic:\n",
    "        #y2.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))\n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp2.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y2.append(np.mean(tmp2))\n",
    "    for subject in subject_order_maxilo:\n",
    "        #y3.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))    \n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp3.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y3.append(np.mean(tmp3))\n",
    "    for subject in subject_order_general:\n",
    "        #y4.append((mean_nb_peaks_jerk[subject][segment])/(mean_duration_run[subject][segment]))  \n",
    "        for j, run in enumerate(run_list[subject][segment]):\n",
    "            tmp4.append( nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j])\n",
    "        y4.append(np.mean(tmp4))\n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "\n",
    "    plt.scatter(experience_years_neuro, y1, s = 120 ,color='black', marker = 'o', label ='Neuro')\n",
    "    plt.scatter(experience_years_plastic, y2, s = 120 ,color='red', marker = '*', label = 'Plastic')\n",
    "    plt.scatter(experience_years_maxilo, y3, s = 120 ,color='orange', marker = '+', label = 'Maxillo')\n",
    "    plt.scatter(experience_years_general, y4, s = 120 ,color='green', marker = '^', label = 'General')\n",
    "\n",
    "    plt.xticks(np.arange(1, 26, 2))\n",
    "\n",
    "    plt.ylabel('Mean nb of jerk motions / run time [s-1]')\n",
    "    plt.xlabel('Years experience')\n",
    "    plt.title('Segment: ' + str(segment_new_optitrack[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    #plt.legend(bbox_to_anchor=(1.4, 1.03))\n",
    "    \n",
    "    if segment == \"530\":\n",
    "        plt.ylim([-0.4, 2.5])\n",
    "    else:\n",
    "        plt.ylim([-0.4, 2])\n",
    "    \n",
    "    #plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk', 'V2_T_jerk_VS_exp_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_jerk','no_legend', 'V2_T_jerk_VS_exp_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388aa92-b507-4445-a091-5adfc173d331",
   "metadata": {},
   "source": [
    "### plot BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3300b23-94f0-4bee-82d5-f90e299ae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_order_novice = ['7','9','12']\n",
    "ALI_novice = [9,9,10]\n",
    "subject_order_intermediate = ['11','8','2','5','6']\n",
    "ALI_intermediate = [6,6,6,7,7]\n",
    "subject_order_expert = ['10','3','4']\n",
    "ALI_expert = [3,4,4]\n",
    "\n",
    "segment_new = [2,3,4,5,6,1]\n",
    "\n",
    "for k, segment in enumerate(segment_list):\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    y3 = []\n",
    "\n",
    "    \n",
    "    for subject in subject_order_expert:\n",
    "        y1.append(mean_BD[subject][segment])\n",
    "    for subject in subject_order_intermediate:\n",
    "        y2.append(mean_BD[subject][segment])\n",
    "    for subject in subject_order_novice:\n",
    "        y3.append(mean_BD[subject][segment])     \n",
    "    \n",
    "    plt.figure(figsize=(6.5, 4.5))\n",
    "\n",
    "    plt.scatter(ALI_expert, y1, s = 120 ,color='blue', marker = 'o', label ='Experts')\n",
    "    plt.scatter(ALI_intermediate, y2, s = 120 ,color='blue', marker = '^', label = 'Intermediates')\n",
    "    plt.scatter(ALI_novice, y3, s = 120 ,color='blue', marker = '*', label = 'Novices')\n",
    "\n",
    "\n",
    "    plt.ylabel('Bimanual dexterity [-]')\n",
    "    plt.xlabel('ALI score')\n",
    "    plt.title('Segment: ' + str(segment_new[k]), fontdict=None, loc='center', pad=None)\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.5, 1.03))\n",
    "    ticks = [3,4,5,6,7,8,9,10]\n",
    "    \n",
    "    plt.xlim([2, 11])\n",
    "    if segment == \"530\":\n",
    "        plt.ylim([-0.2, 0.4])\n",
    "    else:\n",
    "        if segment == \"560\":\n",
    "            plt.ylim([-0.1, 0.5])\n",
    "        else:\n",
    "            plt.ylim([-0.1, 0.5])\n",
    "                \n",
    "    #plt.ylim([0, max(max(y1),max(y2),max(y3))+15])\n",
    "    #plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "    plt.xticks(ticks=ticks, labels=ticks)\n",
    "    \n",
    "    plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_BD', 'BD_VS_ali_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "    #plt.savefig(join('..', 'data_exp',  'PLOTS','optitrack_BD','no_legend', 'BD_VS_ali_segment' + segment  +'.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8a836-04a9-4088-891f-6d0c7609ba3e",
   "metadata": {},
   "source": [
    "### plot interpolation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be385746-be14-470e-8ed2-ff1094432ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subject_list_optitrack:   \n",
    "    for segment in segment_list:\n",
    "        for run in run_list[subject][segment]:\n",
    "            fig = go.Figure()\n",
    "            for tool in ['tweezer_x', 'tweezer_y', 'tweezer_z','needle_holder2_x', 'needle_holder2_y', 'needle_holder2_z']:  \n",
    "                time_current =  optitrack_non_zero_time[subject][segment][run][tool]\n",
    "\n",
    "                data_current1 = np.array(optitrack_non_zero[subject][segment][run][tool])\n",
    "                data_current2 = np.array(interpolated_data[subject][segment][run][tool])\n",
    "                               \n",
    "                fig.add_trace(go.Scatter(y=data_current2, x=np.array(time_vector_interp[subject][segment][run][tool] -data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool+ \"interp\"))\n",
    "                fig.add_trace(go.Scatter(y=data_current1, x=np.array((optitrack_non_zero_time[subject][segment][run][tool])-data_segments[subject][segment][run][sensor]['rel_time'][0]),\n",
    "                    mode='markers', name=tool ))\n",
    "            fig.update_layout(title='Subject: ' + subject + ', Run: ' + str(run) +', Segment:' + str(segment),\n",
    "                xaxis_title='Time',\n",
    "                yaxis_title='Optitrack data [m]',\n",
    "                width=1000,\n",
    "                height=500)\n",
    "            #fig.show()\n",
    "                       \n",
    "            if not os.path.exists(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' )):\n",
    "                os.makedirs(join(path_to_data_folder, recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack' ))\n",
    "            fig.write_image(join('..', 'data_exp', recording_session[subject] , subject, run, 'SENSORS', 'SEGMENTATION', 'plots_optitrack', 'optitrack_position_INTERP_subject_'+ subject+ 'run'+ str(run) + '_segment' + segment  +'.png'))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929362f-09e5-49ff-acb5-00d7cea3a2ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ANOVA optitrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b244c-01f7-45b4-b648-c67d00471546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### one way anova hand travel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811abaf-91d4-4e3b-8cbc-3e64ee0c00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data separating expertise for each channels\n",
    "\n",
    "\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','6','7','7','9','9','10']\n",
    "\n",
    "subject_order_novice = ['7','9','12']\n",
    "subject_order_intermediate = ['11','8','2','5','6']\n",
    "subject_order_expert = ['10','3','4']\n",
    "\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': subject_order_expert,\n",
    "    'Novice': subject_order_novice,\n",
    "    'Intermediate': subject_order_intermediate\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "hand_travel_segment_subject_expertise = {}\n",
    "for segment in segment_list_optitrack:\n",
    "    hand_travel_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list_optitrack: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','hand_travel_dist' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','value_hand_travel_tweezers_x', 'value_hand_travel_tweezers_y','value_hand_travel_tweezers_z','value_hand_travel_nh_x', 'value_hand_travel_nh_y', 'value_hand_travel_nh_z',]\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                tweezer_x = range_travel[subject][segment][run][tools_position[0]] \n",
    "                tweezer_y = range_travel[subject][segment][run][tools_position[1]] \n",
    "                tweezer_z = range_travel[subject][segment][run][tools_position[2]] \n",
    "                nh_x = range_travel[subject][segment][run][tools_position[3]] \n",
    "                nh_y = range_travel[subject][segment][run][tools_position[4]] \n",
    "                nh_z = range_travel[subject][segment][run][tools_position[5]] \n",
    "                \n",
    "                row = [cat, tweezer_x, tweezer_y, tweezer_z, nh_x, nh_y, nh_z]\n",
    "                writer.writerow(row)\n",
    "                hand_travel_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "                    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n",
    "\n",
    "hand_travel_expertise_dataframe = {}\n",
    "for segment, values in hand_travel_segment_subject_expertise.items():\n",
    "    \n",
    "    hand_travel_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_hand_travel_tweezers_x\", \"value_hand_travel_tweezers_y\",\"value_hand_travel_tweezers_z\",\"value_hand_travel_nh_x\", \"value_hand_travel_nh_y\", \"value_hand_travel_nh_z\"])\n",
    "#print( time_expertise_dataframe)\n",
    "    \n",
    "hand_travel_anova_results = {}\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_tweezers_x ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: tweezer x \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_tweezers_y ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: tweezer y \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_tweezers_z ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: tweezer z \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_nh_x ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: needle holder x \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_nh_y ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: needle holder y \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for segment, dataframe in hand_travel_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_hand_travel_nh_z ~ C(category)', data=dataframe).fit()\n",
    "    hand_travel_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" tool: needle holder z \" )\n",
    "    print(hand_travel_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b58658-91f0-472d-8be9-6837329be73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24788c0-540a-4180-88bc-0d64d4816281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2d44011-0826-47fd-91f6-2583590fb42c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75ed82-14ff-4398-bf62-9dc2ec3400e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dff752-9b5a-40fb-bb45-5fd41fbb5729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99fbf0b0-64cb-4999-987c-f1ec90aba2b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### two ways anova: years experience and ALI for jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa47cc-e47c-41f2-84cd-5f3f107943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data separating expertise for each channels\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "novice_subjects = ['7','9','12']\n",
    "intermediate_subjects = ['11','8','5','6','2']\n",
    "expert_subjects = ['10','3','4']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"years1_subjects = ['5','6','8','2']\n",
    "years2_subjects = ['12','11','3']\n",
    "years3_subjects = ['10','4']\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "\n",
    "subject_experience = {\n",
    "    '1': years1_subjects, #<10 years\n",
    "    '2': years2_subjects, # between 10 and 20\n",
    "    '3': years3_subjects # above 20\n",
    "}\"\"\"\n",
    "\n",
    "years_experience_cat = {\n",
    "    '7': \"None\",\n",
    "    '9': \"None\",\n",
    "    '2': \"1-10 years\",\n",
    "    '5':\"1-10 years\",\n",
    "    '6':\"1-10 years\",\n",
    "    '8':\"1-10 years\",\n",
    "    '12': \"10-20 years\",\n",
    "    '11':\"10-20 years\",\n",
    "    '3':\"10-20 years\",\n",
    "    '10':\">20 years\",    \n",
    "    '4':\">20 years\"\n",
    "}\n",
    "\n",
    "jerk_segment_subject_expertise = {}\n",
    "for segment in segment_list_optitrack:\n",
    "    jerk_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list_optitrack: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','jerk' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','years_experience', 'value_nb_jerk']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                nb_jerk = nb_peaks_jerk[subject][segment][run]\n",
    "                \n",
    "                row = [cat, years_experience_cat[subject], nb_jerk]\n",
    "                writer.writerow(row)\n",
    "                jerk_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n",
    "\n",
    "jerk_expertise_dataframe = {}\n",
    "for segment, values in jerk_segment_subject_expertise.items():\n",
    "    \n",
    "    jerk_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"years_experience\", \"value_nb_jerk\"])\n",
    "#print( time_expertise_dataframe)\n",
    "    \n",
    "jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(category)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk\" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "    \n",
    "jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(years_experience)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk\" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    " #perform two-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(category) + C(years_experience) + C(category):C(years_experience)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk \" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94242f8b-7449-4ce4-ad18-a0916998cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data separating expertise for each channels\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "\n",
    "years1_subjects = ['5','6','8','2']\n",
    "years2_subjects = ['12','11','3']\n",
    "years3_subjects = ['10','4']\n",
    "\n",
    "categories = ['<10_years','10-20_years','>20_years']\n",
    "\n",
    "subject_experience = {\n",
    "    '<10_years': years1_subjects, #<10 years\n",
    "    '10-20_years': years2_subjects, # between 10 and 20\n",
    "    '>20_years': years3_subjects # above 20\n",
    "}\n",
    "\n",
    "\n",
    "jerk2_segment_subject_expertise = {}\n",
    "for segment in segment_list_optitrack:\n",
    "    jerk2_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list_optitrack: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','exp_jerk' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['years_experience', 'value_nb_jerk']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in categories:     \n",
    "        for subject in subject_experience[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                nb_jerk = nb_peaks_jerk[subject][segment][run]\n",
    "                \n",
    "                row = [cat, nb_jerk]\n",
    "                writer.writerow(row)\n",
    "                jerk_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536cdf2-ae4b-4903-b966-aee9b0d03433",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ANOVA for jerk devided by time for experience and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdde79c-e471-41b6-8a75-96234786b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data separating expertise for each channels\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "novice_subjects = ['7','9','12']\n",
    "intermediate_subjects = ['11','8','5','6','2']\n",
    "expert_subjects = ['10','3','4']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "jerk_segment_subject_expertise = {}\n",
    "for segment in segment_list_optitrack:\n",
    "    jerk_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list_optitrack: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','jerk_normT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','years_experience', 'value_nb_jerk']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for j, run in enumerate(run_list[subject][segment]):\n",
    "                nb_jerk_t = nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j]\n",
    "                \n",
    "                row = [cat, nb_jerk_t]\n",
    "                writer.writerow(row)\n",
    "                jerk_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n",
    "\n",
    "jerk_expertise_dataframe = {}\n",
    "for segment, values in jerk_segment_subject_expertise.items():\n",
    "    \n",
    "    jerk_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_nb_jerk\"])\n",
    "#print( time_expertise_dataframe)\n",
    "    \n",
    "jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(category)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk\" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "    \n",
    "\"\"\"jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(years_experience)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk\" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\"\"\"\n",
    "\n",
    "\"\"\"jerk_anova_results = {}\n",
    "for segment, dataframe in jerk_expertise_dataframe.items():\n",
    " #perform two-way ANOVA\n",
    "    model = ols('value_nb_jerk ~ C(category) + C(years_experience) + C(category):C(years_experience)', data=dataframe).fit()\n",
    "    jerk_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" jerk \" )\n",
    "    print(jerk_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab49f74-325f-4576-a3af-f8e1f90e0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data separating expertise for each channels\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "\n",
    "years1_subjects = ['5','6','8','2']\n",
    "years2_subjects = ['12','11','3']\n",
    "years3_subjects = ['10','4']\n",
    "\n",
    "categories = ['<10_years','10-20_years','>20_years']\n",
    "\n",
    "subject_experience = {\n",
    "    '<10_years': years1_subjects, #<10 years\n",
    "    '10-20_years': years2_subjects, # between 10 and 20\n",
    "    '>20_years': years3_subjects # above 20\n",
    "}\n",
    "\n",
    "\n",
    "jerk2_segment_subject_expertise = {}\n",
    "for segment in segment_list_optitrack:\n",
    "    jerk2_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list_optitrack: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','exp_jerk_normT' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['years_experience', 'value_nb_jerk']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in categories:     \n",
    "        for subject in subject_experience[cat]:   \n",
    "            for j, run in enumerate(run_list[subject][segment]):\n",
    "                nb_jerk_t = nb_peaks_jerk[subject][segment][run] / duration_run_segments[subject][segment][j]\n",
    "                \n",
    "                row = [cat, nb_jerk_t]\n",
    "                writer.writerow(row)\n",
    "                jerk2_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abe8da-997d-4c4f-9ba6-6a18e582ea8d",
   "metadata": {},
   "source": [
    "### ANOVA BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0c26f04f-a9f7-4e3a-9e08-6a55f817ada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment: 500 BD\n",
      "               sum_sq    df         F    PR(>F)\n",
      "C(category)  0.111795   2.0  2.589852  0.085937\n",
      "Residual     0.992832  46.0       NaN       NaN\n",
      "\n",
      "\n",
      "segment: 510 BD\n",
      "               sum_sq    df         F    PR(>F)\n",
      "C(category)  0.103555   2.0  4.882091  0.011845\n",
      "Residual     0.498464  47.0       NaN       NaN\n",
      "\n",
      "\n",
      "segment: 530 BD\n",
      "               sum_sq    df         F    PR(>F)\n",
      "C(category)  0.079971   2.0  1.905854  0.160011\n",
      "Residual     0.986079  47.0       NaN       NaN\n",
      "\n",
      "\n",
      "segment: 540 BD\n",
      "               sum_sq    df         F    PR(>F)\n",
      "C(category)  0.256458   2.0  9.693188  0.000316\n",
      "Residual     0.595295  45.0       NaN       NaN\n",
      "\n",
      "\n",
      "segment: 541 BD\n",
      "               sum_sq    df          F    PR(>F)\n",
      "C(category)  0.438054   2.0  10.277236  0.000204\n",
      "Residual     0.980346  46.0        NaN       NaN\n",
      "\n",
      "\n",
      "segment: 560 BD\n",
      "               sum_sq    df         F    PR(>F)\n",
      "C(category)  0.019587   2.0  2.725743  0.076562\n",
      "Residual     0.158088  44.0       NaN       NaN\n",
      "\n",
      "\n",
      "-----------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the data separating expertise for each channels\n",
    "subject_order = ['10','3','4','8','11','2','5','6','7','9','12']\n",
    "ALI_score = ['3','4','4','6','6','7','7','9','9','10']\n",
    "\n",
    "novice_subjects = ['7','9','12']\n",
    "intermediate_subjects = ['11','8','5','6','2']\n",
    "expert_subjects = ['10','3','4']\n",
    "category = ['Novice', 'Intermediate', 'Expert']\n",
    "\n",
    "\n",
    "\n",
    "subject_expertise = {\n",
    "    'Expert': expert_subjects,\n",
    "    'Novice': novice_subjects,\n",
    "    'Intermediate': intermediate_subjects\n",
    "}\n",
    "\n",
    "\n",
    "BD_segment_subject_expertise = {}\n",
    "for segment in segment_list:\n",
    "    BD_segment_subject_expertise[segment] = []\n",
    "\n",
    "for segment in segment_list: \n",
    "    folder = join('..', 'data_exp' )\n",
    "    rs_csv = join(folder,'ANOVA','optitrack','BD' + segment +'.csv')\n",
    "    f = open(rs_csv, 'w') # open the file in the write mode                        \n",
    "    # create the csv writer\n",
    "    writer = csv.writer(f)\n",
    "    header = ['category','value_BD']\n",
    "    # write a row to the csv file\n",
    "    writer.writerow(header)\n",
    "    for cat in category:     \n",
    "        for subject in subject_expertise[cat]:   \n",
    "            for run in run_list[subject][segment]:\n",
    "                BD_val = BD[subject][segment][run]\n",
    "                \n",
    "                row = [cat, BD_val]\n",
    "                writer.writerow(row)\n",
    "                BD_segment_subject_expertise[segment].append(row)\n",
    "    f.close() \n",
    "\n",
    "    #met a la suite les valeurs des temps pour les runs des sujets avec la meme expertise, pour chaque segment\n",
    "#print(time_segment_subject_expertise)\n",
    "\n",
    "BD_expertise_dataframe = {}\n",
    "for segment, values in BD_segment_subject_expertise.items():\n",
    "    \n",
    "    BD_expertise_dataframe[segment] = pd.DataFrame(values, columns=[\"category\", \"value_BD\"])\n",
    "#print( time_expertise_dataframe)\n",
    "    \n",
    "BD_anova_results = {}\n",
    "for segment, dataframe in BD_expertise_dataframe.items():\n",
    "    #perform one-way ANOVA\n",
    "    model = ols('value_BD ~ C(category)', data=dataframe).fit()\n",
    "    BD_anova_results[segment] = sm.stats.anova_lm(model, typ=2)\n",
    "    print(\"segment: \" + segment + \" BD\" )\n",
    "    print(BD_anova_results[segment])\n",
    "    print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392262c-4409-4f07-9aaa-874209cbde5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## junk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdadcca-26e0-422f-9039-5334fbf6d219",
   "metadata": {},
   "source": [
    "## interpolation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802fffd3-ac4c-4338-bf8b-95086cfe432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19077\n",
      "19077\n",
      "19077\n",
      "19077\n",
      "5416\n",
      "6223\n",
      "6223\n",
      "14853.4\n",
      "14853.4\n",
      "14853.4\n",
      "[14694.425      14694.43333333 14694.44166667 ... 14853.375\n",
      " 14853.38333333 14853.39166666]\n",
      "[14694.425      14694.43333333 14694.44166667 ... 14853.375\n",
      " 14853.38333333 14853.39166666]\n"
     ]
    }
   ],
   "source": [
    "print(len(interpolated_data[subject][segment][run]['needle_holder2_x']))\n",
    "print(len(interpolated_data[subject][segment][run]['tweezer_x']))\n",
    "print(len(time_vector_interp[subject][segment][run]['needle_holder2_x']))\n",
    "print(len(time_vector_interp[subject][segment][run]['tweezer_x']))\n",
    "\n",
    "print(len(optitrack_non_zero_time[subject][segment][run]['needle_holder2_x']))\n",
    "print(len(optitrack_non_zero_time[subject][segment][run]['tweezer_x']))\n",
    "\n",
    "print(len(data_segments[subject][segment][run][sensor]['rel_time']))   \n",
    "print(np.max(data_segments[subject][segment][run][sensor]['rel_time']))\n",
    "print(np.max(optitrack_non_zero_time[subject][segment][run]['needle_holder2_x']))\n",
    "print(np.max(optitrack_non_zero_time[subject][segment][run]['tweezer_x']))\n",
    "\n",
    "print((time_vector_interp[subject][segment][run]['needle_holder2_x']))\n",
    "print((time_vector_interp[subject][segment][run]['tweezer_x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed7349-4110-4041-a36d-e472ddf49363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef1ab6-9791-4815-b0da-c2584f1e2c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b197f3e9-b4a1-4f5f-a615-faa0d34e8079",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad221eeb-0a19-4c25-8cec-653f3856e818",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "60ab83cf-e15e-4187-b344-af9a7c75a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19076\n",
      "19076\n",
      "19076\n",
      "19076\n",
      "19077\n",
      "19077\n",
      "6223\n",
      "5416\n",
      "12\n",
      "560\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(norm_tip_speed[subject][segment][run][\"tweezer\"]))\n",
    "print(len(norm_tip_speed[subject][segment][run][\"needle_holder2\"]))\n",
    "print(len(diff_x_tip[subject][segment][run][\"tweezer\"]))\n",
    "print(len(diff_x_tip[subject][segment][run][\"needle_holder2\"]))\n",
    "print(len(pos_x_tip[subject][segment][run][\"tweezer\"]))\n",
    "print(len(pos_x_tip[subject][segment][run][\"needle_holder2\"]))\n",
    "print(len(optitrack_non_zero[subject][segment][run][\"tweezer\" + '_' + 'x']))\n",
    "print(len(optitrack_non_zero[subject][segment][run][\"needle_holder2\" + '_' + 'x']))\n",
    "print(subject)\n",
    "print(segment)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc587d5b-4648-4608-9968-c258dd70b1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a852dff-4cf8-4f26-a4f7-9515f47b1fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180f828-e51a-4fe3-a967-06f88cc4098a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b8f10-66f1-414b-b5a4-2c93a3c221b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
